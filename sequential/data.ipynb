{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "seed = 42\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    \n",
    "def get_timestamp(date_format: str = '%d%H%M%S') -> str:\n",
    "    timestamp = datetime.now()\n",
    "    return timestamp.strftime(date_format)\n",
    "\n",
    "data_dir = \"./data/sequential/small\"\n",
    "mk_dir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(data, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def dump_json(data, path):\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_pt(data, path):\n",
    "    with open(path, \"wb\") as file:\n",
    "        torch.save(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 load 및 shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.read_csv(\"./data/articles.csv\")\n",
    "interaction_data = pd.read_csv(\"./data/transactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜 및 사용자 기준으로 정렬된 것과 기존 데이터가 같은가? : True\n"
     ]
    }
   ],
   "source": [
    "is_equal = interaction_data.equals(interaction_data.sort_values(by=['t_dat','customer_id'], axis=0).reset_index(drop=True))\n",
    "print(f\"날짜 및 사용자 기준으로 정렬된 것과 기존 데이터가 같은가? : {is_equal}\") \n",
    "# 정렬 필요하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384834fd79d64dbe855cc0174d806a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31788323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다량 구매 하나로 줄이기\n",
    "drop_idx = []\n",
    "\n",
    "for idx in tqdm(range(1,len(interaction_data))):\n",
    "    if interaction_data.iloc[idx-1].equals(interaction_data.iloc[idx]):\n",
    "        drop_idx.append(idx)\n",
    "\n",
    "interaction_data = interaction_data.drop(index=drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 포함된 행 drop\n",
    "n_item_data = item_data.dropna(axis=0, how=\"any\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Item data :  (105126, 25)\n",
      "shape of interaction data :  (28839228, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of Item data : \",n_item_data.shape)\n",
    "print(\"shape of interaction data : \", interaction_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지가 없는 아이템 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_by_id(df, article_id:int, no_list:list, echo:int=1, img_show:bool=True):\n",
    "    if article_id in no_list:\n",
    "        return\n",
    "    if echo:\n",
    "        display(df[df.article_id == article_id])\n",
    "\n",
    "    img_id = \"0\"+str(article_id)\n",
    "    img = Image.open(\"./data/images/\"+img_id[0:3]+\"/\"+img_id+\".jpg\")\n",
    "\n",
    "    if img_show:\n",
    "        img.show()\n",
    "\n",
    "def find_no_img_item(df):\n",
    "    no_img = []\n",
    "\n",
    "    for item in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img_by_id(df, item[1][0], no_list=no_img, echo=0, img_show=False)\n",
    "        except FileNotFoundError:\n",
    "            no_img.append(item[0])\n",
    "\n",
    "    return no_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a14855e026645b08d2768a67dea1aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonbo\\AppData\\Local\\Temp\\ipykernel_18840\\1998916234.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_by_id(df, item[1][0], no_list=no_img, echo=0, img_show=False)\n"
     ]
    }
   ],
   "source": [
    "no_img_idx = find_no_img_item(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-img item :  442\n"
     ]
    }
   ],
   "source": [
    "print(\"# of non-img item : \",len(no_img_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of n_item_data :  (105100, 25)\n"
     ]
    }
   ],
   "source": [
    "# 이미지가 없는 아이템 삭제\n",
    "no_img_item = {idx:item_data.iloc[idx].article_id for idx in no_img_idx}\n",
    "n_item_data = item_data.drop(no_img_idx, axis=0).reset_index(drop=True) # 이미지 없는 아이템을 삭제한 데이터\n",
    "print(\"shape of n_item_data : \", n_item_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상품 카테고리(product_type_no)에 따른 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of n_item_data :  (104973, 25)\n"
     ]
    }
   ],
   "source": [
    "# product_type에 속하는 상품이 10개 미만인 경우 삭제 131 -> 94로 줄어듦, 아이템은 약 130개 사라짐\n",
    "n_item_data = n_item_data.groupby('product_type_no').filter(lambda x: len(x) >= 10).reset_index(drop=True)\n",
    "print(\"shape of n_item_data : \", n_item_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of n_item_data :  (104572, 25)\n",
      "# of product_type :  84\n"
     ]
    }
   ],
   "source": [
    "# product_type 중 불필요한 것 삭제 -> 84로 줄어듧, 아이템 400개 정도 사라짐\n",
    "rm_list = [\"Umbrella\", \"Bracelet\", \"Giftbox\", \"Waterbottle\", \n",
    "           \"Nipple covers\", 'Chem. cosmetics', \"Fine cosmetics\", \"Soft Toys\",\n",
    "           \"Bra extender\", \"Cushion\", \"Side table\", \"Dog Wear\", \"Keychain\",\n",
    "           \"Sewing kit\", \"Towel\", \"Mobile case\", \"Zipper head\",\n",
    "           \"Wireless earphone case\", \"Stain remover spray\",\n",
    "           \"Clothing mist\", \"Hair ties\"]\n",
    "n_item_data = n_item_data[~n_item_data['product_type_name'].isin(rm_list)].reset_index(drop=True)\n",
    "print(\"shape of n_item_data : \", n_item_data.shape)\n",
    "print(\"# of product_type : \", n_item_data.product_type_name.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of interaction data :  (28839228, 5)\n",
      "shape of n_interaction_data :  (28622541, 5)\n"
     ]
    }
   ],
   "source": [
    "# interacion data에서 앞선 과정에서 삭제된 데이터 제거\n",
    "n_interaction_data = interaction_data[interaction_data['article_id'].isin(n_item_data['article_id'])].reset_index(drop=True)\n",
    "print(\"shape of interaction data : \", interaction_data.shape)\n",
    "print(\"shape of n_interaction_data : \", n_interaction_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구매이력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_ = n_interaction_data.groupby([\"customer_id\"]).article_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   1361131.00000\n",
       "mean         21.02850\n",
       "std          34.41201\n",
       "min           1.00000\n",
       "25%           3.00000\n",
       "50%           9.00000\n",
       "75%          24.00000\n",
       "max        1636.00000\n",
       "Name: article_id, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(cnt_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 구매 횟수에 대한 빈도 막대 그래프\n",
    "plt.bar(unique, counts)\n",
    "# plt.xlim((0,200))\n",
    "# plt.ylim((0,500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아이템 및 유저의 상호작용 수에 따른 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = n_item_data[[\"article_id\",\"product_type_no\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이템/유저 등장 빈도에 따른 데이터 구성\n",
    "# 유저: 상호작용이 threshold 이하인 경우 삭제, 아이템 : 상호작용이 20 이하인 경우 삭제 \n",
    "# 상호작용 유저/아이템 수는 반복 구매를 제외하고 unique한 값을 기준으로 함\n",
    "# 반복적으로 실행하여, 모든 유저, 아이템이 조건을 만족하도록 함\n",
    "\n",
    "def data_cutter(origin_data, threshold=20):\n",
    "    while True:\n",
    "        new_data = origin_data.groupby('customer_id').filter(lambda x: x.article_id.nunique() >= threshold).reset_index(drop=True)\n",
    "        new_data = new_data.groupby('article_id').filter(lambda x: x.customer_id.nunique() >= 20).reset_index(drop=True)\n",
    "        \n",
    "        if new_data.equals(origin_data):\n",
    "            print(\"finish\")\n",
    "            break\n",
    "        origin_data = new_data\n",
    "        print(\"cut again\")\n",
    "\n",
    "    print(\"shape of n_interaction_data : \", new_data.shape)\n",
    "    print(\"num of user : \", new_data.customer_id.nunique())\n",
    "    print(\"num of item : \", new_data.article_id.nunique())\n",
    "    print(\"data density : \", new_data.shape[0]/(new_data.customer_id.nunique()*new_data.article_id.nunique())*100, \"%\")\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut again\n",
      "cut again\n",
      "cut again\n",
      "cut again\n",
      "finish\n",
      "shape of n_interaction_data :  (15984824, 5)\n",
      "num of user :  190977\n",
      "num of item :  60286\n",
      "data density :  0.13883863102382377 %\n"
     ]
    }
   ],
   "source": [
    "# n_interaction_data_10 = data_cutter(n_interaction_data, 10)\n",
    "# n_interaction_data_20 = data_cutter(n_interaction_data, 20)\n",
    "new_interaction_data = data_cutter(n_interaction_data, 40) # 아이템: 20미만 삭제, 유저: 40미만 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_item_data = n_item_data[n_item_data['article_id'].isin(new_interaction_data['article_id'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_type마다 속하는 item 목록 생성 {product_type_no : [items]}\n",
    "items_by_prod_type = dict(list(n_item_data.groupby(\"product_type_no\")))\n",
    "for k in items_by_prod_type.keys():\n",
    "    items_by_prod_type[k] = items_by_prod_type[k].article_id.reset_index(drop=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_type에 속하는 아이템이 5개 미만인 경우 prod_type과 그에 속하는 아이템 삭제\n",
    "rm_list = [key for key, value in items_by_prod_type.items() if len(value) < 5]\n",
    "\n",
    "for k in rm_list:\n",
    "    del items_by_prod_type[k]\n",
    "    \n",
    "n_item_data = n_item_data[~n_item_data['product_type_no'].isin(rm_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interaction_data = new_interaction_data[new_interaction_data['article_id'].isin(n_item_data['article_id'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of n_item_data :  (60285, 2)\n",
      "shape of new_interaction_data :  (15984802, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of n_item_data : \", n_item_data.shape)\n",
    "print(\"shape of new_interaction_data : \", new_interaction_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"shape of interaction data\" : new_interaction_data.shape,\n",
    "            \"num of user\" : new_interaction_data.customer_id.nunique(),\n",
    "            \"num of item\" : new_interaction_data.article_id.nunique(),\n",
    "            \"data density\" : f'{new_interaction_data.shape[0]/(new_interaction_data.customer_id.nunique()*new_interaction_data.article_id.nunique())*100}%'}\n",
    "dump_json(metadata, f'{data_dir}/metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_type마다 속하는 item 목록 생성 {product_type_no : [items]}\n",
    "items_by_prod_type = dict(list(n_item_data.groupby(\"product_type_no\")))\n",
    "for k in items_by_prod_type.keys():\n",
    "    items_by_prod_type[k] = items_by_prod_type[k].article_id.reset_index(drop=True).tolist()\n",
    "\n",
    "torch.save(items_by_prod_type, f\"{data_dir}/items_by_prod_type.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아이템 이미지 임베딩 생성 with fashion clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108775015, 108775044, 108775051, ..., 949198001, 949551001,\n",
       "       949551002], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_item_data[\"article_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "fclip = FashionCLIP('fashion-clip')\n",
    "\n",
    "images = [\"./data/images/\" + \"0\" + str(k)[0:2] + \"/\" + \"0\"+str(k) + \".jpg\" for k in n_item_data[\"article_id\"].unique()]\n",
    "image_embeddings = fclip.encode_images(images, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {article_id : emb}\n",
    "idx_emb_map = {i:torch.tensor(v) for i,(k,v) in enumerate(zip(n_item_data[\"article_id\"].unique(), image_embeddings))}\n",
    "torch.save(idx_emb_map, f'{data_dir}/idx_emb_map.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 임베딩을 pkl/json 파일로 저장하고 싶은 경우 실행\n",
    "dump_pickle(image_embeddings, f'{data_dir}/img_emb_small.pkl')\n",
    "# dump_json(image_embeddings, f'{data_dir}/img_emb_small.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of user 190977\n",
      "# of item 60285\n"
     ]
    }
   ],
   "source": [
    "user2idx = {v:k for k,v in enumerate(new_interaction_data['customer_id'].unique())} # {user_id:idx}\n",
    "item2idx = {v:k for k,v in enumerate(n_item_data['article_id'].unique())}         # {item_id:idx}\n",
    "\n",
    "print(\"# of user\", len(user2idx))\n",
    "print(\"# of item\", len(item2idx))\n",
    "\n",
    "torch.save(item2idx, f'{data_dir}/item2idx.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108775015, 108775044, 108775051, ..., 949198001, 949551001,\n",
       "       949551002], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemnames = n_item_data['article_id'].unique()\n",
    "item2dix_already = np.asarray(item2dix_already.keys())\n",
    "result = np.setdiff1d(itemnames, item2dix_already)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60285"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interaction_data[\"customer_id\"] = new_interaction_data[\"customer_id\"].map(user2idx)\n",
    "new_interaction_data[\"article_id\"] = new_interaction_data[\"article_id\"].map(item2idx)\n",
    "n_item_data[\"article_id\"] = n_item_data[\"article_id\"].map(item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_with_prod_type = {k:v for k,v in zip(n_item_data.article_id, n_item_data.product_type_no)}\n",
    "torch.save(item_with_prod_type, f'{data_dir}/item_with_prod_type.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/valid/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_interaction_data = new_interaction_data.drop([\"t_dat\", \"price\",\"sales_channel_id\"], axis=1)\n",
    "unique_data = new_interaction_data.drop_duplicates([\"article_id\", \"customer_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = unique_data.groupby(\"customer_id\").sample(n=1, random_state=seed) # 랜덤하게 1개 추출하여 test로 사용\n",
    "unique_data = unique_data[~unique_data.index.isin(test_data.index)] # test set으로 추출된 것 제거\n",
    "valid_data = unique_data.groupby(\"customer_id\").sample(n=1, random_state=seed) # 다시 랜덤하게 1개 추출하여 valid로 사용\n",
    "\n",
    "print(f'test 및 valid가 중복없이 생성되었는가? : {pd.concat([valid_data, test_data]).drop_duplicates(keep=False).shape[0] == (valid_data.shape[0] + test_data.shape[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = unique_data.groupby(\"customer_id\").nth(-1) # 랜덤하게 1개 추출하여 test로 사용\n",
    "valid_data = unique_data.groupby(\"customer_id\").nth(-2) # 다시 랜덤하게 1개 추출하여 valid로 사용\n",
    "\n",
    "print(f'test 및 valid가 중복없이 생성되었는가? : {pd.concat([valid_data, test_data]).drop_duplicates(keep=False).shape[0] == (valid_data.shape[0] + test_data.shape[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split by time (unused item case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = unique_data.groupby(\"customer_id\").nth(-1).reset_index() #가장 마지막 1개 추출\n",
    "user_item_dict = dict(list(new_interaction_data.groupby(\"customer_id\")))\n",
    "\n",
    "for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "    i = -1\n",
    "    item = row.article_id\n",
    "    user = row.customer_id\n",
    "    \n",
    "    while sum(user_item_dict[user].article_id.isin([item])) > 1: #구매 이력에 1번 이상 존재하는 경우 그 앞의 것 확인\n",
    "        i -= 1\n",
    "        item = user_item_dict[user].article_id.iloc[i]\n",
    "        # print(f\"{idx, user} Again\")\n",
    "    \n",
    "    test_data.at[idx, 'article_id'] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index          2139805\n",
      "customer_id     161442\n",
      "article_id       34615\n",
      "Name: 50, dtype: int64\n",
      "index          2139805\n",
      "customer_id     161442\n",
      "article_id       27547\n",
      "Name: 50, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 값이 변경됐는지 확인\n",
    "print(test_data.iloc[50])\n",
    "print(unique_data.groupby(\"customer_id\").nth(-1).reset_index().iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data = unique_data[~unique_data.index.isin(test_data[\"index\"])] # test set으로 추출된 것 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = unique_data.groupby(\"customer_id\").nth(-1).reset_index() # 가장 마지막 1개 추출 -> test를 제외하였으므로 -2번째로 볼 수 있음\n",
    "\n",
    "for idx, row in tqdm(valid_data.iterrows(), total=len(valid_data)):\n",
    "    i = -1\n",
    "    item = row.article_id\n",
    "    user = row.customer_id\n",
    "    \n",
    "    while sum(user_item_dict[user].article_id.isin([item])) > 1: #구매 이력에 1번 이상 존재하는 경우 제외\n",
    "        i -= 1\n",
    "        item = user_item_dict[user].article_id.iloc[i]\n",
    "        # print(f\"{idx, user} Again\")\n",
    "    \n",
    "    valid_data.at[idx, 'article_id'] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index          3500727\n",
      "customer_id     176326\n",
      "article_id       11046\n",
      "Name: 199, dtype: int64\n",
      "index          3273411\n",
      "customer_id      17510\n",
      "article_id       27309\n",
      "Name: 199, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 값이 변경됐는지 확인\n",
    "print(valid_data.iloc[199])\n",
    "print(unique_data.groupby(\"customer_id\").nth(-2).reset_index().iloc[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 및 valid가 중복없이 생성되었는가? : True\n"
     ]
    }
   ],
   "source": [
    "print(f'test 및 valid가 중복없이 생성되었는가? : {pd.concat([valid_data, test_data]).drop_duplicates(keep=False).shape[0] == (valid_data.shape[0] + test_data.shape[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test/valid로 선정된 것 train에서 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = pd.Index([None])\n",
    "\n",
    "for key, data in tqdm(new_interaction_data.groupby(\"customer_id\"), total=new_interaction_data.customer_id.nunique()):\n",
    "    valid_item = valid_data[valid_data.customer_id==key].article_id\n",
    "    test_item = test_data[test_data.customer_id==key].article_id\n",
    "    idxs = data[data.article_id.isin(np.concatenate((valid_item, test_item)))].index\n",
    "    if len(idxs) > 2: # 검증용\n",
    "        print(key)\n",
    "    drop_index = drop_index.append(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_data :  (191087, 2)\n",
      "shape of valid_data :  (191087, 2)\n",
      "shape of train_data :  (15622247, 2)\n"
     ]
    }
   ],
   "source": [
    "drop_index = drop_index.dropna() # remove None\n",
    "train_data = new_interaction_data.drop(index=drop_index) \n",
    "\n",
    "test_data = test_data.reset_index(drop=True).drop(columns=\"index\")\n",
    "valid_data = valid_data.reset_index(drop=True).drop(columns=\"index\")\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "valid_data = valid_data.sort_values(by=\"customer_id\").reset_index(drop=True)\n",
    "test_data = test_data.sort_values(by=\"customer_id\").reset_index(drop=True)\n",
    "\n",
    "print(\"shape of test_data : \", test_data.shape)\n",
    "print(\"shape of valid_data : \", valid_data.shape)\n",
    "print(\"shape of train_data : \", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>22710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>22707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id\n",
       "0            0        3060\n",
       "1            0       22709\n",
       "2            0       22710\n",
       "3            0       22707\n",
       "4            0        3059"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>58272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id\n",
       "0            0         516\n",
       "1            1       41580\n",
       "2            2       50506\n",
       "3            3       59749\n",
       "4            4       58272"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id\n",
       "0            0        5440\n",
       "1            1       55048\n",
       "2            2       50506\n",
       "3            3       59752\n",
       "4            4       43049"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neg smapling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item 등장 빈도에 대한 목록 생성 {article_id : cnt}, trian_data에 있는 것만 반영\n",
    "# item_occur_cnt = train_data.groupby(\"article_id\").count().reset_index()\n",
    "# item_occur_cnt.rename(columns={\"customer_id\":\"cnt\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # product_type마다 속하는 item 목록 생성 {product_type_no : [[items], [cnts]]}\n",
    "# items_by_prod_type_cnt = dict(list(n_item_data.groupby(\"product_type_no\")))\n",
    "# for k in items_by_prod_type_cnt.keys():\n",
    "#     items_by_prod_type_cnt[k].rename(columns={\"product_type_no\":\"cnt\"}, inplace=True)\n",
    "#     items_by_prod_type_cnt[k] = items_by_prod_type_cnt[k].reset_index(drop=True)\n",
    "#     items_by_prod_type_cnt[k].cnt = 0\n",
    "\n",
    "#     for idx, row in items_by_prod_type_cnt[k].iterrows():\n",
    "#         if row.article_id in item_occur_cnt.article_id.values:\n",
    "#             items_by_prod_type_cnt[k].at[idx, 'cnt'] = item_occur_cnt.loc[item_occur_cnt['article_id'] == row.article_id, 'cnt'].values[0]\n",
    "\n",
    "# dump_pickle(items_by_prod_type_cnt, \"items_by_prod_type_cnt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_type마다 속하는 item 목록 생성 {product_type_no : [items]}\n",
    "items_by_prod_type = dict(list(n_item_data.groupby(\"product_type_no\")))\n",
    "for k in items_by_prod_type.keys():\n",
    "    items_by_prod_type[k] = items_by_prod_type[k].article_id.reset_index(drop=True).tolist()\n",
    "\n",
    "torch.save(items_by_prod_type, f'{data_dir}/items_by_prod_type.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user의 pos item 목록 생성 {user_id : [items]}\n",
    "bert_train_data = dict(list(train_data.groupby(\"customer_id\")))\n",
    "for k in bert_train_data.keys():\n",
    "    bert_train_data[k] = bert_train_data[k].article_id.reset_index(drop=True).tolist()\n",
    "\n",
    "torch.save(bert_train_data, f'{data_dir}/bert_train_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_triples_data(df, item_df, items_by_prod_type, pos_items_each_user):\n",
    "    def neg_sampling(pos_list, prod_type_no):\n",
    "        neg = random.choice(items_by_prod_type[prod_type_no]) \n",
    "        while neg in pos_list:\n",
    "            neg = random.choice(items_by_prod_type[prod_type_no]) \n",
    "        return neg\n",
    "    \n",
    "    for user_id, rows in tqdm(df.groupby(\"customer_id\")):\n",
    "            pos_list = pos_items_each_user[user_id]\n",
    "            for idx, row in rows.iterrows():\n",
    "                item_id = row.article_id\n",
    "                prod_type_no = item_df[item_df[\"article_id\"] == item_id].product_type_no.item()\n",
    "                df.at[idx, 'neg'] = neg_sampling(pos_list, prod_type_no)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190977/190977 [00:21<00:00, 8843.85it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_sampled_train_df = make_triples_data(train_data, n_item_data, items_by_prod_type, pos_items_each_user)\n",
    "neg_sampled_train_df.neg = neg_sampled_train_df.neg.apply(lambda x : int(x))\n",
    "neg_sampled_train_df.to_csv(f'{data_dir}/neg_sampled_train_df.csv')\n",
    "\n",
    "neg_sampled_valid_df = make_triples_data(valid_data, n_item_data, items_by_prod_type, pos_items_each_user)\n",
    "neg_sampled_valid_df.neg = neg_sampled_valid_df.neg.apply(lambda x : int(x))\n",
    "neg_sampled_valid_df.to_csv(f'{data_dir}/neg_sampled_valid_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMDataset(Dataset):\n",
    "    def __init__(self, df, mode:str) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.df.iloc[index]['customer_id']\n",
    "        pos = self.df.iloc[index]['article_id']\n",
    "        if self.mode in [\"valid\", \"train\"]:\n",
    "            neg = self.df.iloc[index]['neg']\n",
    "            return user, pos, neg\n",
    "        return user, pos\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sasrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSeqDataset(Dataset):\n",
    "    def __init__(self, train_df, valid_df, test_df, mode:str, max_len:int=30) -> None:\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.test_df = test_df\n",
    "        self.mode = mode\n",
    "        self.max_len = max_len\n",
    "        self.seq = {}\n",
    "        self.pos = {}\n",
    "        self.neg = {}\n",
    "        \n",
    "        self.__prepareData()\n",
    "        \n",
    "    def __makeSeq(self, train_pos, train_neg):\n",
    "        train_pos = train_pos + 1 # cos padding(zero)\n",
    "        train_neg = train_neg + 1\n",
    "                \n",
    "        seq_len = len(train_pos) \n",
    "        if seq_len > self.max_len:\n",
    "            seq = train_pos[-(self.max_len+1):-1]\n",
    "            pos = train_pos[-self.max_len:]\n",
    "            neg = train_neg[-self.max_len:]\n",
    "        else:\n",
    "            seq = np.zeros([self.max_len], dtype=np.int32)\n",
    "            pos = np.zeros([self.max_len], dtype=np.int32)\n",
    "            neg = np.zeros([self.max_len], dtype=np.int32)\n",
    "            seq[self.max_len-seq_len+1:] = train_pos[:-1]\n",
    "            pos[self.max_len-seq_len+1:] = train_pos[1:]\n",
    "            neg[self.max_len-seq_len+1:] = train_neg[1:]\n",
    "        \n",
    "        return (seq, pos, neg)\n",
    "    \n",
    "    def __prepareData(self):\n",
    "        for user_id, rows in tqdm(self.train_df.groupby(\"customer_id\")):\n",
    "            if self.mode == \"train\":\n",
    "                seq, pos, neg = self.__makeSeq(rows.article_id, rows.neg)\n",
    "            if self.mode == \"valid\":\n",
    "                valid = self.valid_df[self.valid_df.customer_id==user_id]\n",
    "                train_pos = np.append(rows.article_id, valid.article_id)\n",
    "                train_neg = np.append(rows.neg, valid.neg)\n",
    "                seq, pos, neg = self.__makeSeq(train_pos, train_neg)\n",
    "            if self.mode == \"test\":\n",
    "                valid = self.valid_df[self.valid_df.customer_id==user_id]\n",
    "                test = self.test_df[self.test_df.customer_id==user_id]\n",
    "                train_pos = np.append(rows.article_id,[valid.article_id, test.article_id])\n",
    "                seq, pos, neg = self.__makeSeq(train_pos, train_pos) # use seq only\n",
    "                \n",
    "            self.seq[user_id] = seq\n",
    "            self.pos[user_id] = pos\n",
    "            self.neg[user_id] = neg\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        seq = self.seq[index]\n",
    "        pos = self.pos[index]\n",
    "        neg = self.neg[index]\n",
    "        return seq, pos, neg\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make sequence data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sequence\n",
    "data_by_user = dict(list(train_data.groupby(\"customer_id\")))\n",
    "bert_train_data = {}\n",
    "bert_valid_data = {}\n",
    "bert_test_data = {}\n",
    "\n",
    "for k in tqdm(data_by_user.keys()):\n",
    "    bert_train_data[k] = data_by_user[k].article_id.reset_index(drop=True).tolist()\n",
    "    bert_valid_data[k] = bert_train_data[k] + [valid_data.iloc[k].article_id]\n",
    "    bert_test_data[k] = bert_valid_data[k] + [test_data.iloc[k].article_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_train_data, f'{data_dir}/seq_train_data.pt')\n",
    "torch.save(bert_valid_data, f'{data_dir}/bert_valid_data.pt')\n",
    "torch.save(bert_test_data, f'{data_dir}/bert_test_data.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### candidate item samplig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = np.arange(len(item2idx))\n",
    "sample_size = 1000\n",
    "candidate_items_each_user = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190977/190977 [02:01<00:00, 1578.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# HMseqDataset\n",
    "for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "    user, item = row\n",
    "    candidate_items = torch.tensor(np.append(np.random.choice(np.setdiff1d(all_items, pos_items_each_user[user]), sample_size), item))\n",
    "    candidate_items_each_user[user] = candidate_items + 1\n",
    "\n",
    "dump_pickle(candidate_items_each_user, f'{data_dir}/seq_candidate_items_each_user_small.pkl')\n",
    "# dump_json(candidate_items_each_user, f'{data_dir}/candidate_items_each_user_small.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190977/190977 [02:04<00:00, 1533.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# HMDataset\n",
    "for user, target in tqdm(test_dataset):\n",
    "    candidate_items = torch.tensor(np.append(np.random.choice(np.setdiff1d(all_items, pos_items_each_user[user]), sample_size), target))\n",
    "    candidate_items_each_user[user] = candidate_items\n",
    "\n",
    "dump_pickle(candidate_items_each_user, f'{data_dir}/candidate_items_each_user_small.pkl')\n",
    "# dump_json(candidate_items_each_user, f'{data_dir}/candidate_items_each_user_small.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data from HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "items_by_prod_type_idx.pt: 100%|██████████| 503k/503k [00:00<00:00, 15.2MB/s]\n",
      "item_with_prod_type_idx.pt: 100%|██████████| 338k/338k [00:00<00:00, 10.7MB/s]\n",
      "Fetching 13 files: 100%|██████████| 13/13 [00:01<00:00, 10.28it/s]\n"
     ]
    }
   ],
   "source": [
    "data_repo = \"sequential\"\n",
    "dataset = \"small\"\n",
    "data_version = \"458a05aeec7ef122d343834a9c5dd66f1c75b8a0\"\n",
    "\n",
    "path = (\n",
    "            snapshot_download(\n",
    "                repo_id=f\"SLKpnu/{data_repo}\",\n",
    "                repo_type=\"dataset\",\n",
    "                cache_dir=\"./data\",\n",
    "                revision=data_version,\n",
    "            )\n",
    "            + \"/\"\n",
    "            + dataset\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### category id-idx mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_with_prod_type = torch.load(f\"{path}/item_with_prod_type.pt\")\n",
    "items_by_prod_type = torch.load(f\"{path}/items_by_prod_type.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catid2idx = {v:k for k,v in enumerate(items_by_prod_type.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/sequential/small\"\n",
    "\n",
    "item_with_prod_type_idx = torch.stack([torch.tensor(catid2idx[v]) for k,v in item_with_prod_type.items()])\n",
    "items_by_prod_type_idx = {catid2idx[k]:torch.tensor(v) for k,v in items_by_prod_type.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(item_with_prod_type_idx, f'{data_dir}/item_with_prod_type_idx.pt')\n",
    "torch.save(items_by_prod_type_idx, f'{data_dir}/items_by_prod_type_idx.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gen_img_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = \"../../../image_gen/Grad_proj/dataset_fashion/embeddings/\"\n",
    "\n",
    "gen_img_emb_sep = torch.stack([torch.from_numpy(torch.load(emb_path+str(id)+\".pth\")) for id in item2idx.keys()], 0)  # n_item * 3 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen_img_emb_sep, f\"{data_dir}/gen_img_emb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload data to Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token \"your write token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "item_with_prod_type_idx.pt: 100%|██████████| 483k/483k [00:01<00:00, 461kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/SLKpnu/sequential/commit/f87d82148a32fb66f74dc2dfea9e3cf477838c91', commit_message='dataset created timestamp : 19140947', commit_description='', oid='f87d82148a32fb66f74dc2dfea9e3cf477838c91', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to Huggingface Hub\n",
    "_, _, repo, dir = data_dir.split(\"/\")\n",
    "api = HfApi()\n",
    "api.upload_folder(folder_path=data_dir, path_in_repo=dir, repo_id=f\"SLKpnu/{repo}\", \n",
    "                  commit_message=f\"dataset created timestamp : {get_timestamp()}\", repo_type=\"dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행 시간 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.random.randint 실행 시간: 6.5607867789804 초\n",
      "random.sample 실행 시간: 0.37414733300101943 초\n",
      "random.choice 실행 시간: 0.17139070699340664 초\n",
      "np.random.choice 실행 시간: 13.791083243995672 초\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def function_1(pos_list, n_item):\n",
    "    neg = np.random.randint(0, n_item, 1) \n",
    "    while neg in pos_list:\n",
    "        neg = np.random.randint(0, n_item, 1) \n",
    "    return neg\n",
    "\n",
    "def function_2(pos_list, n_item):\n",
    "    neg = random.sample(range(0,n_item), 1) \n",
    "    while neg in pos_list:\n",
    "        neg = random.sample(range(0,n_item), 1) \n",
    "    return neg\n",
    "\n",
    "def function_3(pos_list, n_item):\n",
    "    neg = random.choice(range(0,n_item)) \n",
    "    while neg in pos_list:\n",
    "        neg = random.choice(range(0,n_item)) \n",
    "    return neg\n",
    "\n",
    "def function_4(pos_list, n_item):\n",
    "    neg = np.random.choice(np.arange(n_item), 1)\n",
    "    while neg in pos_list:\n",
    "        neg =  np.random.choice(np.arange(n_item), 1)\n",
    "    return neg\n",
    "\n",
    "n_item = len(item2idx)\n",
    "pos = random.sample(range(1,n_item), 40)\n",
    "n = 115500\n",
    "\n",
    "time_1 = timeit.timeit('function_1(pos, n_item)', globals=globals(), number=n)\n",
    "time_2 = timeit.timeit('function_2(pos, n_item)', globals=globals(), number=n)\n",
    "time_3 = timeit.timeit('function_3(pos, n_item)', globals=globals(), number=n)\n",
    "time_4 = timeit.timeit('function_4(pos, n_item)', globals=globals(), number=n)\n",
    "\n",
    "print(f'np.random.randint 실행 시간: {time_1} 초')\n",
    "print(f'random.sample 실행 시간: {time_2} 초')\n",
    "print(f'random.choice 실행 시간: {time_3} 초')\n",
    "print(f'np.random.choice 실행 시간: {time_4} 초')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(pos_list, n_item):\n",
    "    neg = random.choice(range(0,n_item)) \n",
    "    while neg in pos_list:\n",
    "        neg = random.choice(range(0,n_item)) \n",
    "    return neg\n",
    "\n",
    "def function_2(pos_list, n_item):\n",
    "    pos_list = {k:1 for k in pos_list}\n",
    "    neg = random.choice(range(0,n_item)) \n",
    "    while neg in pos_list:\n",
    "        neg = random.choice(range(0,n_item)) \n",
    "    return neg\n",
    "\n",
    "n_item = len(item2idx)\n",
    "pos = random.sample(range(1,n_item), 40)\n",
    "n = 315500\n",
    "\n",
    "time_1 = timeit.timeit('function_1(pos, n_item)', globals=globals(), number=n)\n",
    "time_2 = timeit.timeit('function_2(pos, n_item)', globals=globals(), number=n)\n",
    "\n",
    "print(f'list 실행 시간: {time_1} 초')\n",
    "print(f'dict 실행 시간: {time_2} 초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(set) 실행 시간: 508.1635248339999 초\n",
      "np.setdiff1d 실행 시간: 69.18620454200027 초\n",
      "set 실행 시간: 5.8264562089998435 초\n",
      "np.arange 실행 시간: 0.028278708000470942 초\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def function_1(pos_list, all_item):\n",
    "    candicate_items = torch.tensor(list(all_item - set(pos_list)))\n",
    "\n",
    "def function_2(pos_list, all_item):\n",
    "    candicate_items = torch.tensor(np.setdiff1d(all_item, pos_list))\n",
    "   \n",
    "def function_3():\n",
    "    items_set = set(range(1,104573))\n",
    "    \n",
    "def function_4():\n",
    "    items_np = np.arange(104573, dtype=np.int32)\n",
    "    \n",
    "\n",
    "items_set = set(range(1,104573))\n",
    "items_np = np.arange(104573, dtype=np.int32)\n",
    "pos = random.sample(range(1,104573), 40)\n",
    "n1 = 74570\n",
    "n2 = 4000\n",
    "\n",
    "time_1 = timeit.timeit('function_1(pos, items_set)', globals=globals(), number=n1)\n",
    "print(f'list(set) 실행 시간: {time_1} 초')\n",
    "\n",
    "time_2 = timeit.timeit('function_2(pos, items_np)', globals=globals(), number=n1)\n",
    "print(f'np.setdiff1d 실행 시간: {time_2} 초')\n",
    "\n",
    "time_3 = timeit.timeit('function_3()', globals=globals(), number=n2)\n",
    "print(f'set 실행 시간: {time_3} 초')\n",
    "\n",
    "time_4 = timeit.timeit('function_4()', globals=globals(), number=n2)\n",
    "print(f'np.arange 실행 시간: {time_4} 초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.random.choice 실행 시간: 41.994027569977334 초\n",
      "random.sample + list 실행 시간: 174.8324626859976 초\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def function_1(pos_list, all_item):\n",
    "    candicate_items = torch.tensor(np.random.choice(np.setdiff1d(all_item, pos_list), 100))\n",
    "\n",
    "\n",
    "def function_2(pos_list, all_item):\n",
    "    candicate_items = torch.tensor(random.sample(list(np.setdiff1d(all_item, pos_list)), 100))\n",
    "    \n",
    "\n",
    "# items_set = set(range(1,104573))\n",
    "items_np = np.arange(104573, dtype=np.int32)\n",
    "pos = random.sample(range(1,104573), 40)\n",
    "n1 = 24570\n",
    "\n",
    "time_1 = timeit.timeit('function_1(pos, items_np)', globals=globals(), number=n1)\n",
    "print(f'np.random.choice 실행 시간: {time_1} 초')\n",
    "\n",
    "time_2 = timeit.timeit('function_2(pos, items_np)', globals=globals(), number=n1)\n",
    "print(f'random.sample + list 실행 시간: {time_2} 초')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60285"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "id_emb_map = load_pickle(\"id_emb_map.pkl\")\n",
    "len(id_emb_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img_emb = torch.load(r'data\\datasets--SLKpnu--sequential\\snapshots\\74651f0ea852d5628ecebb39140421ce929da218\\small\\gen_img_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60233"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2idx = torch.load(r\"data\\datasets--SLKpnu--sequential\\snapshots\\74651f0ea852d5628ecebb39140421ce929da218\\small\\item2idx.pt\")\n",
    "len(item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_img_emb = {}\n",
    "no_exist = []\n",
    "for k,v in item2idx.items():\n",
    "    try:\n",
    "        origin_img_emb[v] = id_emb_map[k]\n",
    "    except(KeyError):\n",
    "        origin_img_emb[v] = gen_img_emb[v]\n",
    "        no_exist.append((k,gen_img_emb[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60233\n",
      "[(174057028, tensor([[ 0.5001,  0.3464, -0.5843,  ..., -0.3886, -0.5194, -0.0071],\n",
      "        [ 0.3858, -0.1543, -0.4027,  ...,  0.0421,  0.2099,  0.1490],\n",
      "        [-0.1924,  0.1194, -0.0207,  ...,  0.1424,  0.5080,  0.2998]])), (179208001, tensor([[ 0.3096, -0.9084,  0.0380,  ...,  0.2732,  0.1218, -0.2119],\n",
      "        [-0.0470, -0.3921,  0.0340,  ...,  0.1654,  0.2772, -0.5624],\n",
      "        [-0.1404,  0.0206,  0.0556,  ...,  0.2461,  0.1689, -0.0915]])), (212042043, tensor([[ 0.0039,  1.5170, -1.6842,  ..., -0.2377,  0.0739,  0.3854],\n",
      "        [ 0.2138,  0.2723, -0.6957,  ...,  0.6235,  0.1133,  0.2569],\n",
      "        [ 0.1497, -0.0786, -1.3205,  ..., -0.2463,  0.0699,  0.2456]])), (212629004, tensor([[ 0.1730,  0.9818, -0.8050,  ..., -0.0032,  0.1285, -0.0640],\n",
      "        [ 0.1749,  1.3639, -0.0345,  ..., -0.1010, -0.1444,  0.2835],\n",
      "        [ 0.4589,  1.4795, -0.1282,  ..., -0.1467, -0.0974,  0.3367]])), (216961011, tensor([[-1.0157,  0.4298, -1.4339,  ...,  0.0193,  0.0056, -0.2950],\n",
      "        [-0.3336, -1.0463, -1.0392,  ...,  0.4242, -0.1073,  0.0279],\n",
      "        [-0.8392, -1.4844, -1.0258,  ...,  0.2765,  0.0615,  0.0261]])), (218354021, tensor([[ 0.0974, -0.0437, -0.3947,  ...,  0.6021, -0.1760, -0.0515],\n",
      "        [ 0.2235,  0.6490, -0.5008,  ...,  0.3419,  0.1245,  0.0181],\n",
      "        [ 0.1782, -0.1003, -0.3505,  ...,  0.3741, -0.0084,  0.2226]])), (241602023, tensor([[-0.1299,  0.0547, -1.0270,  ..., -0.4481, -0.3230,  0.3241],\n",
      "        [ 0.2348, -0.7162, -0.7401,  ..., -0.2116, -0.3861,  0.0552],\n",
      "        [ 0.4228, -0.6644, -0.4661,  ...,  0.0499, -0.2873,  0.0525]])), (272591001, tensor([[-2.2604e-01, -1.2080e-01, -1.8843e-02,  ..., -3.0939e-01,\n",
      "         -2.8597e-01, -7.6691e-02],\n",
      "        [ 3.2740e-01, -4.5179e-01,  2.1031e-01,  ...,  1.5117e-01,\n",
      "          5.0198e-01, -1.4461e-01],\n",
      "        [-2.0497e-01,  1.1530e-01, -6.6259e-01,  ...,  4.6443e-02,\n",
      "         -3.2014e-02,  3.3076e-04]])), (324963030, tensor([[-0.0764,  0.0383, -0.1780,  ..., -0.2790,  0.0272,  0.1342],\n",
      "        [ 0.1194,  0.3553,  0.5220,  ..., -0.4576,  0.0078, -0.0471],\n",
      "        [-0.2040, -0.1505, -0.3309,  ..., -0.2003,  0.1636, -0.0486]])), (357792006, tensor([[ 0.4498,  0.1985, -0.7009,  ...,  0.1109, -0.2097,  0.6677],\n",
      "        [ 0.4256,  0.8177, -0.8956,  ...,  0.1712, -0.1580,  0.6702],\n",
      "        [ 0.4724, -0.1705,  0.0152,  ...,  0.1850, -0.2428,  0.3763]])), (396135047, tensor([[ 0.4798,  0.7579,  0.2272,  ...,  0.2205,  0.3690,  0.3873],\n",
      "        [ 0.1504,  0.7473, -0.4101,  ...,  0.4424,  0.2958,  0.0199],\n",
      "        [ 0.4016,  0.7124,  0.7881,  ...,  0.4022,  0.0736,  0.4387]])), (396135048, tensor([[ 0.1483, -0.1334, -0.4379,  ...,  0.2077,  0.2472, -0.1281],\n",
      "        [ 0.2573,  0.3325,  0.0841,  ...,  0.2295, -0.1687,  0.1637],\n",
      "        [-0.0154, -0.6034, -0.0534,  ...,  0.0599, -0.0249,  0.1413]])), (408875001, tensor([[-0.1049,  0.5927, -0.5366,  ...,  0.1551,  0.3135,  0.0809],\n",
      "        [ 0.4056,  1.0184, -0.2638,  ...,  0.2225,  0.0984,  0.0488],\n",
      "        [ 0.3555, -0.0087,  0.2392,  ...,  0.2985,  0.0530,  0.0579]])), (408875002, tensor([[ 0.5521, -0.0694,  0.0216,  ...,  0.3233, -0.3847,  0.0953],\n",
      "        [ 0.3842,  0.6545,  0.1796,  ...,  0.0603,  0.0357,  0.1875],\n",
      "        [ 0.3480,  0.2444, -0.0743,  ...,  0.5709,  0.0135,  0.0104]])), (408875010, tensor([[ 0.3036,  0.6582,  0.5092,  ...,  0.6213, -0.0446,  0.0909],\n",
      "        [ 0.4632,  1.2057, -0.2267,  ..., -0.0122, -0.4586,  0.2953],\n",
      "        [ 0.5194,  0.7994, -0.2904,  ...,  0.5145, -0.5821,  0.2490]])), (411565004, tensor([[ 0.2542, -1.3319, -0.7902,  ...,  0.0419,  0.0998,  0.5408],\n",
      "        [ 0.2127,  0.6850, -0.1926,  ...,  0.0243, -0.0381,  0.4724],\n",
      "        [ 0.1362, -1.2532, -0.5884,  ...,  0.2979,  0.2479,  0.6874]])), (419634007, tensor([[ 0.1815,  0.9581,  0.6602,  ...,  0.0234, -0.0105, -0.2730],\n",
      "        [ 0.2409,  2.0405,  0.1201,  ...,  0.0300,  0.1150, -0.4581],\n",
      "        [-0.4229,  0.5036, -0.4588,  ..., -0.1811, -0.2027, -0.4920]])), (419634010, tensor([[ 0.0091,  1.2879,  0.2619,  ...,  0.2500, -0.1654,  0.0761],\n",
      "        [ 0.3744,  1.2870,  0.7800,  ...,  0.2869, -0.0602, -0.2448],\n",
      "        [-0.2308, -0.4932, -0.4684,  ...,  0.6082, -0.0926,  0.4938]])), (419634013, tensor([[ 0.3414, -0.5251, -0.3162,  ...,  0.6843, -0.0283, -0.2049],\n",
      "        [ 0.5755,  1.4987, -0.2252,  ...,  0.1010, -0.1741, -0.0866],\n",
      "        [ 0.3026,  0.9787,  0.1888,  ...,  0.4418, -0.1453, -0.2428]])), (423112004, tensor([[-0.2110,  1.8116, -0.2697,  ...,  0.0249,  0.0934, -0.0209],\n",
      "        [-0.3611,  0.6644, -0.6089,  ...,  0.0050,  0.0764, -0.0234],\n",
      "        [ 0.1947,  0.3105,  0.4888,  ...,  0.6060,  0.0505, -0.3555]])), (443262014, tensor([[ 0.0745, -0.0142, -1.2028,  ...,  0.4410,  0.3443,  0.1857],\n",
      "        [ 0.4685, -0.3525, -1.1086,  ...,  0.4258,  0.1862, -0.2258],\n",
      "        [ 0.2369, -0.7340, -1.4511,  ...,  0.0977,  0.2318,  0.0769]])), (446224011, tensor([[ 0.0573,  0.2324, -0.2325,  ..., -0.3756, -0.0018, -0.0183],\n",
      "        [ 0.4858,  1.3492, -0.2184,  ...,  0.0093, -0.1962,  0.1350],\n",
      "        [-0.2206,  1.5273,  0.0790,  ..., -0.0235,  0.2002, -0.0476]])), (446224013, tensor([[ 0.6273,  0.8912,  0.1583,  ...,  0.1249, -0.0930,  0.1318],\n",
      "        [ 0.1365,  0.7886,  0.7841,  ...,  0.2314, -0.2894,  0.1211],\n",
      "        [ 0.0672,  1.1260,  0.4724,  ..., -0.4976,  0.1047,  0.1543]])), (451380026, tensor([[ 0.0807, -1.1666,  0.6020,  ...,  0.1178, -0.2188,  0.3879],\n",
      "        [ 0.1189, -1.7998, -0.7077,  ..., -0.3011, -0.2952, -0.3358],\n",
      "        [ 0.3125, -2.1500, -0.5376,  ..., -0.2826, -0.3949, -0.4815]])), (461414009, tensor([[-0.4217,  0.9151,  0.0711,  ..., -0.1968,  0.2350, -0.5085],\n",
      "        [ 0.2263,  1.3274, -0.2049,  ..., -0.0384,  0.1907, -0.0854],\n",
      "        [-0.0340,  0.8960, -0.6335,  ..., -0.3952,  0.3147, -0.1642]])), (468666002, tensor([[ 0.1632,  0.7379, -0.5424,  ...,  0.4616,  0.1194, -0.1651],\n",
      "        [ 0.2595, -0.2798,  0.0650,  ...,  0.3318,  0.0205, -0.2247],\n",
      "        [ 0.0807, -0.2509, -0.0313,  ...,  0.1492,  0.2606, -0.5627]])), (469658014, tensor([[ 0.1493,  0.0161, -0.3024,  ...,  0.3830,  0.0812, -0.1677],\n",
      "        [ 0.3845, -0.2746, -0.3422,  ...,  0.6548, -0.1873, -0.2130],\n",
      "        [ 0.2457, -0.7092,  0.2502,  ...,  0.8096,  0.4207, -0.4379]])), (470985008, tensor([[-0.1671, -0.3999, -1.1757,  ...,  0.2006,  0.0720,  0.4434],\n",
      "        [ 0.1276,  0.7022, -0.5750,  ..., -0.3146, -0.1121,  0.3083],\n",
      "        [ 0.0331, -0.9766, -0.5870,  ...,  0.1465, -0.1552,  0.1069]])), (470985010, tensor([[ 0.2921,  0.1355, -0.9680,  ...,  0.5153,  0.2829,  0.2513],\n",
      "        [-0.3934, -1.4570, -0.2909,  ...,  0.4730,  0.0188,  0.2097],\n",
      "        [-0.1151,  0.4980, -0.9278,  ...,  0.8679,  0.2203,  0.2601]])), (480076004, tensor([[-0.1200, -0.1847,  0.2971,  ...,  0.3221,  0.4687, -0.0738],\n",
      "        [ 0.0212,  0.0784,  0.1204,  ...,  0.1439, -0.0106, -0.5756],\n",
      "        [ 0.0460, -0.2391, -0.4831,  ...,  0.1366,  0.2259, -0.2468]])), (485678032, tensor([[ 0.5689,  0.6323, -1.1621,  ...,  0.2930, -0.0988,  0.0739],\n",
      "        [ 0.7898,  0.1554, -1.1782,  ...,  0.2482, -0.2652, -0.0556],\n",
      "        [ 0.7953,  0.0034, -0.8871,  ...,  0.1263,  0.1703,  0.0362]])), (485973011, tensor([[ 0.1414,  0.3198, -0.1498,  ...,  0.3400,  0.2264,  0.0109],\n",
      "        [-0.0098,  0.0758, -0.2456,  ...,  0.0274,  0.4289, -0.2128],\n",
      "        [ 0.4296, -0.3819,  0.3944,  ...,  0.1399,  0.3640, -0.2549]])), (486639004, tensor([[-1.7694e-02, -2.9724e-01, -1.1517e-01,  ...,  4.2777e-01,\n",
      "         -8.6310e-02, -3.5961e-01],\n",
      "        [ 2.9896e-02, -6.3574e-01, -6.9081e-02,  ...,  5.4903e-01,\n",
      "         -8.8515e-03,  5.8896e-02],\n",
      "        [ 4.8405e-01, -1.8018e-01, -4.6378e-01,  ...,  1.2416e-01,\n",
      "          1.7111e-04, -2.1746e-01]])), (490473012, tensor([[ 0.2354,  0.5145, -1.1128,  ...,  0.0493,  0.7802, -0.2473],\n",
      "        [ 0.5752, -0.3385, -0.0745,  ..., -0.0721,  0.5866,  0.1358],\n",
      "        [-0.5148, -0.0854, -0.9882,  ...,  0.2536,  0.4666, -0.2488]])), (494030013, tensor([[ 0.5189,  0.4567, -0.1261,  ...,  0.0980,  0.1523,  0.3507],\n",
      "        [ 0.2863,  0.7160,  0.0336,  ...,  0.0710, -0.0742, -0.1279],\n",
      "        [ 0.4123,  0.5560,  0.3356,  ..., -0.2102,  0.2106, -0.0514]])), (496762004, tensor([[ 0.3384,  0.7955,  0.3665,  ..., -0.1495, -0.0023,  0.1308],\n",
      "        [ 0.3362,  0.5155,  0.0893,  ..., -0.1540, -0.3293, -0.0323],\n",
      "        [ 0.0026,  0.3714,  0.6990,  ...,  0.0831, -0.1819,  0.1034]])), (504152001, tensor([[-0.2251,  0.6859,  0.5355,  ..., -0.0304,  0.2687,  0.1365],\n",
      "        [ 0.2822,  0.4765,  0.5469,  ...,  0.1007,  0.2551, -0.1475],\n",
      "        [ 0.2274,  0.3369,  0.7624,  ...,  0.1897,  0.1069,  0.1901]])), (504152008, tensor([[ 0.0770,  0.9162,  0.4707,  ...,  0.2022,  0.1004, -0.3410],\n",
      "        [-0.1458, -0.1378,  0.4397,  ...,  0.0251,  0.2660, -0.0660],\n",
      "        [ 0.1368,  0.2941, -0.2964,  ...,  0.3454,  0.1325, -0.0350]])), (504960001, tensor([[ 0.5854,  0.7769, -0.3494,  ..., -0.3771,  0.3151,  0.0932],\n",
      "        [ 0.2550,  0.4747, -0.7323,  ..., -0.1413,  0.1133,  0.0890],\n",
      "        [ 0.4623,  0.6550, -0.9038,  ...,  0.1660,  0.2366,  0.0476]])), (504960003, tensor([[ 0.3896, -0.2022, -1.1904,  ...,  0.4761,  0.1213,  0.1758],\n",
      "        [ 0.7922, -0.8383, -1.1462,  ...,  0.5150,  0.2187,  0.3578],\n",
      "        [ 0.3705, -0.8693, -1.1407,  ...,  0.3125,  0.0469,  0.1341]])), (506177002, tensor([[ 0.7339,  1.2639, -0.0976,  ...,  0.1290, -0.5023,  0.3966],\n",
      "        [ 0.4093,  0.4186, -0.4616,  ...,  0.4125, -0.1570,  0.3355],\n",
      "        [ 0.3893, -1.6683,  0.6166,  ...,  0.4444,  0.1814, -0.2323]])), (512964002, tensor([[ 0.3214, -0.1858, -0.1691,  ...,  0.3931, -0.0570,  0.5056],\n",
      "        [ 0.4209, -0.7704,  0.0511,  ...,  0.2344,  0.0111,  0.4661],\n",
      "        [ 0.5625,  1.2457,  0.4194,  ...,  0.0950, -0.0182,  0.2557]])), (513701002, tensor([[ 0.0039, -0.5568, -0.7197,  ..., -0.0773, -0.0238, -0.3947],\n",
      "        [-0.1314,  0.4182, -0.9958,  ..., -0.1959, -0.0148, -0.5065],\n",
      "        [ 0.1382,  0.1098, -0.8811,  ..., -0.0652, -0.1840, -0.4386]])), (517054003, tensor([[ 0.5838, -0.2069, -0.3738,  ...,  0.2653,  0.3589,  0.1503],\n",
      "        [ 0.7373,  0.3196, -0.8391,  ...,  0.1077,  0.3177,  0.0531],\n",
      "        [ 0.6520, -0.8213, -1.2627,  ..., -0.1672,  0.1529, -0.0150]])), (519219008, tensor([[ 0.0085, -0.0558, -0.3402,  ..., -0.3673, -0.4339, -0.3681],\n",
      "        [ 0.0074,  0.3049, -0.3614,  ...,  0.4235, -0.2593, -0.0841],\n",
      "        [ 0.0371,  0.5953, -0.5127,  ...,  0.2290,  0.0247, -0.3450]])), (525111001, tensor([[ 0.1476,  0.8619,  0.1316,  ...,  0.0279, -0.0419,  0.6095],\n",
      "        [-0.1646, -0.0912, -0.1619,  ...,  0.2377, -0.0359,  0.3053],\n",
      "        [ 0.1490,  0.2484,  0.0749,  ...,  0.2294, -0.1619,  0.4095]])), (528931003, tensor([[ 0.1208,  1.3934, -0.2136,  ..., -0.1118, -0.0753,  0.0119],\n",
      "        [-0.2437,  0.7224, -0.3135,  ...,  0.0826,  0.0683, -0.0868],\n",
      "        [-0.0015,  0.9960,  0.1419,  ...,  0.3962,  0.4005,  0.4366]])), (530106001, tensor([[ 0.5766,  0.6716,  0.0728,  ...,  0.0733, -0.2164, -0.1550],\n",
      "        [ 0.2817,  0.3441, -0.7605,  ...,  0.2448,  0.0976, -0.3353],\n",
      "        [ 0.1074,  0.0228, -0.2170,  ...,  0.0084, -0.2001,  0.0332]])), (530106002, tensor([[ 0.0987,  0.8561, -1.3268,  ..., -0.0119, -0.0995, -0.3745],\n",
      "        [ 0.1668,  1.4278, -0.9406,  ...,  0.0548, -0.1383,  0.1724],\n",
      "        [ 0.3968,  0.9381, -0.5315,  ..., -0.0253, -0.0041, -0.1120]])), (537732001, tensor([[ 0.3774, -0.9101, -0.0665,  ...,  0.3336,  0.2056, -0.0548],\n",
      "        [ 0.1454, -1.0896, -0.5426,  ...,  0.3139,  0.1740, -0.2997],\n",
      "        [-0.1551,  0.5922,  0.2679,  ..., -0.1698, -0.3440, -0.2862]])), (539724003, tensor([[ 0.5734,  0.3434,  0.4344,  ...,  0.2204,  0.4478, -0.0798],\n",
      "        [ 0.2465,  0.5641,  0.5874,  ...,  0.0610,  0.4114, -0.5155],\n",
      "        [ 0.5823,  0.1922,  0.7487,  ...,  0.0410,  0.2662, -0.5101]])), (541512005, tensor([[ 0.1151, -0.1511, -0.1388,  ...,  0.6179, -0.1396, -0.1724],\n",
      "        [-0.0650, -0.6638, -0.3990,  ...,  0.4527,  0.0483, -0.2990],\n",
      "        [-0.0494, -0.7074, -0.2172,  ...,  0.4401, -0.0563, -0.2243]])), (541519005, tensor([[ 0.4336,  0.5902, -0.5823,  ...,  0.4695, -0.3881, -0.1170],\n",
      "        [ 0.0597,  0.7454,  0.0714,  ...,  0.2931, -0.2087, -0.3538],\n",
      "        [ 0.4774,  0.2418, -0.0954,  ...,  0.4983,  0.0639, -0.3219]])), (546128001, tensor([[ 0.3218,  1.3802,  0.2675,  ..., -0.1774, -0.0321,  0.2556],\n",
      "        [ 1.0086,  1.6997, -0.0494,  ...,  0.0947, -0.2866, -0.0821],\n",
      "        [ 0.3491,  0.4315, -0.7904,  ...,  0.0351, -0.3927, -0.3522]])), (546141003, tensor([[ 0.6390, -1.1020, -0.3363,  ...,  0.2488, -0.0730, -0.2545],\n",
      "        [ 0.2058,  0.0921, -0.1231,  ...,  0.2848, -0.0682, -0.2893],\n",
      "        [ 0.5352, -0.1250,  0.2107,  ...,  0.1730,  0.0351, -0.3905]])), (552471003, tensor([[ 0.0520,  1.0246, -0.0332,  ...,  0.1541,  0.2174,  0.1924],\n",
      "        [ 0.1011,  0.1893, -0.1881,  ...,  0.0232, -0.3292,  0.1238],\n",
      "        [-0.0643,  0.9448,  0.0479,  ...,  0.2088, -0.1737, -0.1944]])), (554811016, tensor([[ 0.0041,  0.1888,  0.4218,  ...,  0.3745,  0.3159, -0.3449],\n",
      "        [ 0.0135,  0.5930,  0.4103,  ...,  0.2998,  0.3041,  0.0081],\n",
      "        [-0.0175,  0.0532,  0.7685,  ...,  0.2583,  0.2140,  0.0174]])), (554811018, tensor([[-0.1243,  1.1009,  0.1404,  ..., -0.1926,  0.1715,  0.0207],\n",
      "        [ 0.2100,  1.2851,  0.4667,  ..., -0.2334,  0.6172,  0.0308],\n",
      "        [ 0.0312,  0.8330,  0.2186,  ...,  0.0511,  0.0504, -0.0816]])), (554811019, tensor([[ 0.0249,  0.3675,  0.2645,  ...,  0.1774,  0.0212, -0.1517],\n",
      "        [ 0.3438, -0.2737,  0.1173,  ...,  0.1702,  0.2662, -0.1749],\n",
      "        [ 0.8210,  1.5532,  0.1999,  ..., -0.0128,  0.3040,  0.0942]])), (559529001, tensor([[ 0.4995,  1.5542,  0.2065,  ..., -0.0067, -0.0911, -0.1091],\n",
      "        [ 0.1079,  0.0320,  0.2939,  ...,  0.1829, -0.1754, -0.2614],\n",
      "        [ 0.5574,  0.7132,  0.0721,  ...,  0.1513,  0.2423, -0.3138]])), (561303001, tensor([[ 0.3789,  0.2107, -0.6587,  ..., -0.2698,  0.3601,  0.4355],\n",
      "        [ 0.2126, -0.6372,  0.0514,  ..., -0.3046,  0.2919,  0.3423],\n",
      "        [ 0.0681,  0.3273, -0.3193,  ..., -0.1789,  0.2032, -0.1998]])), (562092002, tensor([[ 0.0367,  1.0688, -0.1310,  ...,  0.1295,  0.5812,  0.0900],\n",
      "        [ 0.1679,  1.2263, -0.3418,  ...,  0.1042,  0.2681,  0.0624],\n",
      "        [ 0.0247,  0.6234,  0.1707,  ...,  0.1547,  0.1434, -0.2248]])), (562298002, tensor([[ 0.5219,  0.1648, -0.3362,  ..., -0.0071, -0.0236,  0.0991],\n",
      "        [-0.5665, -0.0672, -0.7833,  ...,  0.3710, -0.0245, -0.1680],\n",
      "        [ 0.1866, -0.2508, -0.4213,  ...,  0.2661, -0.2862,  0.0324]])), (564326003, tensor([[-0.3707, -1.2474, -0.9605,  ...,  0.1064, -0.0087,  0.2856],\n",
      "        [ 0.1381, -1.4457,  0.1337,  ..., -0.1022, -0.1045,  0.3804],\n",
      "        [-0.2746,  0.1432, -0.6173,  ...,  0.3988, -0.0981,  0.0409]])), (565533001, tensor([[ 0.2011,  0.9653, -0.1515,  ...,  0.3086, -0.0505, -0.4878],\n",
      "        [ 0.1452,  1.0725, -0.0534,  ...,  0.0160, -0.3566, -0.0914],\n",
      "        [ 0.4830,  1.0750, -0.4324,  ...,  0.2895, -0.0626, -0.4342]])), (566289001, tensor([[ 0.7905, -0.1280, -1.0643,  ...,  0.0538,  0.1370,  0.4624],\n",
      "        [ 0.7605, -0.3256, -0.8723,  ...,  0.2253,  0.3686,  0.4347],\n",
      "        [ 0.7701,  0.8447, -1.7566,  ...,  0.1478, -0.1763,  0.5815]])), (566432003, tensor([[ 0.0486, -0.6794, -0.6815,  ...,  0.5101, -0.0233, -0.2317],\n",
      "        [ 0.0268, -0.3650, -0.3688,  ...,  0.1736,  0.2066, -0.2396],\n",
      "        [ 0.1585,  0.2317, -0.3990,  ...,  0.4555,  0.1793,  0.1254]])), (568020001, tensor([[ 0.2629, -0.0604, -0.1284,  ...,  0.5614,  0.2044, -0.3990],\n",
      "        [ 0.2920, -0.1912,  0.0030,  ...,  0.4584, -0.0278, -0.3009],\n",
      "        [ 0.1211, -0.3907,  0.5951,  ...,  0.2292,  0.0374, -0.3386]])), (570144002, tensor([[ 0.0294,  0.6869, -0.0168,  ...,  0.5151, -0.1672, -0.6411],\n",
      "        [ 0.3403,  0.6013,  0.0494,  ...,  0.3964, -0.2845, -0.4359],\n",
      "        [-0.0158,  0.8131, -0.1614,  ...,  0.0075, -0.0346, -0.5398]])), (571041001, tensor([[ 0.0076,  1.2073, -0.3107,  ..., -0.0618, -0.0608, -0.4924],\n",
      "        [ 0.1108,  0.2325,  0.1583,  ...,  0.4891, -0.0297, -0.1885],\n",
      "        [ 0.0013,  0.6846,  0.1943,  ...,  0.2718, -0.2330, -0.2100]])), (571982012, tensor([[-0.2586, -0.7036, -1.0243,  ...,  0.3653,  0.1855,  0.0426],\n",
      "        [-0.5854, -0.3589, -0.6382,  ...,  0.4637, -0.1022,  0.5363],\n",
      "        [-0.5772,  0.5593, -0.7926,  ...,  0.3391, -0.3567,  0.4474]])), (573152009, tensor([[ 0.4022, -1.0574, -0.1887,  ...,  0.0173,  0.5636, -0.3220],\n",
      "        [ 0.1091, -0.4609,  0.2574,  ..., -0.0112,  0.1775, -0.0540],\n",
      "        [ 0.0977, -0.1548, -0.5552,  ..., -0.0346, -0.0034, -0.2510]])), (574528007, tensor([[-0.0856, -0.6696, -0.9664,  ..., -0.2711, -0.3491, -0.0906],\n",
      "        [ 0.0849, -1.2570, -0.4222,  ..., -0.1203, -0.2352, -0.2213],\n",
      "        [ 0.0521, -1.0715, -0.5373,  ..., -0.0353, -0.0875, -0.1253]])), (574528008, tensor([[-0.2504,  0.3999, -0.5530,  ..., -0.0894, -0.3057, -0.1193],\n",
      "        [-0.4284, -0.7790, -0.4101,  ..., -0.2143,  0.1429,  0.1301],\n",
      "        [-0.2269, -0.4004, -0.2333,  ..., -0.0624, -0.0710, -0.0564]])), (574750001, tensor([[-0.1676,  1.0428, -0.1690,  ..., -0.3798,  0.3098, -0.1229],\n",
      "        [-0.0763, -0.0814,  0.1670,  ...,  0.2240,  0.4835, -0.0091],\n",
      "        [-0.4706,  0.8927, -0.1854,  ...,  0.2478,  0.1237, -0.2142]])), (576812001, tensor([[ 0.5162,  1.6890, -1.1680,  ...,  0.5742, -0.5683, -0.0599],\n",
      "        [ 0.2594,  1.6814, -0.7204,  ...,  0.6662,  0.0637,  0.0213],\n",
      "        [ 0.0570,  2.0267, -1.0448,  ...,  0.3872, -0.4858,  0.3608]])), (578816002, tensor([[ 0.1248,  0.3645, -0.3018,  ...,  0.4014,  0.6730, -0.0708],\n",
      "        [ 0.3425, -1.3790, -0.3020,  ...,  0.3694,  0.2457,  0.2565],\n",
      "        [ 0.2075, -0.0811, -0.0711,  ...,  0.0708,  0.7156,  0.3811]])), (578816004, tensor([[ 0.0920, -0.0258, -0.1313,  ...,  0.2209,  0.3873,  0.1151],\n",
      "        [-0.1493,  0.3737, -1.2405,  ..., -0.0121,  0.3237, -0.1857],\n",
      "        [ 0.1070,  0.7068, -0.4987,  ...,  0.4706,  0.3897,  0.0437]])), (579118002, tensor([[ 0.6733,  0.1871, -0.3207,  ...,  0.2179,  0.4932,  0.1954],\n",
      "        [ 0.3068, -0.5394, -0.5783,  ..., -0.0904,  0.5885,  0.0632],\n",
      "        [ 0.1515, -0.8289, -0.6971,  ..., -0.1664,  0.4531,  0.3210]])), (580140001, tensor([[ 1.4784e-01, -1.6158e-01, -1.2414e-01,  ...,  3.7823e-01,\n",
      "         -4.8078e-03, -4.8476e-02],\n",
      "        [ 2.5793e-01, -3.4862e-01, -1.4640e+00,  ...,  7.2386e-02,\n",
      "         -1.0636e-01, -1.2665e-03],\n",
      "        [ 3.9392e-01, -5.1431e-01, -1.0832e+00,  ...,  9.4000e-02,\n",
      "         -1.5088e-01,  1.3925e-01]])), (580475001, tensor([[-0.0779,  1.2160, -0.0285,  ..., -0.1940,  0.3159, -0.1694],\n",
      "        [-0.2360,  0.2043,  0.0565,  ...,  0.1588,  0.4217, -0.0614],\n",
      "        [ 0.3447,  0.9206, -0.8003,  ..., -0.1867,  0.2827, -0.4493]])), (580526003, tensor([[-0.0901, -0.2256, -0.4537,  ..., -0.1501,  0.1226,  0.4758],\n",
      "        [-0.3297,  0.3151, -1.1285,  ...,  0.2266,  0.1899,  0.2937],\n",
      "        [-0.4381, -0.4301, -1.0092,  ...,  0.1696,  0.4827,  0.3850]])), (581103004, tensor([[-0.1878,  1.3331, -0.1067,  ..., -0.1034,  0.0935,  0.1269],\n",
      "        [ 0.5631,  0.4071, -0.4534,  ...,  0.0275,  0.0820, -0.1784],\n",
      "        [ 0.1329,  1.4521, -0.5844,  ..., -0.2076,  0.1819, -0.3847]])), (581162001, tensor([[ 0.0267,  0.8892, -0.3493,  ...,  0.0454, -0.0549, -0.3112],\n",
      "        [ 0.6934, -0.0218, -0.1854,  ...,  0.0510, -0.2363,  0.0842],\n",
      "        [-0.0288,  0.3231, -0.2155,  ...,  0.3594, -0.6634, -0.5498]])), (583084003, tensor([[-0.0307,  0.3718, -0.2434,  ...,  0.3925, -0.0416,  0.2791],\n",
      "        [ 0.0824, -0.2678, -0.1972,  ..., -0.0572,  0.4033,  0.2418],\n",
      "        [ 0.4389, -0.7701, -0.5499,  ...,  0.0499,  0.1837,  0.1831]])), (583362001, tensor([[-0.0723,  0.8783, -0.3418,  ...,  0.6947, -0.1086,  0.2836],\n",
      "        [ 0.1488,  1.1847, -0.8523,  ...,  0.1569, -0.1536, -0.1323],\n",
      "        [ 0.1063,  1.5496, -0.9826,  ...,  0.5774, -0.4015,  0.3437]])), (583362002, tensor([[ 0.4685,  1.5608, -0.2528,  ...,  0.1520, -0.2475,  0.0648],\n",
      "        [-0.2108,  1.8229, -0.6280,  ...,  0.5671, -0.2676,  0.2674],\n",
      "        [-0.1027,  1.3482,  0.0886,  ...,  0.6806, -0.1915, -0.0063]])), (583983001, tensor([[ 0.0723,  0.3719, -0.5195,  ...,  0.4769,  0.1268, -0.0322],\n",
      "        [-0.2270,  0.1001, -0.5262,  ...,  0.3840,  0.1505, -0.3253],\n",
      "        [ 0.0190, -0.4743, -0.6241,  ...,  0.6690, -0.1213, -0.1585]])), (585809001, tensor([[-0.1455,  0.3395, -1.1135,  ..., -0.1036,  0.1437, -0.0484],\n",
      "        [-0.1460, -0.4000, -0.4283,  ..., -0.0331, -0.0623, -0.5453],\n",
      "        [-0.1363,  0.2732, -1.6798,  ...,  0.0693,  0.2541, -0.1810]])), (585809002, tensor([[ 0.5796,  0.0412, -0.7932,  ..., -0.0743,  0.1498,  0.1054],\n",
      "        [ 0.3999,  0.3912, -0.7975,  ..., -0.1666, -0.1168, -0.3823],\n",
      "        [ 0.3881,  0.7647, -0.9046,  ...,  0.1798,  0.3612, -0.1246]])), (588893001, tensor([[ 0.1693,  0.2210, -1.1762,  ...,  0.1051, -0.0311, -0.1379],\n",
      "        [ 0.2435,  0.6274, -1.2865,  ..., -0.0064,  0.1331,  0.3037],\n",
      "        [ 0.0392, -0.1029, -1.7475,  ...,  0.2716, -0.2763, -0.0629]])), (590560001, tensor([[-0.1830,  0.0632, -0.3464,  ...,  0.4855, -0.3685, -0.3131],\n",
      "        [ 0.0442,  0.0821, -0.5687,  ...,  0.2890, -0.1876, -0.3401],\n",
      "        [-0.1144,  0.1635,  0.1201,  ...,  0.5958,  0.0925, -0.1441]])), (592415003, tensor([[-0.1143, -0.0677,  0.3508,  ..., -0.1333, -0.1533, -0.1327],\n",
      "        [ 0.1023,  0.8572, -0.1464,  ..., -0.0469, -0.0993, -0.4005],\n",
      "        [ 0.4412, -0.4186,  0.6523,  ..., -0.2437, -0.2538, -0.0420]])), (594167001, tensor([[-0.4997,  1.6279, -0.6497,  ..., -0.4242,  0.1531, -0.3949],\n",
      "        [ 0.0163,  0.0845, -0.7533,  ..., -0.2699,  0.6645, -0.4256],\n",
      "        [-0.5433, -0.5221, -0.8827,  ..., -0.6481,  0.4420, -0.2222]])), (594177003, tensor([[ 0.2583,  0.0324, -0.4290,  ...,  0.2928,  0.0780,  0.3522],\n",
      "        [ 0.1793, -0.5894, -0.6720,  ..., -0.0838,  0.6633,  0.4415],\n",
      "        [ 0.7857, -0.1413, -0.4194,  ...,  0.0345,  0.4387,  0.2454]])), (594630001, tensor([[ 0.0488,  0.2458, -1.0411,  ..., -0.1473, -0.3468,  0.2757],\n",
      "        [ 0.7398,  0.8523, -1.4688,  ...,  0.4422,  0.0317,  0.4065],\n",
      "        [ 0.4490,  1.9368, -0.6349,  ...,  0.3732, -0.2811,  0.0931]])), (594630002, tensor([[ 0.6891,  1.9091, -0.3453,  ...,  0.5930, -0.2026,  0.0274],\n",
      "        [ 0.5544,  0.6799, -1.2483,  ...,  0.2787, -0.1117,  0.3605],\n",
      "        [ 1.1786,  0.6141, -1.0544,  ...,  0.4259, -0.1036,  0.4940]])), (595196003, tensor([[ 3.3438e-04,  9.8232e-01,  4.3699e-03,  ..., -5.4544e-01,\n",
      "          6.7013e-02, -3.9722e-01],\n",
      "        [ 6.7826e-02, -2.8587e-01, -7.0099e-02,  ..., -3.7356e-02,\n",
      "         -1.6544e-01,  1.4488e-02],\n",
      "        [ 2.0777e-01,  2.3658e-01, -5.0005e-01,  ..., -4.7326e-04,\n",
      "          2.0796e-01,  4.1629e-02]])), (595718002, tensor([[ 0.2853,  0.5142, -0.0184,  ...,  0.2091, -0.2167,  0.4889],\n",
      "        [ 0.5318,  1.0111, -0.5599,  ...,  0.5604, -0.2967,  0.7492],\n",
      "        [ 0.7663,  1.0811, -0.6594,  ...,  0.1366, -0.0766,  0.7906]])), (596877001, tensor([[-0.3099, -1.5242,  0.1308,  ...,  0.7517,  0.1064, -0.3148],\n",
      "        [-0.0954, -0.8651, -0.4031,  ...,  0.7752,  0.2575, -0.4650],\n",
      "        [-0.3028, -0.6460, -0.1672,  ...,  0.8614,  0.2229, -0.4039]])), (597420001, tensor([[ 0.4542, -0.1873, -0.8989,  ...,  0.2170,  0.2747,  0.1053],\n",
      "        [ 0.9163, -0.1048, -1.1329,  ...,  0.0397, -0.0079,  0.5101],\n",
      "        [ 0.2056, -0.2605, -0.7508,  ...,  0.4707,  0.2571,  0.3159]])), (598397002, tensor([[ 0.3165, -0.4576, -1.3038,  ...,  0.3153,  0.0781,  0.3596],\n",
      "        [ 0.6089,  0.4882, -0.9293,  ...,  0.4201,  0.0083,  0.7117],\n",
      "        [ 0.3576,  0.5061, -0.7759,  ..., -0.3302,  0.2139,  0.5837]])), (598397003, tensor([[ 0.1274, -0.4685, -0.8503,  ...,  0.4995,  0.1013,  0.3426],\n",
      "        [-0.1611,  1.0340, -0.6113,  ...,  0.3803, -0.1991,  0.2603],\n",
      "        [-0.0321, -0.0570, -0.7886,  ...,  0.8370,  0.3539,  0.1454]])), (599375001, tensor([[ 0.2338,  0.9506, -0.4211,  ...,  0.2424,  0.0106,  0.4478],\n",
      "        [ 0.3667,  0.4735, -0.3303,  ...,  0.3361,  0.0185,  0.6867],\n",
      "        [ 0.6917,  1.4182, -0.7070,  ...,  0.2627, -0.0079,  0.7698]])), (600441002, tensor([[ 0.5315, -0.6897, -1.0454,  ..., -0.3235, -0.0115, -0.3241],\n",
      "        [-0.1484, -0.8151,  0.2143,  ...,  0.0266,  0.5588,  0.1846],\n",
      "        [ 0.2793, -0.2944, -0.4734,  ..., -0.0799,  0.0856, -0.3711]])), (603582003, tensor([[-0.1826, -0.8855, -0.8218,  ...,  0.4299,  0.0314, -0.1645],\n",
      "        [-0.2482, -0.3274, -0.3125,  ...,  0.0096, -0.0957, -0.1505],\n",
      "        [ 0.0865, -0.3850, -0.4056,  ...,  0.4166, -0.3666, -0.2697]])), (603582004, tensor([[-0.3873,  0.6117, -1.0019,  ...,  0.3350, -0.2699,  0.2406],\n",
      "        [-0.3537, -0.7344, -0.4543,  ...,  0.3731, -0.1565,  0.2345],\n",
      "        [-0.1505, -0.6176, -0.6068,  ...,  0.5378, -0.5415, -0.0772]])), (603583006, tensor([[ 0.1495, -0.6744, -0.4074,  ...,  0.2645, -0.4063, -0.2312],\n",
      "        [ 0.1077, -0.8240, -0.0054,  ..., -0.0920, -0.2949, -0.3129],\n",
      "        [ 0.0790, -0.1877, -0.7802,  ...,  0.0599, -0.3412,  0.0690]])), (604875002, tensor([[ 0.1572, -0.2468, -0.0844,  ...,  0.3591, -0.1775,  0.1916],\n",
      "        [-0.0232,  0.2746, -0.4152,  ...,  0.1730, -0.3990,  0.3475],\n",
      "        [ 0.2853,  0.3692, -0.1008,  ...,  0.2026, -0.3711,  0.7811]])), (607390001, tensor([[-0.0661, -0.1182,  0.0314,  ...,  0.3135,  0.3198, -0.1371],\n",
      "        [-0.1355,  0.0668, -0.6269,  ...,  0.2711,  0.5130,  0.1011],\n",
      "        [ 0.1636, -0.1429, -0.1410,  ...,  0.4120,  0.2375, -0.1398]])), (607503001, tensor([[ 0.7397, -0.7766, -1.1494,  ..., -0.1887, -0.2945,  0.1039],\n",
      "        [ 0.4219, -1.2187, -0.6610,  ..., -0.0468, -0.3033, -0.3173],\n",
      "        [ 0.1107, -1.6038, -1.0038,  ..., -0.1348, -0.1520, -0.1931]])), (607554001, tensor([[ 0.3485, -0.5011, -0.6828,  ...,  0.5474, -0.2179,  0.3055],\n",
      "        [-0.1778, -0.3461, -0.2001,  ...,  0.3178,  0.2552,  0.3856],\n",
      "        [ 0.4120,  1.0945, -0.9971,  ...,  0.0185,  0.1261,  0.0572]])), (608347001, tensor([[ 0.2300, -0.8620, -1.0818,  ...,  0.1593,  0.1679,  0.4181],\n",
      "        [ 0.2741,  0.3310, -0.7550,  ...,  0.3733, -0.2540,  0.6733],\n",
      "        [-0.1712,  0.6389, -0.6702,  ...,  0.3366,  0.2838,  0.2511]])), (609309001, tensor([[ 0.1427,  1.0484, -0.6436,  ...,  0.7574, -0.3598,  0.1281],\n",
      "        [ 0.0551,  1.5807, -0.9681,  ...,  0.6575, -0.0480,  0.3891],\n",
      "        [ 0.2501,  2.0272, -1.4971,  ...,  0.6264, -0.1577,  0.1001]])), (609598002, tensor([[ 0.0523,  0.6271, -0.3659,  ...,  0.2003, -0.1735,  0.0472],\n",
      "        [ 0.1080,  0.8725, -0.3385,  ...,  0.2451,  0.2928,  0.0238],\n",
      "        [ 0.2829,  0.4498, -0.0098,  ..., -0.1034,  0.0924,  0.3372]])), (610107001, tensor([[-0.0640,  1.1109, -1.0885,  ...,  0.1398, -0.3159, -0.2110],\n",
      "        [ 0.1369,  0.4234, -1.4662,  ...,  0.4023,  0.1044, -0.2561],\n",
      "        [ 0.4846, -0.2240, -0.4067,  ...,  0.6035, -0.2545,  0.2894]])), (610776001, tensor([[-0.0263,  0.6401, -0.8193,  ..., -0.1158,  0.2274, -0.0678],\n",
      "        [-0.0103,  0.4351, -0.5449,  ..., -0.1637,  0.1396, -0.1323],\n",
      "        [ 0.1684, -0.7809, -0.7285,  ..., -0.0127, -0.0360, -0.0147]])), (610776002, tensor([[ 0.4213, -0.2045, -0.2787,  ...,  0.0976, -0.1073,  0.0016],\n",
      "        [ 0.4390,  0.1565, -0.6059,  ...,  0.2994, -0.0304, -0.2347],\n",
      "        [ 0.7637, -0.8402, -0.3730,  ...,  0.4289,  0.1995,  0.0123]])), (612075001, tensor([[ 0.2782,  0.2026,  0.3358,  ...,  0.0985,  0.3927,  0.2038],\n",
      "        [ 0.6217,  0.5298, -0.2641,  ...,  0.0141, -0.3655, -0.0307],\n",
      "        [ 0.4290, -0.5626,  0.3079,  ..., -0.0023,  0.1769, -0.0093]])), (612075002, tensor([[ 0.3624, -0.1304, -0.0391,  ...,  0.0907, -0.1245,  0.1008],\n",
      "        [ 0.8512,  0.0028,  0.3299,  ..., -0.0096,  0.3706,  0.1413],\n",
      "        [ 0.1956,  0.6242,  0.2389,  ..., -0.0192,  0.4012,  0.6648]])), (612075004, tensor([[ 0.3283,  0.4890,  0.0314,  ...,  0.0030,  0.4012, -0.0925],\n",
      "        [ 0.1682, -0.3925,  0.2998,  ...,  0.0016,  0.0231, -0.0406],\n",
      "        [ 0.1986, -0.3500,  1.1691,  ..., -0.0957,  0.3995,  0.1158]])), (612277001, tensor([[ 0.3519,  1.0460, -0.5326,  ...,  0.1574, -0.3410,  0.1581],\n",
      "        [ 0.2334,  0.2857,  0.0454,  ...,  0.3998, -0.2828,  0.0534],\n",
      "        [ 0.0553,  1.2034, -0.4295,  ...,  0.2900,  0.0350,  0.1025]])), (613274001, tensor([[ 0.2999, -0.2427, -0.2973,  ...,  0.1343,  0.3588,  0.0940],\n",
      "        [ 0.2319, -0.0622, -0.0380,  ...,  0.0106,  0.5000, -0.1761],\n",
      "        [ 0.1116, -0.0602, -0.9902,  ...,  0.2788, -0.1068, -0.0117]])), (615508001, tensor([[-0.1753,  0.6963,  0.0510,  ...,  0.0436,  0.2887, -0.4729],\n",
      "        [-0.2493,  0.7960,  0.1292,  ...,  0.1990, -0.1281, -0.0215],\n",
      "        [-0.1969,  1.4304, -0.8988,  ..., -0.5117, -0.1567, -0.3006]])), (617534007, tensor([[ 0.1522,  0.2694, -0.0452,  ...,  0.3665,  0.1873, -0.1242],\n",
      "        [ 0.0027, -0.7973,  0.2724,  ...,  0.0434,  0.2528, -0.2180],\n",
      "        [ 0.0184,  0.0180, -0.0958,  ...,  0.0846,  0.3489, -0.1232]])), (618160001, tensor([[-0.0568,  0.3284,  0.3599,  ..., -0.1812,  0.4659, -0.4341],\n",
      "        [-0.3567,  0.5679,  0.6543,  ..., -0.1009,  0.3813, -0.3340],\n",
      "        [ 0.2151,  0.1033, -0.3002,  ..., -0.4114,  0.4610, -0.1249]])), (618160002, tensor([[-0.7754, -0.2676,  0.4350,  ...,  0.1827,  0.0950, -0.6460],\n",
      "        [ 0.0101,  0.3675, -0.4199,  ..., -0.2353,  0.2175, -0.5170],\n",
      "        [ 0.0741,  0.4426,  0.0866,  ..., -0.0034,  0.3574, -0.3591]])), (619190001, tensor([[ 0.0865, -0.5737,  0.5531,  ...,  0.7034,  0.3544,  0.4009],\n",
      "        [ 0.4469,  0.1159,  0.6989,  ...,  0.2809,  0.0995,  0.5779],\n",
      "        [ 0.6591,  0.2590, -0.5832,  ...,  0.3048,  0.1682,  0.5164]])), (619553002, tensor([[ 0.1748, -0.2013,  0.2057,  ...,  0.4045, -0.2525,  0.3539],\n",
      "        [-0.1608,  0.6962,  0.4079,  ...,  0.1187,  0.3158,  0.2883],\n",
      "        [ 0.0347, -0.1745, -0.1723,  ...,  0.1180, -0.3793,  0.3114]])), (620216021, tensor([[ 0.0236,  0.1565,  0.2485,  ...,  0.2233,  0.3178, -0.4772],\n",
      "        [ 0.0910,  0.7607, -0.3174,  ...,  0.5561,  0.0079, -0.2099],\n",
      "        [ 0.1397, -0.1300, -0.2374,  ...,  0.6827,  0.2815, -0.1273]])), (620319007, tensor([[ 0.5050,  0.3263, -0.6361,  ...,  0.2889, -0.1313,  0.4130],\n",
      "        [ 0.1809, -0.4335, -0.8312,  ...,  0.3764,  0.0804,  0.5700],\n",
      "        [ 0.5226,  0.0631, -1.2122,  ..., -0.0599, -0.1613,  0.6365]])), (620319011, tensor([[ 1.1483e-01, -1.7429e+00, -2.2482e-01,  ...,  5.3966e-01,\n",
      "         -3.0685e-01,  1.3588e-01],\n",
      "        [ 7.5241e-01,  1.9149e-01, -9.3539e-01,  ...,  6.0251e-01,\n",
      "         -7.4536e-04,  2.4108e-01],\n",
      "        [ 2.9693e-01, -1.0694e+00, -6.8320e-01,  ...,  5.9889e-01,\n",
      "         -1.6519e-01,  3.5605e-01]])), (620585007, tensor([[-4.3753e-02, -3.2343e-01, -2.9007e-01,  ...,  2.7420e-01,\n",
      "          3.5665e-01,  4.2768e-02],\n",
      "        [-4.3711e-01, -2.6530e-01, -3.0524e-01,  ..., -3.6997e-01,\n",
      "          3.4286e-01, -3.1028e-01],\n",
      "        [-6.4611e-05, -4.1014e-02, -3.1168e-01,  ...,  2.9352e-01,\n",
      "          2.1369e-01, -9.3831e-02]])), (620754001, tensor([[-0.3276,  0.9584, -0.3485,  ...,  0.1057, -0.4059, -0.2854],\n",
      "        [-0.0300,  0.4454, -0.7796,  ...,  0.3058, -0.2593, -0.1589],\n",
      "        [-0.3751,  0.7421, -0.5918,  ...,  0.2009, -0.1037, -0.0249]])), (626263002, tensor([[-0.1834,  0.5524,  0.0645,  ..., -0.0744,  0.2023, -0.2263],\n",
      "        [ 0.3588, -0.6466,  0.3502,  ...,  0.1016,  0.1925, -0.2889],\n",
      "        [-0.1188, -0.5070,  0.7485,  ...,  0.2911,  0.1192, -0.1683]])), (629381001, tensor([[ 0.6164, -0.0428,  0.1687,  ...,  0.3299,  0.2771,  0.1350],\n",
      "        [ 0.2485,  1.2680,  0.2281,  ..., -0.0119,  0.1102,  0.2096],\n",
      "        [ 0.6071,  0.9065,  0.4917,  ...,  0.4134,  0.0768, -0.3069]])), (629381002, tensor([[ 0.0186,  0.4361,  0.5027,  ...,  0.0489,  0.1330, -0.2875],\n",
      "        [ 0.1233,  0.3895,  0.2556,  ...,  0.4950, -0.0592, -0.2740],\n",
      "        [ 0.0968,  1.2376, -0.0804,  ...,  0.2547,  0.2084, -0.2318]])), (629381004, tensor([[ 0.0270,  0.9025,  0.6054,  ...,  0.1557,  0.1837,  0.1461],\n",
      "        [ 0.1497,  0.3352, -0.4434,  ...,  0.2581, -0.0461,  0.0961],\n",
      "        [ 0.3237, -0.2431,  0.1840,  ...,  0.5893,  0.1484,  0.1187]])), (630319001, tensor([[-0.0557,  0.3979, -0.3811,  ..., -0.1760,  0.0873,  0.3680],\n",
      "        [ 0.4575,  0.4430,  0.1951,  ...,  0.4042,  0.1428,  0.3535],\n",
      "        [ 0.4936,  0.4395,  0.3170,  ...,  0.1525,  0.1515,  0.0399]])), (630319004, tensor([[ 0.3637,  1.0138, -0.7804,  ...,  0.1272,  0.3374,  0.1217],\n",
      "        [ 0.4502,  0.6449, -0.3422,  ...,  0.3870,  0.2883, -0.1531],\n",
      "        [ 0.2588,  0.4178, -0.2813,  ...,  0.0908, -0.1600,  0.1631]])), (630324001, tensor([[ 0.2622, -0.0319,  0.0985,  ...,  0.1941,  0.5105, -0.0534],\n",
      "        [ 0.3875,  0.6175, -0.1222,  ..., -0.0603,  0.5531,  0.2265],\n",
      "        [ 0.1800, -0.0216,  0.0607,  ...,  0.1990, -0.0280,  0.0617]])), (630326003, tensor([[ 0.4772,  0.2048, -0.7526,  ..., -0.2251, -0.0177, -0.1040],\n",
      "        [ 0.3296,  0.0278, -1.2476,  ...,  0.1517, -0.0044, -0.1567],\n",
      "        [ 0.0611,  0.3139, -0.2147,  ..., -0.1682, -0.0132, -0.3009]])), (630326004, tensor([[-0.0987, -0.0233, -0.6452,  ..., -0.1796,  0.0646, -0.4506],\n",
      "        [ 0.3412, -0.5084, -0.3580,  ...,  0.2257, -0.0676, -0.6107],\n",
      "        [-0.0918, -0.0597, -1.0079,  ..., -0.1504,  0.0623, -0.5489]])), (632642003, tensor([[ 0.3098,  1.5375, -0.6959,  ..., -0.0888,  0.1948,  0.0055],\n",
      "        [-0.1316,  0.7922, -0.5867,  ...,  0.2418,  0.3472,  0.2057],\n",
      "        [-0.0382,  0.1885, -0.8303,  ..., -0.0330,  0.3064,  0.4629]])), (634160002, tensor([[ 0.3545,  0.8145,  0.0246,  ...,  0.0641,  0.1993, -0.0688],\n",
      "        [ 0.4866,  0.6601,  0.0595,  ..., -0.0031,  0.1429,  0.1309],\n",
      "        [-0.0271,  0.6743, -0.2698,  ...,  0.2254,  0.4732,  0.2057]])), (634160004, tensor([[ 0.0588,  0.9109, -0.3033,  ...,  0.1958,  0.0497,  0.1701],\n",
      "        [ 0.2620,  0.9968,  0.6380,  ...,  0.0618, -0.1416,  0.1875],\n",
      "        [ 0.1901,  0.5137, -0.1802,  ...,  0.2652,  0.3986, -0.2702]])), (639404001, tensor([[ 0.2954,  0.4242, -0.4765,  ...,  0.4914, -0.0641,  0.5016],\n",
      "        [ 0.2319, -0.6255, -0.1012,  ...,  0.5271, -0.0083,  0.5468],\n",
      "        [ 0.3168,  1.0757, -0.0898,  ...,  0.3629, -0.1170,  0.5781]])), (642390001, tensor([[ 0.2659,  0.1344,  0.0091,  ..., -0.1104,  0.1356,  0.3434],\n",
      "        [-0.1037,  0.0659, -0.5973,  ...,  0.2325, -0.1661, -0.0610],\n",
      "        [ 0.3221,  0.2103,  0.2604,  ...,  0.3338,  0.2786,  0.0771]])), (645754002, tensor([[-0.1748,  0.7144,  0.0776,  ...,  0.4727,  0.0738,  0.2600],\n",
      "        [-0.4590,  0.8854, -0.0530,  ...,  0.3021, -0.3243,  0.1828],\n",
      "        [-0.3493,  0.6084,  0.2183,  ...,  0.5194, -0.1744,  0.0129]])), (653814001, tensor([[ 0.0151,  0.8544, -1.8292,  ..., -0.2948,  0.0293, -0.1938],\n",
      "        [ 0.3335,  0.2684, -1.0548,  ..., -0.1749, -0.1387,  0.0439],\n",
      "        [ 0.2251, -0.0881, -1.5996,  ..., -0.3271,  0.2516,  0.1511]])), (660315002, tensor([[ 0.0564,  1.9149, -0.5131,  ..., -0.0839, -0.1398,  0.0491],\n",
      "        [ 0.0820,  1.6158, -0.8648,  ..., -0.0729,  0.0803,  0.2030],\n",
      "        [ 0.4693,  1.1602, -0.9289,  ..., -0.1444,  0.2232,  0.2126]])), (667040001, tensor([[ 0.0284,  0.6630,  0.1518,  ...,  0.1210, -0.0628,  0.1343],\n",
      "        [-0.0083,  0.7816,  0.1119,  ...,  0.0250,  0.0125, -0.0734],\n",
      "        [ 0.1048,  1.0474,  0.5093,  ...,  0.4866,  0.1090,  0.0654]])), (669734002, tensor([[-3.0787e-01, -2.8045e-01, -1.1370e-01,  ..., -2.0134e-01,\n",
      "          1.8310e-01, -2.7622e-01],\n",
      "        [-3.9765e-04,  2.1816e-01,  2.8168e-01,  ...,  2.4409e-01,\n",
      "          2.0675e-01, -1.7658e-02],\n",
      "        [ 2.1012e-02, -8.4369e-01, -1.3800e-01,  ..., -1.7205e-02,\n",
      "         -5.8313e-02, -7.8253e-02]])), (674052001, tensor([[-0.1596,  0.8685,  0.7987,  ...,  0.1632, -0.2031,  0.1687],\n",
      "        [-0.6865,  3.3226,  0.4041,  ..., -0.3269, -0.5278, -0.2638],\n",
      "        [-0.5074,  1.2346,  0.2958,  ..., -0.2282, -0.2333,  0.2729]])), (674606048, tensor([[ 0.3517,  1.1993,  0.4037,  ..., -0.4773, -0.6534,  0.0210],\n",
      "        [-0.4345,  0.6562,  0.7429,  ..., -0.1930, -0.3738,  0.1318],\n",
      "        [ 0.3057,  0.8847,  0.3951,  ...,  0.0579, -0.2980,  0.1860]])), (683148002, tensor([[ 0.5026, -0.6625, -0.3527,  ...,  0.5638, -0.0032, -0.3738],\n",
      "        [ 0.5666, -0.8363, -0.4125,  ...,  0.5261,  0.2659, -0.2418],\n",
      "        [ 0.3600,  0.3679,  0.2308,  ...,  0.2307,  0.4239, -0.1452]])), (684282001, tensor([[ 0.1515, -0.4270, -0.1076,  ...,  0.1743, -0.1571, -0.3477],\n",
      "        [ 0.3380,  0.3880,  0.2461,  ...,  0.0915,  0.2486, -0.3384],\n",
      "        [ 0.3165,  0.2561, -0.2311,  ...,  0.1128,  0.1150, -0.7732]])), (685183001, tensor([[-0.3867,  1.5990, -0.3576,  ..., -0.5576,  0.5263, -0.0625],\n",
      "        [-0.0403,  1.2280,  0.0958,  ..., -0.3947,  0.1659,  0.1025],\n",
      "        [-0.4188,  0.9819, -0.6669,  ..., -0.2078,  0.3447, -0.0771]])), (687858001, tensor([[-0.5791,  1.1105, -0.3679,  ..., -0.0251,  0.5393,  0.3153],\n",
      "        [ 0.0809,  0.2847, -0.2083,  ..., -0.2422,  0.3104, -0.4110],\n",
      "        [-0.1191,  0.6342, -0.2211,  ...,  0.2456,  0.1551,  0.1959]])), (699923092, tensor([[ 0.4328, -0.2881, -1.0029,  ..., -0.1612,  0.0604, -0.0583],\n",
      "        [ 0.2164,  0.5305, -0.9079,  ..., -0.2333, -0.0795, -0.3426],\n",
      "        [-0.0742,  0.6321, -0.1843,  ..., -0.1366, -0.0038, -0.5346]])), (699923104, tensor([[-0.0391, -0.3432, -0.8469,  ...,  0.4307,  0.0752, -0.1909],\n",
      "        [ 0.1829, -0.2399, -0.6826,  ...,  0.4077,  0.0403, -0.2594],\n",
      "        [ 0.1920, -0.6974, -0.6597,  ..., -0.0222, -0.0250, -0.2015]])), (713997076, tensor([[-0.1428,  0.9299, -0.2917,  ...,  0.6439,  0.2029, -0.0132],\n",
      "        [ 0.0044,  0.4728,  0.5390,  ...,  0.4435, -0.1511, -0.5216],\n",
      "        [ 0.3517,  0.4706,  0.1321,  ...,  0.6644,  0.2680,  0.3584]])), (721107003, tensor([[ 0.4737,  1.5356, -1.0450,  ...,  0.2604, -0.1806,  0.4105],\n",
      "        [ 0.1698,  1.1556, -0.8120,  ...,  0.3431, -0.3622,  0.0686],\n",
      "        [ 0.4837,  0.7307, -0.7274,  ...,  0.5235,  0.0231,  0.3206]])), (724482001, tensor([[ 0.2476,  0.4363, -0.8659,  ..., -0.0775, -0.0968,  0.0714],\n",
      "        [ 0.1081,  0.1909, -0.4991,  ..., -0.1621,  0.1422,  0.1470],\n",
      "        [ 0.4948,  0.0851, -0.6922,  ...,  0.1256, -0.2805, -0.0610]])), (733896001, tensor([[-0.1885,  1.4695, -0.0430,  ...,  0.1307,  0.2068,  0.3423],\n",
      "        [-0.2983,  0.2844, -0.7521,  ...,  0.1177, -0.0253,  0.1219],\n",
      "        [-0.1801,  0.8991, -0.1512,  ...,  0.3085,  0.2151,  0.3438]])), (746261007, tensor([[-0.2565,  0.1433, -0.4310,  ...,  0.0905,  0.1494, -0.1823],\n",
      "        [ 0.0561,  0.5858, -1.1910,  ...,  0.1960,  0.1667, -0.1899],\n",
      "        [-0.3224, -0.5516, -0.7867,  ...,  0.0590,  0.0216, -0.0197]])), (754792003, tensor([[ 0.4583, -0.0121,  0.0433,  ...,  0.5968,  0.1499, -0.0171],\n",
      "        [ 0.3408, -0.4208,  0.2383,  ...,  0.4177, -0.2216, -0.5057],\n",
      "        [ 0.5912,  1.2067,  0.1155,  ...,  0.4111, -0.1460, -0.3146]])), (763988002, tensor([[ 0.4455,  0.0486, -0.6083,  ..., -0.1420,  0.3172,  0.0237],\n",
      "        [-0.0186, -0.0011, -0.9503,  ..., -0.1220,  0.2845,  0.1858],\n",
      "        [ 0.1742,  0.6634, -0.4170,  ..., -0.3089,  0.3659,  0.2817]])), (766777015, tensor([[-0.0263, -0.5892, -0.7628,  ...,  0.2583, -0.3355,  0.0155],\n",
      "        [ 0.0419, -0.8938, -0.5788,  ...,  0.0810, -0.2030,  0.1918],\n",
      "        [ 0.0642,  0.1411, -1.0779,  ...,  0.3739, -0.1787, -0.0042]])), (772448004, tensor([[ 0.3358,  1.6361,  0.2461,  ...,  0.1884,  0.5005,  0.0412],\n",
      "        [-0.0469,  1.0753,  0.2710,  ...,  0.1190,  0.5843,  0.4574],\n",
      "        [ 0.2055,  0.9600,  0.6672,  ...,  0.0117,  0.0968,  0.0077]])), (778064045, tensor([[ 0.2291,  0.1169, -0.1285,  ..., -0.0475,  0.4377, -0.2321],\n",
      "        [ 0.4182,  0.4057,  0.1571,  ...,  0.4506, -0.1563, -0.1650],\n",
      "        [ 0.3420, -0.6346, -0.4040,  ...,  0.1863,  0.6055, -0.1060]])), (780300001, tensor([[-0.1897,  0.2655, -0.1125,  ..., -0.0647,  0.5072,  0.1154],\n",
      "        [-0.1875,  0.4587, -0.4853,  ...,  0.0152,  0.5429,  0.2144],\n",
      "        [ 0.0687,  0.4960, -0.4161,  ..., -0.1104,  0.2536, -0.1401]])), (781135001, tensor([[ 0.1371, -0.7826,  0.4040,  ..., -0.2877, -0.5579, -0.4455],\n",
      "        [ 0.1613,  0.2055,  0.5177,  ..., -0.0694,  0.2656,  0.1681],\n",
      "        [-0.0362, -1.2199,  0.3694,  ...,  0.1010, -0.3571, -0.0748]])), (788632002, tensor([[ 0.3032,  1.5976,  0.7969,  ..., -0.0312, -0.3173,  0.1031],\n",
      "        [ 0.0994,  0.1005,  0.4919,  ...,  0.1912,  0.0908,  0.1733],\n",
      "        [ 0.3024,  0.2866,  0.8099,  ...,  0.2673,  0.0800,  0.3199]])), (797075003, tensor([[ 0.5217, -0.2878, -0.6661,  ...,  0.0691, -0.3259,  0.1848],\n",
      "        [ 0.7286, -0.6267, -0.5196,  ..., -0.2098, -0.4158,  0.0109],\n",
      "        [ 0.4098, -0.8386, -0.3953,  ..., -0.0712, -0.1474, -0.1560]])), (803593009, tensor([[ 0.1383,  0.3320,  0.2998,  ...,  0.3835, -0.2146,  0.2527],\n",
      "        [ 0.0986,  0.2237, -0.1680,  ...,  0.0211, -0.2855,  0.1713],\n",
      "        [ 0.4346,  0.2788,  0.2573,  ...,  0.4385, -0.1144,  0.0854]])), (807265006, tensor([[ 0.5825,  2.4246, -0.1035,  ...,  0.0944, -0.2815,  0.0762],\n",
      "        [ 0.2339,  1.0561, -0.0028,  ...,  0.1909, -0.0531,  0.2943],\n",
      "        [ 0.7063,  2.0734,  0.0735,  ..., -0.2075, -0.1181, -0.0190]])), (836393002, tensor([[-0.0645,  0.7429,  0.0170,  ...,  0.1392,  0.1198, -0.0680],\n",
      "        [ 0.0186,  0.3772, -0.5279,  ..., -0.4640,  0.0856,  0.0620],\n",
      "        [-0.1930,  0.3688, -0.6097,  ..., -0.2022,  0.1506,  0.0150]])), (863646002, tensor([[ 0.1678,  0.1723,  0.5807,  ...,  0.0444, -0.1143,  0.3213],\n",
      "        [ 0.1061,  0.7275,  0.4679,  ...,  0.3809, -0.1932,  0.1242],\n",
      "        [ 0.3352, -0.3179,  0.4790,  ...,  0.1059, -0.2858,  0.1271]])), (866482002, tensor([[ 0.1113,  0.3118,  0.6618,  ..., -0.1492,  0.1412, -0.2795],\n",
      "        [ 0.2186,  0.1175, -0.9756,  ..., -0.1081, -0.4759, -0.2330],\n",
      "        [-0.0050, -0.0745,  0.0395,  ...,  0.1090, -0.3404, -0.0352]])), (871624006, tensor([[ 0.4580,  0.5980, -0.8031,  ..., -0.0521,  0.0191,  0.0598],\n",
      "        [ 0.1228,  1.1305, -1.0617,  ..., -0.0826,  0.2840,  0.3244],\n",
      "        [ 0.3905,  0.9896, -0.7142,  ...,  0.2626, -0.3235,  0.3614]])), (877369001, tensor([[ 0.1808,  0.7247, -0.3721,  ...,  0.1126, -0.0185,  0.0591],\n",
      "        [ 0.1746, -0.2927,  0.0458,  ...,  0.2596, -0.2041, -0.2363],\n",
      "        [ 0.2130,  0.7410, -0.0107,  ..., -0.4469, -0.0692,  0.0361]])), (880333001, tensor([[ 0.3289,  0.8660,  0.2903,  ...,  0.0914, -0.0923,  0.1893],\n",
      "        [ 0.3662,  0.4428,  0.3928,  ...,  0.2804,  0.0134,  0.1512],\n",
      "        [ 0.3691, -0.3117,  0.7006,  ...,  0.3029, -0.1062, -0.2342]])), (881251002, tensor([[ 0.0729,  0.4651, -0.2867,  ...,  0.2258,  0.4988, -0.1340],\n",
      "        [ 0.2489,  0.9276,  0.0545,  ..., -0.0057,  0.7321,  0.0450],\n",
      "        [ 0.1736,  0.2701, -0.0517,  ...,  0.2694,  0.3152, -0.1176]])), (901588001, tensor([[ 0.3107,  0.9459,  0.6367,  ..., -0.2399,  0.2045,  0.1092],\n",
      "        [-0.1117,  1.1225,  0.1468,  ..., -0.2216,  0.2239,  0.1564],\n",
      "        [ 0.1843,  0.1154, -0.0890,  ...,  0.2937, -0.0249, -0.5147]])), (903309002, tensor([[ 9.2946e-02,  1.3033e+00,  1.0622e-01,  ...,  6.7121e-02,\n",
      "          1.8820e-01, -2.0255e-01],\n",
      "        [ 9.3298e-02,  4.2043e-01,  2.3399e-01,  ...,  5.8692e-01,\n",
      "         -1.6593e-01,  9.2049e-02],\n",
      "        [ 3.6019e-04,  7.3847e-01,  1.1163e-01,  ...,  2.3650e-01,\n",
      "          1.1491e-01, -1.6486e-01]])), (923805001, tensor([[ 0.0082,  0.5432, -0.6135,  ...,  0.2811, -0.1851,  0.0624],\n",
      "        [ 0.1925,  0.2034, -0.3115,  ...,  0.0257, -0.0514, -0.1491],\n",
      "        [ 0.3847,  1.3219, -0.0539,  ...,  0.4892, -0.3360, -0.0834]]))]\n"
     ]
    }
   ],
   "source": [
    "print(len(origin_img_emb))\n",
    "print(no_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(origin_img_emb, 'origin_img_emb.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
