{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U fashion-clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "item_data = pd.read_csv(\"./data/articles.csv\")\n",
    "interaction_data = pd.read_csv(\"./data/transactions_train.csv\")\n",
    "user_data = pd.read_csv(\"./data/customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### img prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def img_by_id(df, article_id:int, no_list:list, echo:int=1, img_show:bool=True):\n",
    "    if article_id in no_list:\n",
    "        return\n",
    "    if echo:\n",
    "        display(df[df.article_id == article_id])\n",
    "\n",
    "    img_id = \"0\"+str(article_id)\n",
    "    img = Image.open(\"./data/images/\"+img_id[0:3]+\"/\"+img_id+\".jpg\")\n",
    "\n",
    "    if img_show:\n",
    "        img.show()\n",
    "\n",
    "def find_no_img_item(df):\n",
    "    no_img = []\n",
    "\n",
    "    for item in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img_by_id(df, item[1][0], no_list=no_img, echo=0, img_show=False)\n",
    "        except FileNotFoundError:\n",
    "            no_img.append(item[0])\n",
    "\n",
    "    return no_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105542/105542 [00:22<00:00, 4757.04it/s]\n"
     ]
    }
   ],
   "source": [
    "no_img_ids = find_no_img_item(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_img_article_id = [item_data.iloc[x].article_id for x in no_img_ids]\n",
    "\n",
    "n_item_data = item_data.drop(no_img_ids, axis=0).reset_index(drop=True)\n",
    "n_interaction_data = interaction_data[~interaction_data[\"article_id\"].isin(no_img_article_id)].reset_index(drop=True)\n",
    "\n",
    "user2idx = {v:k for k,v in enumerate(user_data['customer_id'].unique())}\n",
    "item2idx = {v:k for k,v in enumerate(n_item_data['article_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights, resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "\n",
    "\n",
    "# # load pretrained alexnet\n",
    "# model_alex = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "# model_res = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "# model_vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# # del last clf layer\n",
    "# model_alex.classifier = model_alex.classifier[:-3]\n",
    "# model_res.fc = nn.Identity()\n",
    "# model_vgg.classifier = model_vgg.classifier[:-3]\n",
    "\n",
    "fclip = FashionCLIP('fashion-clip')\n",
    "\n",
    "images = [\"./data/images/\" + \"0\" + str(k)[0:2] + \"/\" + \"0\"+str(k) + \".jpg\" for k in n_item_data[\"article_id\"].tolist()]\n",
    "# image_embeddings = fclip.encode_images(images, batch_size=32)\n",
    "\n",
    "\n",
    "# feat_map_res = make_feature_map(model_res,n_item_data, book2idx)\n",
    "# feat_map_alex = make_feature_map(model_alex, n_book_data, book2idx)\n",
    "# feat_map_vgg = make_feature_map(model_vgg,n_book_data, book2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만들어둔 임베딩 csv로 저장해두기\n",
    "# pd.DataFrame(images).to_csv(\"img_list.csv\", index=False)\n",
    "# pd.DataFrame(image_embeddings).to_csv(\"img_emb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = pd.read_csv(\"img_list.csv\")\n",
    "img_emb = pd.read_csv(\"img_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105100, 512)\n"
     ]
    }
   ],
   "source": [
    "print(img_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emb = torch.tensor(img_emb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9380, dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img 16=\"0118458003\", 17=\"0118458004\"\n",
    "res = nn.functional.cosine_similarity(img_emb[16], img_emb[17], dim=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class HMDataset(Dataset):\n",
    "    def __init__(self, df, user2idx, item2idx, is_train:bool=True) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.is_train = is_train\n",
    "        self.user2idx = user2idx\n",
    "        self.item2idx = item2idx\n",
    "        self.n_user = len(self.user2idx)\n",
    "        self.n_item = len(self.item2idx)\n",
    "        # mapping id2idx\n",
    "        self.df['article_id'] = self.df['article_id'].map(self.item2idx)\n",
    "        self.df['customer_id'] = self.df['customer_id'].map(self.user2idx)\n",
    "\n",
    "        if is_train:\n",
    "            self.df['neg'] = np.zeros(len(self.df), dtype=int)\n",
    "            self._make_triples_data()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.df.customer_id[index]\n",
    "        pos = self.df.article_id[index]\n",
    "        \n",
    "        if self.is_train:\n",
    "            neg = self.df.neg[index]\n",
    "            return user, pos, neg\n",
    "        \n",
    "        return user, pos\n",
    "    \n",
    "    def _neg_sampling(self, pos_list):\n",
    "        neg = np.random.randint(0,self.n_item,1)\n",
    "        while neg in pos_list:\n",
    "            neg = np.random.randint(0,self.n_item,1)\n",
    "        return neg\n",
    "\n",
    "    def _make_triples_data(self):\n",
    "        for id in tqdm(range(self.n_user)):\n",
    "            user_df = self.df[self.df.customer_id==id]\n",
    "            pos_list = (user_df.article_id).tolist()\n",
    "            for i in range(len(user_df)):\n",
    "                idx = user_df.index[i]\n",
    "                self.df.at[idx, 'neg'] = self._neg_sampling(pos_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_interaction_data = n_interaction_data.groupby('customer_id').filter(lambda x: len(x) > 3).reset_index(drop=True)\n",
    "test_df = n_interaction_data.groupby('customer_id').nth(-1)\n",
    "train_df = n_interaction_data[~n_interaction_data.index.isin(test_df.index)]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30976586, 5) (1006221, 5) (29970365, 5) 30976586\n"
     ]
    }
   ],
   "source": [
    "print(n_interaction_data.shape, test_df.shape, train_df.shape, test_df.shape[0]+train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0021da829b898f82269fc51feded4eac2129058ee95bd75bb1591e2eb14ecc79'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0].customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0021da829b898f82269fc51feded4eac2129058ee95bd7...</td>\n",
       "      <td>625229004</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id   \n",
       "0  2018-09-20  0021da829b898f82269fc51feded4eac2129058ee95bd7...   625229004  \\\n",
       "\n",
       "      price  sales_channel_id  \n",
       "0  0.019814                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0021da829b898f82269fc51feded4eac2129058ee95bd7...</td>\n",
       "      <td>649356002</td>\n",
       "      <td>0.027441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0021da829b898f82269fc51feded4eac2129058ee95bd7...</td>\n",
       "      <td>579941002</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0021da829b898f82269fc51feded4eac2129058ee95bd7...</td>\n",
       "      <td>629760002</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         t_dat                                        customer_id  article_id   \n",
       "49  2018-09-20  0021da829b898f82269fc51feded4eac2129058ee95bd7...   649356002  \\\n",
       "50  2018-09-20  0021da829b898f82269fc51feded4eac2129058ee95bd7...   579941002   \n",
       "51  2018-09-20  0021da829b898f82269fc51feded4eac2129058ee95bd7...   629760002   \n",
       "\n",
       "       price  sales_channel_id  \n",
       "49  0.027441                 1  \n",
       "50  0.019814                 1  \n",
       "51  0.015237                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_df[test_df.customer_id == '0021da829b898f82269fc51feded4eac2129058ee95bd75bb1591e2eb14ecc79'])\n",
    "display(train_df[train_df.customer_id == '0021da829b898f82269fc51feded4eac2129058ee95bd75bb1591e2eb14ecc79'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 37292/1371980 [10:29<6:14:37, 59.38it/s] "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_dataset = HMDataset(train_df, user2idx, item2idx)\n",
    "test_dataset = HMDataset(test_df, user2idx, item2idx, is_train=False)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>724</td>\n",
       "      <td>29020</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1383</td>\n",
       "      <td>26169</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2829</td>\n",
       "      <td>20712</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>8486</td>\n",
       "      <td>25774</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>11652</td>\n",
       "      <td>40814</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006216</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371091</td>\n",
       "      <td>92619</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006217</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371691</td>\n",
       "      <td>100190</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006218</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371721</td>\n",
       "      <td>103611</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006219</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371747</td>\n",
       "      <td>88088</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006220</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1371960</td>\n",
       "      <td>101250</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006221 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              t_dat  customer_id  article_id     price  sales_channel_id\n",
       "0        2018-09-20          724       29020  0.019814                 1\n",
       "1        2018-09-20         1383       26169  0.033881                 2\n",
       "2        2018-09-20         2829       20712  0.030492                 1\n",
       "3        2018-09-20         8486       25774  0.005068                 2\n",
       "4        2018-09-20        11652       40814  0.013542                 2\n",
       "...             ...          ...         ...       ...               ...\n",
       "1006216  2020-09-22      1371091       92619  0.042356                 2\n",
       "1006217  2020-09-22      1371691      100190  0.042356                 2\n",
       "1006218  2020-09-22      1371721      103611  0.043203                 1\n",
       "1006219  2020-09-22      1371747       88088  0.006763                 1\n",
       "1006220  2020-09-22      1371960      101250  0.033881                 2\n",
       "\n",
       "[1006221 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class VBPR(nn.Module):\n",
    "    def __init__(self, n_user, n_item, K, img_embedding) -> None:\n",
    "        super().__init__()\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.K = K\n",
    "        self.item_vis_imbedding = img_embedding # user * 512\n",
    "        self.D = self.item_vis_imbedding.shape[1]\n",
    "\n",
    "        self.offset = nn.Parameter(torch.zeros(1))\n",
    "        self.user_bias = nn.Embedding(self.n_user,1)\n",
    "        self.item_bias = nn.Embedding(self.n_item,1)\n",
    "        self.vis_bias = nn.Embedding(self.D,1)\n",
    "        self.user_emb = nn.Embedding(self.n_user,self.K)\n",
    "        self.item_emb = nn.Embedding(self.n_item,self.K)\n",
    "        self.user_vis_emb = nn.Embedding(self.n_user, self.D)\n",
    "    \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_bias.weight)\n",
    "        nn.init.xavier_uniform_(self.item_bias.weight.data)\n",
    "        nn.init.xavier_uniform_(self.vis_bias.weight.data)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight.data)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight.data)\n",
    "        nn.init.xavier_uniform_(self.user_vis_emb.weight.data)\n",
    "    \n",
    "    def cal_each(self, user, item):\n",
    "        vis_term = (self.user_vis_emb(user)@(self.item_vis_imbedding[item].T)).sum(dim=1) + (self.vis_bias.weight.T)@(self.item_vis_imbedding[item].T)\n",
    "        mf_term = self.offset + self.user_bias(user).T + self.item_bias(item).T + (self.user_emb(user)@self.item_emb(item).T).sum(dim=1).unsqueeze(dim=0)\n",
    "        params = (self.offset, self.user_bias(user), self.item_bias(item), self.vis_bias.weight, self.user_emb(user), self.item_emb(item), self.user_vis_emb(user))\n",
    "        return (mf_term+vis_term).squeeze(), params\n",
    "    \n",
    "    def forward(self, user, pos, neg):\n",
    "        xui, pos_params = self.cal_each(user,pos)\n",
    "        xuj, neg_params = self.cal_each(user,neg)\n",
    "        return (xui-xuj), pos_params, neg_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, reg_theta, reg_beta) -> None:\n",
    "        super().__init__()\n",
    "        self.reg_theta = reg_theta\n",
    "        self.reg_beta = reg_beta\n",
    "    \n",
    "    def _cal_l2(self, *tensors):\n",
    "        total = 0\n",
    "        for tensor in tensors:\n",
    "            total += tensor.pow(2).sum()\n",
    "        return 0.5 * total\n",
    "\n",
    "    def _reg_term(self, pos_params, neg_params):\n",
    "        alpha, beta_u, beta_pos, beta_prime_pos, gamma_u, gamma_pos, theta_u = pos_params\n",
    "        _, _, beta_neg, beta_prime_neg, _, gamma_neg, _ = neg_params\n",
    "\n",
    "        reg_out = self.reg_theta * self._cal_l2(alpha, beta_u, beta_pos, beta_neg, theta_u, gamma_u, gamma_pos, gamma_neg)\n",
    "        reg_out += self.reg_beta * self._cal_l2(beta_prime_pos, beta_prime_neg)\n",
    "\n",
    "        return reg_out\n",
    "\n",
    "    def forward(self, diff, pos_params, neg_params):\n",
    "        loss = -nn.functional.logsigmoid(diff).sum()\n",
    "        loss += self._reg_term(pos_params, neg_params)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def train(model, optimizer, dataloader, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for user, pos, neg in tqdm(dataloader):\n",
    "        user = user.to(device)\n",
    "        pos = pos.to(device)\n",
    "        neg = neg.to(device)\n",
    "\n",
    "        diff, pos_params, neg_params = model(user, pos, neg)\n",
    "        loss = criterion(diff, pos_params, neg_params)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "n_user = len(user2idx)\n",
    "n_item = len(item2idx)\n",
    "\n",
    "K = 20\n",
    "reg_theta = 0.1\n",
    "reg_beta = 0.1\n",
    "\n",
    "lr = 0.001\n",
    "epoch = 20\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "criterion = BPRLoss(reg_theta, reg_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbpr_20 = VBPR(n_user, n_item, K, img_emb)\n",
    "optimizer = Adam(params = vbpr_20.parameters(), lr=lr)\n",
    "train_loss_20 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_20.append(train(vbpr_20, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {train_loss_20[-1]:.10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 40\n",
    "\n",
    "vbpr_40 = VBPR(n_user, n_item, K, img_emb)\n",
    "optimizer = Adam(params = vbpr_40.parameters(), lr=lr)\n",
    "train_loss_40 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_40.append(train(vbpr_40, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {train_loss_40[-1]:.10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 60\n",
    "\n",
    "vbpr_60 = VBPR(n_user, n_item, K, img_emb)\n",
    "optimizer = Adam(params = vbpr_60.parameters(), lr=lr)\n",
    "train_loss_60 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_loss_60.append(train(vbpr_60, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {train_loss_60[-1]:.10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epoch), train_loss_20, label=\"VBPR(factor 20)\")\n",
    "plt.plot(range(epoch), train_loss_40, label=\"VBPR(factor 40)\")\n",
    "plt.plot(range(epoch), train_loss_60, label=\"VBPR(factor 60)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top K rec test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "class Recommender:\n",
    "    def __init__(self, model, query_img, train_dataset, n_item, img_emb, device) -> None:\n",
    "        self.model = model\n",
    "        self.train_df = train_dataset.dataset.df\n",
    "        self.all_item = set(range(0,n_item))\n",
    "        self.query_img = query_img\n",
    "        self.img_emb = img_emb\n",
    "        self.device = device\n",
    "\n",
    "    def _get_img_sim(self, itemset:list):\n",
    "        print(\"GET IMG SIM\")\n",
    "        res = []\n",
    "        for item in itemset:\n",
    "            res.append(nn.functional.cosine_similarity(self.query_img, self.img_emb[item.item()]))\n",
    "        return res\n",
    "\n",
    "    def _get_unobs_items(self, user_idx):\n",
    "        obs_item_set = set(self.train_df[self.train_df.user_id==user_idx].isbn)\n",
    "        return list(self.all_item - obs_item_set)\n",
    "\n",
    "    def user_rank(self, user_idx:int, top_k:int=None, img_sim_weight:float=0.5):\n",
    "        self.model.eval()\n",
    "        unobs_itemset = self._get_unobs_items(user_idx)\n",
    "        scaler = MaxAbsScaler()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            itemset = torch.tensor(unobs_itemset).to(self.device)\n",
    "            user = torch.tensor(np.full(len(itemset), user_idx)).to(self.device)\n",
    "            img_sim = torch.tensor(self._get_img_sim(itemset))\n",
    "\n",
    "            out, _ = self.model.cal_each(user, itemset)\n",
    "            out = scaler.fit_transform(out) # range [-1~1]\n",
    "            out = out + img_sim_weight*img_sim # range [-1.5~1.5]\n",
    "\n",
    "            scores = np.array(torch.concat((user.unsqueeze(dim=1),itemset.unsqueeze(dim=1),out.unsqueeze(dim=1)), dim=1))\n",
    "       \n",
    "        sorted_scores = scores[(-scores[:, 2]).argsort()]\n",
    "        return sorted_scores[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(recommender, test_dataset):\n",
    "    df = test_dataset.dataset.df\n",
    "    user_list = df['user_id'].unique()\n",
    "    res_true = {}\n",
    "    res_topk = {}\n",
    "    res_hit = {}\n",
    "    \n",
    "    for user in tqdm(user_list[:50]):\n",
    "        true_item = df[df.user_id==user].isbn\n",
    "        if len(true_item)>4:\n",
    "            res = recommender.user_rank(user, 20)\n",
    "            topk = res[:,1]\n",
    "            hit = len(set(true_item).intersection(set(topk)))\n",
    "            res_true[user] = list(true_item)\n",
    "            res_topk[user] = list(topk)\n",
    "            res_hit[user] = hit\n",
    "    \n",
    "    return res_true, res_topk, res_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fclip.encode_images(query_img, batch_size=1)\n",
    "# res = img_sim(query, feat_map_vgg)\n",
    "# res\n",
    "recommender = Recommender(vbpr_20, query, train_dataset, n_item, img_emb, device)\n",
    "\n",
    "res_true, res_topk, res_hit = eval(recommender, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
