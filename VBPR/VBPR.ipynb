{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_data = pd.read_csv(\"./data/books.csv\")\n",
    "rating_data = pd.read_csv(\"./data/ratings.csv\")\n",
    "user_data = pd.read_csv(\"./data/users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0771074670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0684823802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0425099148</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0553264990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164724</th>\n",
       "      <td>278854</td>\n",
       "      <td>0553578596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164725</th>\n",
       "      <td>278854</td>\n",
       "      <td>0316184152</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164726</th>\n",
       "      <td>278854</td>\n",
       "      <td>0515087122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164727</th>\n",
       "      <td>278854</td>\n",
       "      <td>0553579606</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164728</th>\n",
       "      <td>278854</td>\n",
       "      <td>0425163393</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn  rating\n",
       "0             8  0771074670       1\n",
       "1             8  0002005018       5\n",
       "2            17  0684823802       1\n",
       "3            17  0425099148       7\n",
       "4            17  0553264990       5\n",
       "...         ...         ...     ...\n",
       "164724   278854  0553578596       1\n",
       "164725   278854  0316184152       7\n",
       "164726   278854  0515087122       1\n",
       "164727   278854  0553579606       8\n",
       "164728   278854  0425163393       7\n",
       "\n",
       "[164729 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### img prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def find_no_img(df):\n",
    "    no_img = []\n",
    "\n",
    "    for book in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            isbn = book[1].isbn\n",
    "            img = prepare_img(isbn)\n",
    "        except FileNotFoundError:\n",
    "            no_img.append(book[0])\n",
    "\n",
    "    return no_img\n",
    "\n",
    "def prepare_img(q_isbn):\n",
    "    q_path = book_data[book_data.isbn == q_isbn].img_path.item()\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    transform = transforms.Compose(\n",
    "            [transforms.Resize(256),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            ])\n",
    "    img = Image.open(\"./data/\"+q_path)\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def make_feature_map(model, df, idx):\n",
    "    model.eval()\n",
    "    feature_map = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for book in tqdm(df.iterrows(), total=len(df)):\n",
    "            isbn = book[1].isbn\n",
    "            img = prepare_img(isbn)\n",
    "            feature_map[idx[isbn]] = model(img)\n",
    "\n",
    "    return feature_map\n",
    "\n",
    "def img_sim(query_vec, itemset:dict):\n",
    "    res = {}\n",
    "    for isbn, feat_vec in itemset.items():\n",
    "        res[isbn] = nn.functional.cosine_similarity(query_vec, feat_vec)\n",
    "\n",
    "    sorted_res = sorted(res.items(), key = lambda item : -item[1])\n",
    "\n",
    "    return dict(sorted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27013/27013 [01:11<00:00, 375.91it/s]\n"
     ]
    }
   ],
   "source": [
    "no_img = find_no_img(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_img_isbn = [book_data.iloc[x].isbn for x in no_img]\n",
    "\n",
    "n_book_data = book_data.drop(no_img, axis=0).reset_index(drop=True)\n",
    "n_rating_data = rating_data[~rating_data[\"isbn\"].isin(no_img_isbn)].reset_index(drop=True)\n",
    "\n",
    "user2idx = {v:k for k,v in enumerate(user_data['user_id'].unique())}\n",
    "book2idx = {v:k for k,v in enumerate(n_book_data['isbn'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26689/26689 [12:54<00:00, 34.44it/s]\n",
      "100%|██████████| 26689/26689 [06:28<00:00, 68.67it/s]\n",
      "100%|██████████| 26689/26689 [58:09<00:00,  7.65it/s] \n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights, resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
    "\n",
    "# load pretrained alexnet\n",
    "model_alex = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "model_res = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model_vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# del last clf layer\n",
    "model_alex.classifier = model_alex.classifier[:-3]\n",
    "model_res.fc = nn.Identity()\n",
    "model_vgg.classifier = model_vgg.classifier[:-3]\n",
    "\n",
    "feat_map_res = make_feature_map(model_res,n_book_data, book2idx)\n",
    "feat_map_alex = make_feature_map(model_alex, n_book_data, book2idx)\n",
    "feat_map_vgg = make_feature_map(model_vgg,n_book_data, book2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make sim socre and remove no img items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: tensor([1.0000], grad_fn=<SumBackward1>),\n",
       " 802: tensor([0.8775], grad_fn=<SumBackward1>),\n",
       " 10256: tensor([0.8756], grad_fn=<SumBackward1>),\n",
       " 1181: tensor([0.8725], grad_fn=<SumBackward1>),\n",
       " 51: tensor([0.8652], grad_fn=<SumBackward1>),\n",
       " 982: tensor([0.8641], grad_fn=<SumBackward1>),\n",
       " 25845: tensor([0.8629], grad_fn=<SumBackward1>),\n",
       " 5559: tensor([0.8621], grad_fn=<SumBackward1>),\n",
       " 8845: tensor([0.8613], grad_fn=<SumBackward1>),\n",
       " 9273: tensor([0.8550], grad_fn=<SumBackward1>),\n",
       " 9881: tensor([0.8544], grad_fn=<SumBackward1>),\n",
       " 26287: tensor([0.8539], grad_fn=<SumBackward1>),\n",
       " 13638: tensor([0.8536], grad_fn=<SumBackward1>),\n",
       " 4663: tensor([0.8529], grad_fn=<SumBackward1>),\n",
       " 25184: tensor([0.8513], grad_fn=<SumBackward1>),\n",
       " 16084: tensor([0.8510], grad_fn=<SumBackward1>),\n",
       " 9782: tensor([0.8503], grad_fn=<SumBackward1>),\n",
       " 23923: tensor([0.8501], grad_fn=<SumBackward1>),\n",
       " 15483: tensor([0.8489], grad_fn=<SumBackward1>),\n",
       " 4814: tensor([0.8486], grad_fn=<SumBackward1>),\n",
       " 13127: tensor([0.8484], grad_fn=<SumBackward1>),\n",
       " 16389: tensor([0.8482], grad_fn=<SumBackward1>),\n",
       " 17064: tensor([0.8478], grad_fn=<SumBackward1>),\n",
       " 6357: tensor([0.8470], grad_fn=<SumBackward1>),\n",
       " 3756: tensor([0.8464], grad_fn=<SumBackward1>),\n",
       " 23936: tensor([0.8452], grad_fn=<SumBackward1>),\n",
       " 12688: tensor([0.8437], grad_fn=<SumBackward1>),\n",
       " 16435: tensor([0.8436], grad_fn=<SumBackward1>),\n",
       " 13154: tensor([0.8431], grad_fn=<SumBackward1>),\n",
       " 8681: tensor([0.8428], grad_fn=<SumBackward1>),\n",
       " 20352: tensor([0.8424], grad_fn=<SumBackward1>),\n",
       " 22232: tensor([0.8423], grad_fn=<SumBackward1>),\n",
       " 21797: tensor([0.8420], grad_fn=<SumBackward1>),\n",
       " 1619: tensor([0.8417], grad_fn=<SumBackward1>),\n",
       " 3760: tensor([0.8409], grad_fn=<SumBackward1>),\n",
       " 2222: tensor([0.8404], grad_fn=<SumBackward1>),\n",
       " 25212: tensor([0.8400], grad_fn=<SumBackward1>),\n",
       " 25687: tensor([0.8398], grad_fn=<SumBackward1>),\n",
       " 16312: tensor([0.8391], grad_fn=<SumBackward1>),\n",
       " 2965: tensor([0.8390], grad_fn=<SumBackward1>),\n",
       " 1535: tensor([0.8389], grad_fn=<SumBackward1>),\n",
       " 15493: tensor([0.8385], grad_fn=<SumBackward1>),\n",
       " 7733: tensor([0.8379], grad_fn=<SumBackward1>),\n",
       " 13428: tensor([0.8379], grad_fn=<SumBackward1>),\n",
       " 14616: tensor([0.8369], grad_fn=<SumBackward1>),\n",
       " 13541: tensor([0.8363], grad_fn=<SumBackward1>),\n",
       " 16850: tensor([0.8359], grad_fn=<SumBackward1>),\n",
       " 26240: tensor([0.8359], grad_fn=<SumBackward1>),\n",
       " 14475: tensor([0.8350], grad_fn=<SumBackward1>),\n",
       " 16093: tensor([0.8350], grad_fn=<SumBackward1>),\n",
       " 5339: tensor([0.8339], grad_fn=<SumBackward1>),\n",
       " 6243: tensor([0.8336], grad_fn=<SumBackward1>),\n",
       " 19305: tensor([0.8332], grad_fn=<SumBackward1>),\n",
       " 8162: tensor([0.8330], grad_fn=<SumBackward1>),\n",
       " 11084: tensor([0.8329], grad_fn=<SumBackward1>),\n",
       " 18061: tensor([0.8327], grad_fn=<SumBackward1>),\n",
       " 4309: tensor([0.8327], grad_fn=<SumBackward1>),\n",
       " 6171: tensor([0.8325], grad_fn=<SumBackward1>),\n",
       " 15273: tensor([0.8324], grad_fn=<SumBackward1>),\n",
       " 20066: tensor([0.8321], grad_fn=<SumBackward1>),\n",
       " 9817: tensor([0.8315], grad_fn=<SumBackward1>),\n",
       " 13653: tensor([0.8311], grad_fn=<SumBackward1>),\n",
       " 13196: tensor([0.8308], grad_fn=<SumBackward1>),\n",
       " 13554: tensor([0.8306], grad_fn=<SumBackward1>),\n",
       " 7325: tensor([0.8304], grad_fn=<SumBackward1>),\n",
       " 13987: tensor([0.8301], grad_fn=<SumBackward1>),\n",
       " 4243: tensor([0.8289], grad_fn=<SumBackward1>),\n",
       " 9434: tensor([0.8284], grad_fn=<SumBackward1>),\n",
       " 22950: tensor([0.8281], grad_fn=<SumBackward1>),\n",
       " 25882: tensor([0.8281], grad_fn=<SumBackward1>),\n",
       " 6240: tensor([0.8281], grad_fn=<SumBackward1>),\n",
       " 10823: tensor([0.8280], grad_fn=<SumBackward1>),\n",
       " 2910: tensor([0.8280], grad_fn=<SumBackward1>),\n",
       " 6614: tensor([0.8278], grad_fn=<SumBackward1>),\n",
       " 10172: tensor([0.8276], grad_fn=<SumBackward1>),\n",
       " 16120: tensor([0.8269], grad_fn=<SumBackward1>),\n",
       " 17741: tensor([0.8268], grad_fn=<SumBackward1>),\n",
       " 5563: tensor([0.8259], grad_fn=<SumBackward1>),\n",
       " 1834: tensor([0.8258], grad_fn=<SumBackward1>),\n",
       " 3798: tensor([0.8256], grad_fn=<SumBackward1>),\n",
       " 19770: tensor([0.8255], grad_fn=<SumBackward1>),\n",
       " 21696: tensor([0.8254], grad_fn=<SumBackward1>),\n",
       " 14598: tensor([0.8253], grad_fn=<SumBackward1>),\n",
       " 15395: tensor([0.8252], grad_fn=<SumBackward1>),\n",
       " 16035: tensor([0.8251], grad_fn=<SumBackward1>),\n",
       " 10137: tensor([0.8251], grad_fn=<SumBackward1>),\n",
       " 18096: tensor([0.8247], grad_fn=<SumBackward1>),\n",
       " 12030: tensor([0.8245], grad_fn=<SumBackward1>),\n",
       " 23042: tensor([0.8240], grad_fn=<SumBackward1>),\n",
       " 21443: tensor([0.8229], grad_fn=<SumBackward1>),\n",
       " 5640: tensor([0.8228], grad_fn=<SumBackward1>),\n",
       " 24250: tensor([0.8224], grad_fn=<SumBackward1>),\n",
       " 1516: tensor([0.8223], grad_fn=<SumBackward1>),\n",
       " 3653: tensor([0.8223], grad_fn=<SumBackward1>),\n",
       " 16166: tensor([0.8222], grad_fn=<SumBackward1>),\n",
       " 9917: tensor([0.8221], grad_fn=<SumBackward1>),\n",
       " 5571: tensor([0.8221], grad_fn=<SumBackward1>),\n",
       " 6268: tensor([0.8221], grad_fn=<SumBackward1>),\n",
       " 11319: tensor([0.8220], grad_fn=<SumBackward1>),\n",
       " 154: tensor([0.8220], grad_fn=<SumBackward1>),\n",
       " 1331: tensor([0.8219], grad_fn=<SumBackward1>),\n",
       " 13449: tensor([0.8212], grad_fn=<SumBackward1>),\n",
       " 574: tensor([0.8211], grad_fn=<SumBackward1>),\n",
       " 370: tensor([0.8211], grad_fn=<SumBackward1>),\n",
       " 3606: tensor([0.8211], grad_fn=<SumBackward1>),\n",
       " 12803: tensor([0.8210], grad_fn=<SumBackward1>),\n",
       " 4109: tensor([0.8209], grad_fn=<SumBackward1>),\n",
       " 17434: tensor([0.8209], grad_fn=<SumBackward1>),\n",
       " 20745: tensor([0.8207], grad_fn=<SumBackward1>),\n",
       " 19778: tensor([0.8205], grad_fn=<SumBackward1>),\n",
       " 2327: tensor([0.8202], grad_fn=<SumBackward1>),\n",
       " 11840: tensor([0.8201], grad_fn=<SumBackward1>),\n",
       " 16390: tensor([0.8200], grad_fn=<SumBackward1>),\n",
       " 13309: tensor([0.8198], grad_fn=<SumBackward1>),\n",
       " 16233: tensor([0.8198], grad_fn=<SumBackward1>),\n",
       " 10441: tensor([0.8196], grad_fn=<SumBackward1>),\n",
       " 9845: tensor([0.8196], grad_fn=<SumBackward1>),\n",
       " 312: tensor([0.8196], grad_fn=<SumBackward1>),\n",
       " 9674: tensor([0.8195], grad_fn=<SumBackward1>),\n",
       " 12612: tensor([0.8194], grad_fn=<SumBackward1>),\n",
       " 14443: tensor([0.8193], grad_fn=<SumBackward1>),\n",
       " 12900: tensor([0.8190], grad_fn=<SumBackward1>),\n",
       " 2243: tensor([0.8189], grad_fn=<SumBackward1>),\n",
       " 20575: tensor([0.8188], grad_fn=<SumBackward1>),\n",
       " 4015: tensor([0.8186], grad_fn=<SumBackward1>),\n",
       " 17140: tensor([0.8185], grad_fn=<SumBackward1>),\n",
       " 15366: tensor([0.8185], grad_fn=<SumBackward1>),\n",
       " 1830: tensor([0.8184], grad_fn=<SumBackward1>),\n",
       " 10708: tensor([0.8183], grad_fn=<SumBackward1>),\n",
       " 24997: tensor([0.8182], grad_fn=<SumBackward1>),\n",
       " 10995: tensor([0.8181], grad_fn=<SumBackward1>),\n",
       " 367: tensor([0.8181], grad_fn=<SumBackward1>),\n",
       " 7523: tensor([0.8180], grad_fn=<SumBackward1>),\n",
       " 20156: tensor([0.8180], grad_fn=<SumBackward1>),\n",
       " 26309: tensor([0.8178], grad_fn=<SumBackward1>),\n",
       " 10650: tensor([0.8175], grad_fn=<SumBackward1>),\n",
       " 16192: tensor([0.8174], grad_fn=<SumBackward1>),\n",
       " 13353: tensor([0.8174], grad_fn=<SumBackward1>),\n",
       " 1887: tensor([0.8173], grad_fn=<SumBackward1>),\n",
       " 13607: tensor([0.8169], grad_fn=<SumBackward1>),\n",
       " 11508: tensor([0.8168], grad_fn=<SumBackward1>),\n",
       " 5045: tensor([0.8168], grad_fn=<SumBackward1>),\n",
       " 19966: tensor([0.8166], grad_fn=<SumBackward1>),\n",
       " 1852: tensor([0.8166], grad_fn=<SumBackward1>),\n",
       " 1319: tensor([0.8161], grad_fn=<SumBackward1>),\n",
       " 24349: tensor([0.8160], grad_fn=<SumBackward1>),\n",
       " 14994: tensor([0.8158], grad_fn=<SumBackward1>),\n",
       " 20958: tensor([0.8158], grad_fn=<SumBackward1>),\n",
       " 10909: tensor([0.8155], grad_fn=<SumBackward1>),\n",
       " 16137: tensor([0.8154], grad_fn=<SumBackward1>),\n",
       " 21302: tensor([0.8153], grad_fn=<SumBackward1>),\n",
       " 2049: tensor([0.8152], grad_fn=<SumBackward1>),\n",
       " 1139: tensor([0.8149], grad_fn=<SumBackward1>),\n",
       " 18987: tensor([0.8149], grad_fn=<SumBackward1>),\n",
       " 10687: tensor([0.8149], grad_fn=<SumBackward1>),\n",
       " 21256: tensor([0.8147], grad_fn=<SumBackward1>),\n",
       " 15928: tensor([0.8146], grad_fn=<SumBackward1>),\n",
       " 25853: tensor([0.8145], grad_fn=<SumBackward1>),\n",
       " 23323: tensor([0.8144], grad_fn=<SumBackward1>),\n",
       " 11814: tensor([0.8143], grad_fn=<SumBackward1>),\n",
       " 23772: tensor([0.8142], grad_fn=<SumBackward1>),\n",
       " 20661: tensor([0.8141], grad_fn=<SumBackward1>),\n",
       " 5646: tensor([0.8140], grad_fn=<SumBackward1>),\n",
       " 5116: tensor([0.8139], grad_fn=<SumBackward1>),\n",
       " 24180: tensor([0.8139], grad_fn=<SumBackward1>),\n",
       " 8586: tensor([0.8139], grad_fn=<SumBackward1>),\n",
       " 8549: tensor([0.8139], grad_fn=<SumBackward1>),\n",
       " 9963: tensor([0.8138], grad_fn=<SumBackward1>),\n",
       " 15481: tensor([0.8138], grad_fn=<SumBackward1>),\n",
       " 23956: tensor([0.8134], grad_fn=<SumBackward1>),\n",
       " 11035: tensor([0.8134], grad_fn=<SumBackward1>),\n",
       " 1346: tensor([0.8133], grad_fn=<SumBackward1>),\n",
       " 22552: tensor([0.8129], grad_fn=<SumBackward1>),\n",
       " 1704: tensor([0.8129], grad_fn=<SumBackward1>),\n",
       " 11064: tensor([0.8128], grad_fn=<SumBackward1>),\n",
       " 25736: tensor([0.8127], grad_fn=<SumBackward1>),\n",
       " 13492: tensor([0.8125], grad_fn=<SumBackward1>),\n",
       " 9512: tensor([0.8125], grad_fn=<SumBackward1>),\n",
       " 2261: tensor([0.8124], grad_fn=<SumBackward1>),\n",
       " 1838: tensor([0.8124], grad_fn=<SumBackward1>),\n",
       " 23374: tensor([0.8123], grad_fn=<SumBackward1>),\n",
       " 1837: tensor([0.8122], grad_fn=<SumBackward1>),\n",
       " 5336: tensor([0.8121], grad_fn=<SumBackward1>),\n",
       " 14800: tensor([0.8120], grad_fn=<SumBackward1>),\n",
       " 94: tensor([0.8119], grad_fn=<SumBackward1>),\n",
       " 6719: tensor([0.8119], grad_fn=<SumBackward1>),\n",
       " 13923: tensor([0.8118], grad_fn=<SumBackward1>),\n",
       " 12525: tensor([0.8118], grad_fn=<SumBackward1>),\n",
       " 25140: tensor([0.8117], grad_fn=<SumBackward1>),\n",
       " 13527: tensor([0.8113], grad_fn=<SumBackward1>),\n",
       " 15345: tensor([0.8113], grad_fn=<SumBackward1>),\n",
       " 9543: tensor([0.8113], grad_fn=<SumBackward1>),\n",
       " 14523: tensor([0.8112], grad_fn=<SumBackward1>),\n",
       " 2191: tensor([0.8111], grad_fn=<SumBackward1>),\n",
       " 13876: tensor([0.8110], grad_fn=<SumBackward1>),\n",
       " 7113: tensor([0.8110], grad_fn=<SumBackward1>),\n",
       " 20519: tensor([0.8110], grad_fn=<SumBackward1>),\n",
       " 5343: tensor([0.8108], grad_fn=<SumBackward1>),\n",
       " 26571: tensor([0.8107], grad_fn=<SumBackward1>),\n",
       " 24476: tensor([0.8106], grad_fn=<SumBackward1>),\n",
       " 17169: tensor([0.8106], grad_fn=<SumBackward1>),\n",
       " 11102: tensor([0.8106], grad_fn=<SumBackward1>),\n",
       " 12071: tensor([0.8103], grad_fn=<SumBackward1>),\n",
       " 19570: tensor([0.8102], grad_fn=<SumBackward1>),\n",
       " 12629: tensor([0.8102], grad_fn=<SumBackward1>),\n",
       " 12539: tensor([0.8100], grad_fn=<SumBackward1>),\n",
       " 16452: tensor([0.8099], grad_fn=<SumBackward1>),\n",
       " 2343: tensor([0.8098], grad_fn=<SumBackward1>),\n",
       " 10929: tensor([0.8096], grad_fn=<SumBackward1>),\n",
       " 14445: tensor([0.8095], grad_fn=<SumBackward1>),\n",
       " 10245: tensor([0.8095], grad_fn=<SumBackward1>),\n",
       " 16254: tensor([0.8095], grad_fn=<SumBackward1>),\n",
       " 6965: tensor([0.8094], grad_fn=<SumBackward1>),\n",
       " 3941: tensor([0.8094], grad_fn=<SumBackward1>),\n",
       " 7695: tensor([0.8092], grad_fn=<SumBackward1>),\n",
       " 17901: tensor([0.8091], grad_fn=<SumBackward1>),\n",
       " 1008: tensor([0.8088], grad_fn=<SumBackward1>),\n",
       " 17301: tensor([0.8088], grad_fn=<SumBackward1>),\n",
       " 17862: tensor([0.8087], grad_fn=<SumBackward1>),\n",
       " 1505: tensor([0.8085], grad_fn=<SumBackward1>),\n",
       " 16786: tensor([0.8085], grad_fn=<SumBackward1>),\n",
       " 744: tensor([0.8085], grad_fn=<SumBackward1>),\n",
       " 18111: tensor([0.8084], grad_fn=<SumBackward1>),\n",
       " 9484: tensor([0.8084], grad_fn=<SumBackward1>),\n",
       " 22935: tensor([0.8083], grad_fn=<SumBackward1>),\n",
       " 1829: tensor([0.8082], grad_fn=<SumBackward1>),\n",
       " 10537: tensor([0.8080], grad_fn=<SumBackward1>),\n",
       " 19704: tensor([0.8079], grad_fn=<SumBackward1>),\n",
       " 20743: tensor([0.8078], grad_fn=<SumBackward1>),\n",
       " 13348: tensor([0.8077], grad_fn=<SumBackward1>),\n",
       " 13854: tensor([0.8077], grad_fn=<SumBackward1>),\n",
       " 24587: tensor([0.8076], grad_fn=<SumBackward1>),\n",
       " 8382: tensor([0.8076], grad_fn=<SumBackward1>),\n",
       " 8640: tensor([0.8072], grad_fn=<SumBackward1>),\n",
       " 12992: tensor([0.8071], grad_fn=<SumBackward1>),\n",
       " 1692: tensor([0.8071], grad_fn=<SumBackward1>),\n",
       " 24135: tensor([0.8071], grad_fn=<SumBackward1>),\n",
       " 8752: tensor([0.8070], grad_fn=<SumBackward1>),\n",
       " 9909: tensor([0.8066], grad_fn=<SumBackward1>),\n",
       " 19432: tensor([0.8066], grad_fn=<SumBackward1>),\n",
       " 381: tensor([0.8066], grad_fn=<SumBackward1>),\n",
       " 11946: tensor([0.8066], grad_fn=<SumBackward1>),\n",
       " 3927: tensor([0.8064], grad_fn=<SumBackward1>),\n",
       " 485: tensor([0.8064], grad_fn=<SumBackward1>),\n",
       " 7486: tensor([0.8061], grad_fn=<SumBackward1>),\n",
       " 13478: tensor([0.8060], grad_fn=<SumBackward1>),\n",
       " 24602: tensor([0.8060], grad_fn=<SumBackward1>),\n",
       " 19569: tensor([0.8059], grad_fn=<SumBackward1>),\n",
       " 18071: tensor([0.8058], grad_fn=<SumBackward1>),\n",
       " 6924: tensor([0.8058], grad_fn=<SumBackward1>),\n",
       " 11446: tensor([0.8058], grad_fn=<SumBackward1>),\n",
       " 11314: tensor([0.8058], grad_fn=<SumBackward1>),\n",
       " 2404: tensor([0.8057], grad_fn=<SumBackward1>),\n",
       " 1665: tensor([0.8056], grad_fn=<SumBackward1>),\n",
       " 23922: tensor([0.8056], grad_fn=<SumBackward1>),\n",
       " 23662: tensor([0.8056], grad_fn=<SumBackward1>),\n",
       " 15888: tensor([0.8056], grad_fn=<SumBackward1>),\n",
       " 13234: tensor([0.8054], grad_fn=<SumBackward1>),\n",
       " 16391: tensor([0.8054], grad_fn=<SumBackward1>),\n",
       " 12914: tensor([0.8053], grad_fn=<SumBackward1>),\n",
       " 20736: tensor([0.8052], grad_fn=<SumBackward1>),\n",
       " 22801: tensor([0.8052], grad_fn=<SumBackward1>),\n",
       " 13611: tensor([0.8048], grad_fn=<SumBackward1>),\n",
       " 12825: tensor([0.8048], grad_fn=<SumBackward1>),\n",
       " 17522: tensor([0.8048], grad_fn=<SumBackward1>),\n",
       " 13529: tensor([0.8047], grad_fn=<SumBackward1>),\n",
       " 25932: tensor([0.8046], grad_fn=<SumBackward1>),\n",
       " 164: tensor([0.8046], grad_fn=<SumBackward1>),\n",
       " 7017: tensor([0.8046], grad_fn=<SumBackward1>),\n",
       " 17479: tensor([0.8045], grad_fn=<SumBackward1>),\n",
       " 1217: tensor([0.8045], grad_fn=<SumBackward1>),\n",
       " 18081: tensor([0.8045], grad_fn=<SumBackward1>),\n",
       " 6043: tensor([0.8044], grad_fn=<SumBackward1>),\n",
       " 10469: tensor([0.8044], grad_fn=<SumBackward1>),\n",
       " 21651: tensor([0.8043], grad_fn=<SumBackward1>),\n",
       " 24403: tensor([0.8042], grad_fn=<SumBackward1>),\n",
       " 3716: tensor([0.8040], grad_fn=<SumBackward1>),\n",
       " 8264: tensor([0.8039], grad_fn=<SumBackward1>),\n",
       " 20151: tensor([0.8038], grad_fn=<SumBackward1>),\n",
       " 26353: tensor([0.8038], grad_fn=<SumBackward1>),\n",
       " 21178: tensor([0.8037], grad_fn=<SumBackward1>),\n",
       " 13860: tensor([0.8037], grad_fn=<SumBackward1>),\n",
       " 171: tensor([0.8036], grad_fn=<SumBackward1>),\n",
       " 20727: tensor([0.8035], grad_fn=<SumBackward1>),\n",
       " 10938: tensor([0.8035], grad_fn=<SumBackward1>),\n",
       " 8815: tensor([0.8034], grad_fn=<SumBackward1>),\n",
       " 15548: tensor([0.8034], grad_fn=<SumBackward1>),\n",
       " 16906: tensor([0.8032], grad_fn=<SumBackward1>),\n",
       " 9415: tensor([0.8032], grad_fn=<SumBackward1>),\n",
       " 12976: tensor([0.8031], grad_fn=<SumBackward1>),\n",
       " 9040: tensor([0.8028], grad_fn=<SumBackward1>),\n",
       " 22402: tensor([0.8027], grad_fn=<SumBackward1>),\n",
       " 145: tensor([0.8027], grad_fn=<SumBackward1>),\n",
       " 23165: tensor([0.8027], grad_fn=<SumBackward1>),\n",
       " 2273: tensor([0.8027], grad_fn=<SumBackward1>),\n",
       " 22104: tensor([0.8026], grad_fn=<SumBackward1>),\n",
       " 8284: tensor([0.8026], grad_fn=<SumBackward1>),\n",
       " 16112: tensor([0.8026], grad_fn=<SumBackward1>),\n",
       " 15344: tensor([0.8025], grad_fn=<SumBackward1>),\n",
       " 3942: tensor([0.8022], grad_fn=<SumBackward1>),\n",
       " 14140: tensor([0.8021], grad_fn=<SumBackward1>),\n",
       " 7097: tensor([0.8020], grad_fn=<SumBackward1>),\n",
       " 13781: tensor([0.8018], grad_fn=<SumBackward1>),\n",
       " 13866: tensor([0.8017], grad_fn=<SumBackward1>),\n",
       " 13763: tensor([0.8017], grad_fn=<SumBackward1>),\n",
       " 10667: tensor([0.8016], grad_fn=<SumBackward1>),\n",
       " 8188: tensor([0.8015], grad_fn=<SumBackward1>),\n",
       " 15830: tensor([0.8014], grad_fn=<SumBackward1>),\n",
       " 2497: tensor([0.8013], grad_fn=<SumBackward1>),\n",
       " 1488: tensor([0.8013], grad_fn=<SumBackward1>),\n",
       " 6926: tensor([0.8011], grad_fn=<SumBackward1>),\n",
       " 11025: tensor([0.8011], grad_fn=<SumBackward1>),\n",
       " 10718: tensor([0.8011], grad_fn=<SumBackward1>),\n",
       " 136: tensor([0.8009], grad_fn=<SumBackward1>),\n",
       " 1987: tensor([0.8009], grad_fn=<SumBackward1>),\n",
       " 2189: tensor([0.8008], grad_fn=<SumBackward1>),\n",
       " 19459: tensor([0.8008], grad_fn=<SumBackward1>),\n",
       " 13368: tensor([0.8008], grad_fn=<SumBackward1>),\n",
       " 19585: tensor([0.8008], grad_fn=<SumBackward1>),\n",
       " 25307: tensor([0.8008], grad_fn=<SumBackward1>),\n",
       " 17299: tensor([0.8007], grad_fn=<SumBackward1>),\n",
       " 10992: tensor([0.8007], grad_fn=<SumBackward1>),\n",
       " 18040: tensor([0.8006], grad_fn=<SumBackward1>),\n",
       " 19568: tensor([0.8006], grad_fn=<SumBackward1>),\n",
       " 10964: tensor([0.8006], grad_fn=<SumBackward1>),\n",
       " 6576: tensor([0.8005], grad_fn=<SumBackward1>),\n",
       " 10271: tensor([0.8005], grad_fn=<SumBackward1>),\n",
       " 8794: tensor([0.8004], grad_fn=<SumBackward1>),\n",
       " 8240: tensor([0.8002], grad_fn=<SumBackward1>),\n",
       " 22055: tensor([0.8001], grad_fn=<SumBackward1>),\n",
       " 18803: tensor([0.8001], grad_fn=<SumBackward1>),\n",
       " 11146: tensor([0.8000], grad_fn=<SumBackward1>),\n",
       " 12780: tensor([0.8000], grad_fn=<SumBackward1>),\n",
       " 15202: tensor([0.7999], grad_fn=<SumBackward1>),\n",
       " 8427: tensor([0.7999], grad_fn=<SumBackward1>),\n",
       " 25415: tensor([0.7999], grad_fn=<SumBackward1>),\n",
       " 7098: tensor([0.7999], grad_fn=<SumBackward1>),\n",
       " 5475: tensor([0.7997], grad_fn=<SumBackward1>),\n",
       " 5918: tensor([0.7997], grad_fn=<SumBackward1>),\n",
       " 15128: tensor([0.7996], grad_fn=<SumBackward1>),\n",
       " 20320: tensor([0.7996], grad_fn=<SumBackward1>),\n",
       " 7689: tensor([0.7996], grad_fn=<SumBackward1>),\n",
       " 2335: tensor([0.7995], grad_fn=<SumBackward1>),\n",
       " 8757: tensor([0.7994], grad_fn=<SumBackward1>),\n",
       " 568: tensor([0.7993], grad_fn=<SumBackward1>),\n",
       " 4457: tensor([0.7993], grad_fn=<SumBackward1>),\n",
       " 7729: tensor([0.7993], grad_fn=<SumBackward1>),\n",
       " 19064: tensor([0.7992], grad_fn=<SumBackward1>),\n",
       " 233: tensor([0.7992], grad_fn=<SumBackward1>),\n",
       " 6819: tensor([0.7991], grad_fn=<SumBackward1>),\n",
       " 22041: tensor([0.7991], grad_fn=<SumBackward1>),\n",
       " 12644: tensor([0.7991], grad_fn=<SumBackward1>),\n",
       " 19714: tensor([0.7990], grad_fn=<SumBackward1>),\n",
       " 22949: tensor([0.7990], grad_fn=<SumBackward1>),\n",
       " 22426: tensor([0.7990], grad_fn=<SumBackward1>),\n",
       " 23811: tensor([0.7988], grad_fn=<SumBackward1>),\n",
       " 4374: tensor([0.7988], grad_fn=<SumBackward1>),\n",
       " 5533: tensor([0.7987], grad_fn=<SumBackward1>),\n",
       " 13889: tensor([0.7985], grad_fn=<SumBackward1>),\n",
       " 16822: tensor([0.7985], grad_fn=<SumBackward1>),\n",
       " 12122: tensor([0.7985], grad_fn=<SumBackward1>),\n",
       " 12812: tensor([0.7984], grad_fn=<SumBackward1>),\n",
       " 14596: tensor([0.7982], grad_fn=<SumBackward1>),\n",
       " 25962: tensor([0.7982], grad_fn=<SumBackward1>),\n",
       " 16638: tensor([0.7980], grad_fn=<SumBackward1>),\n",
       " 19536: tensor([0.7980], grad_fn=<SumBackward1>),\n",
       " 1284: tensor([0.7979], grad_fn=<SumBackward1>),\n",
       " 4149: tensor([0.7978], grad_fn=<SumBackward1>),\n",
       " 14266: tensor([0.7978], grad_fn=<SumBackward1>),\n",
       " 10095: tensor([0.7978], grad_fn=<SumBackward1>),\n",
       " 19293: tensor([0.7976], grad_fn=<SumBackward1>),\n",
       " 2123: tensor([0.7975], grad_fn=<SumBackward1>),\n",
       " 17883: tensor([0.7975], grad_fn=<SumBackward1>),\n",
       " 24121: tensor([0.7975], grad_fn=<SumBackward1>),\n",
       " 3619: tensor([0.7974], grad_fn=<SumBackward1>),\n",
       " 5567: tensor([0.7974], grad_fn=<SumBackward1>),\n",
       " 10153: tensor([0.7974], grad_fn=<SumBackward1>),\n",
       " 9914: tensor([0.7971], grad_fn=<SumBackward1>),\n",
       " 15642: tensor([0.7970], grad_fn=<SumBackward1>),\n",
       " 15780: tensor([0.7970], grad_fn=<SumBackward1>),\n",
       " 2239: tensor([0.7969], grad_fn=<SumBackward1>),\n",
       " 2854: tensor([0.7969], grad_fn=<SumBackward1>),\n",
       " 24165: tensor([0.7969], grad_fn=<SumBackward1>),\n",
       " 15414: tensor([0.7969], grad_fn=<SumBackward1>),\n",
       " 3504: tensor([0.7968], grad_fn=<SumBackward1>),\n",
       " 6641: tensor([0.7967], grad_fn=<SumBackward1>),\n",
       " 8737: tensor([0.7967], grad_fn=<SumBackward1>),\n",
       " 25268: tensor([0.7966], grad_fn=<SumBackward1>),\n",
       " 5517: tensor([0.7966], grad_fn=<SumBackward1>),\n",
       " 8958: tensor([0.7966], grad_fn=<SumBackward1>),\n",
       " 9638: tensor([0.7965], grad_fn=<SumBackward1>),\n",
       " 18169: tensor([0.7964], grad_fn=<SumBackward1>),\n",
       " 2814: tensor([0.7963], grad_fn=<SumBackward1>),\n",
       " 13089: tensor([0.7962], grad_fn=<SumBackward1>),\n",
       " 5544: tensor([0.7962], grad_fn=<SumBackward1>),\n",
       " 2474: tensor([0.7962], grad_fn=<SumBackward1>),\n",
       " 985: tensor([0.7961], grad_fn=<SumBackward1>),\n",
       " 5827: tensor([0.7961], grad_fn=<SumBackward1>),\n",
       " 3840: tensor([0.7961], grad_fn=<SumBackward1>),\n",
       " 13826: tensor([0.7960], grad_fn=<SumBackward1>),\n",
       " 21026: tensor([0.7960], grad_fn=<SumBackward1>),\n",
       " 24007: tensor([0.7959], grad_fn=<SumBackward1>),\n",
       " 818: tensor([0.7959], grad_fn=<SumBackward1>),\n",
       " 21521: tensor([0.7958], grad_fn=<SumBackward1>),\n",
       " 5705: tensor([0.7958], grad_fn=<SumBackward1>),\n",
       " 14005: tensor([0.7957], grad_fn=<SumBackward1>),\n",
       " 16672: tensor([0.7955], grad_fn=<SumBackward1>),\n",
       " 15012: tensor([0.7955], grad_fn=<SumBackward1>),\n",
       " 14966: tensor([0.7955], grad_fn=<SumBackward1>),\n",
       " 25337: tensor([0.7954], grad_fn=<SumBackward1>),\n",
       " 150: tensor([0.7954], grad_fn=<SumBackward1>),\n",
       " 3717: tensor([0.7954], grad_fn=<SumBackward1>),\n",
       " 25979: tensor([0.7951], grad_fn=<SumBackward1>),\n",
       " 1061: tensor([0.7950], grad_fn=<SumBackward1>),\n",
       " 23318: tensor([0.7949], grad_fn=<SumBackward1>),\n",
       " 4617: tensor([0.7948], grad_fn=<SumBackward1>),\n",
       " 20525: tensor([0.7948], grad_fn=<SumBackward1>),\n",
       " 21347: tensor([0.7947], grad_fn=<SumBackward1>),\n",
       " 18237: tensor([0.7947], grad_fn=<SumBackward1>),\n",
       " 3052: tensor([0.7946], grad_fn=<SumBackward1>),\n",
       " 8428: tensor([0.7945], grad_fn=<SumBackward1>),\n",
       " 19926: tensor([0.7944], grad_fn=<SumBackward1>),\n",
       " 1411: tensor([0.7944], grad_fn=<SumBackward1>),\n",
       " 6744: tensor([0.7943], grad_fn=<SumBackward1>),\n",
       " 20268: tensor([0.7943], grad_fn=<SumBackward1>),\n",
       " 6982: tensor([0.7943], grad_fn=<SumBackward1>),\n",
       " 24114: tensor([0.7943], grad_fn=<SumBackward1>),\n",
       " 16885: tensor([0.7941], grad_fn=<SumBackward1>),\n",
       " 10065: tensor([0.7940], grad_fn=<SumBackward1>),\n",
       " 5539: tensor([0.7939], grad_fn=<SumBackward1>),\n",
       " 12053: tensor([0.7938], grad_fn=<SumBackward1>),\n",
       " 21697: tensor([0.7937], grad_fn=<SumBackward1>),\n",
       " 1399: tensor([0.7936], grad_fn=<SumBackward1>),\n",
       " 4553: tensor([0.7936], grad_fn=<SumBackward1>),\n",
       " 21350: tensor([0.7935], grad_fn=<SumBackward1>),\n",
       " 11907: tensor([0.7935], grad_fn=<SumBackward1>),\n",
       " 4140: tensor([0.7934], grad_fn=<SumBackward1>),\n",
       " 14514: tensor([0.7934], grad_fn=<SumBackward1>),\n",
       " 13038: tensor([0.7934], grad_fn=<SumBackward1>),\n",
       " 6399: tensor([0.7934], grad_fn=<SumBackward1>),\n",
       " 18420: tensor([0.7933], grad_fn=<SumBackward1>),\n",
       " 11884: tensor([0.7933], grad_fn=<SumBackward1>),\n",
       " 25985: tensor([0.7933], grad_fn=<SumBackward1>),\n",
       " 6514: tensor([0.7933], grad_fn=<SumBackward1>),\n",
       " 4032: tensor([0.7932], grad_fn=<SumBackward1>),\n",
       " 13225: tensor([0.7932], grad_fn=<SumBackward1>),\n",
       " 280: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 223: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 609: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 11620: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 1439: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 16584: tensor([0.7929], grad_fn=<SumBackward1>),\n",
       " 22379: tensor([0.7927], grad_fn=<SumBackward1>),\n",
       " 22412: tensor([0.7927], grad_fn=<SumBackward1>),\n",
       " 13228: tensor([0.7927], grad_fn=<SumBackward1>),\n",
       " 26398: tensor([0.7927], grad_fn=<SumBackward1>),\n",
       " 14796: tensor([0.7927], grad_fn=<SumBackward1>),\n",
       " 18417: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 25901: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 16388: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 13345: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 10748: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 10968: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 12325: tensor([0.7926], grad_fn=<SumBackward1>),\n",
       " 22276: tensor([0.7925], grad_fn=<SumBackward1>),\n",
       " 8708: tensor([0.7925], grad_fn=<SumBackward1>),\n",
       " 25225: tensor([0.7925], grad_fn=<SumBackward1>),\n",
       " 7849: tensor([0.7924], grad_fn=<SumBackward1>),\n",
       " 2750: tensor([0.7923], grad_fn=<SumBackward1>),\n",
       " 4743: tensor([0.7922], grad_fn=<SumBackward1>),\n",
       " 25010: tensor([0.7921], grad_fn=<SumBackward1>),\n",
       " 19657: tensor([0.7921], grad_fn=<SumBackward1>),\n",
       " 14965: tensor([0.7920], grad_fn=<SumBackward1>),\n",
       " 4273: tensor([0.7920], grad_fn=<SumBackward1>),\n",
       " 11691: tensor([0.7920], grad_fn=<SumBackward1>),\n",
       " 10702: tensor([0.7919], grad_fn=<SumBackward1>),\n",
       " 2650: tensor([0.7919], grad_fn=<SumBackward1>),\n",
       " 3056: tensor([0.7918], grad_fn=<SumBackward1>),\n",
       " 6130: tensor([0.7918], grad_fn=<SumBackward1>),\n",
       " 15544: tensor([0.7917], grad_fn=<SumBackward1>),\n",
       " 14806: tensor([0.7917], grad_fn=<SumBackward1>),\n",
       " 2183: tensor([0.7916], grad_fn=<SumBackward1>),\n",
       " 11460: tensor([0.7916], grad_fn=<SumBackward1>),\n",
       " 2204: tensor([0.7916], grad_fn=<SumBackward1>),\n",
       " 9017: tensor([0.7916], grad_fn=<SumBackward1>),\n",
       " 14108: tensor([0.7915], grad_fn=<SumBackward1>),\n",
       " 4021: tensor([0.7914], grad_fn=<SumBackward1>),\n",
       " 23178: tensor([0.7914], grad_fn=<SumBackward1>),\n",
       " 18167: tensor([0.7913], grad_fn=<SumBackward1>),\n",
       " 6684: tensor([0.7912], grad_fn=<SumBackward1>),\n",
       " 9493: tensor([0.7911], grad_fn=<SumBackward1>),\n",
       " 8819: tensor([0.7911], grad_fn=<SumBackward1>),\n",
       " 18247: tensor([0.7910], grad_fn=<SumBackward1>),\n",
       " 2818: tensor([0.7910], grad_fn=<SumBackward1>),\n",
       " 2483: tensor([0.7909], grad_fn=<SumBackward1>),\n",
       " 17697: tensor([0.7909], grad_fn=<SumBackward1>),\n",
       " 20681: tensor([0.7908], grad_fn=<SumBackward1>),\n",
       " 9164: tensor([0.7908], grad_fn=<SumBackward1>),\n",
       " 26573: tensor([0.7908], grad_fn=<SumBackward1>),\n",
       " 8160: tensor([0.7907], grad_fn=<SumBackward1>),\n",
       " 11789: tensor([0.7907], grad_fn=<SumBackward1>),\n",
       " 7473: tensor([0.7906], grad_fn=<SumBackward1>),\n",
       " 19317: tensor([0.7906], grad_fn=<SumBackward1>),\n",
       " 20750: tensor([0.7905], grad_fn=<SumBackward1>),\n",
       " 4482: tensor([0.7905], grad_fn=<SumBackward1>),\n",
       " 10296: tensor([0.7904], grad_fn=<SumBackward1>),\n",
       " 4828: tensor([0.7904], grad_fn=<SumBackward1>),\n",
       " 21314: tensor([0.7904], grad_fn=<SumBackward1>),\n",
       " 23510: tensor([0.7903], grad_fn=<SumBackward1>),\n",
       " 4708: tensor([0.7903], grad_fn=<SumBackward1>),\n",
       " 8435: tensor([0.7902], grad_fn=<SumBackward1>),\n",
       " 14070: tensor([0.7902], grad_fn=<SumBackward1>),\n",
       " 16047: tensor([0.7902], grad_fn=<SumBackward1>),\n",
       " 20749: tensor([0.7901], grad_fn=<SumBackward1>),\n",
       " 10591: tensor([0.7901], grad_fn=<SumBackward1>),\n",
       " 14929: tensor([0.7901], grad_fn=<SumBackward1>),\n",
       " 4467: tensor([0.7900], grad_fn=<SumBackward1>),\n",
       " 11097: tensor([0.7898], grad_fn=<SumBackward1>),\n",
       " 20473: tensor([0.7898], grad_fn=<SumBackward1>),\n",
       " 2767: tensor([0.7896], grad_fn=<SumBackward1>),\n",
       " 25869: tensor([0.7895], grad_fn=<SumBackward1>),\n",
       " 6681: tensor([0.7895], grad_fn=<SumBackward1>),\n",
       " 13800: tensor([0.7894], grad_fn=<SumBackward1>),\n",
       " 1716: tensor([0.7894], grad_fn=<SumBackward1>),\n",
       " 25840: tensor([0.7893], grad_fn=<SumBackward1>),\n",
       " 3239: tensor([0.7892], grad_fn=<SumBackward1>),\n",
       " 22006: tensor([0.7892], grad_fn=<SumBackward1>),\n",
       " 9876: tensor([0.7891], grad_fn=<SumBackward1>),\n",
       " 24867: tensor([0.7891], grad_fn=<SumBackward1>),\n",
       " 23583: tensor([0.7891], grad_fn=<SumBackward1>),\n",
       " 18346: tensor([0.7890], grad_fn=<SumBackward1>),\n",
       " 16852: tensor([0.7889], grad_fn=<SumBackward1>),\n",
       " 21865: tensor([0.7888], grad_fn=<SumBackward1>),\n",
       " 25483: tensor([0.7888], grad_fn=<SumBackward1>),\n",
       " 15730: tensor([0.7887], grad_fn=<SumBackward1>),\n",
       " 8315: tensor([0.7885], grad_fn=<SumBackward1>),\n",
       " 3627: tensor([0.7885], grad_fn=<SumBackward1>),\n",
       " 23164: tensor([0.7884], grad_fn=<SumBackward1>),\n",
       " 21471: tensor([0.7883], grad_fn=<SumBackward1>),\n",
       " 11855: tensor([0.7883], grad_fn=<SumBackward1>),\n",
       " 17202: tensor([0.7883], grad_fn=<SumBackward1>),\n",
       " 17913: tensor([0.7883], grad_fn=<SumBackward1>),\n",
       " 24932: tensor([0.7882], grad_fn=<SumBackward1>),\n",
       " 10792: tensor([0.7882], grad_fn=<SumBackward1>),\n",
       " 14314: tensor([0.7881], grad_fn=<SumBackward1>),\n",
       " 24113: tensor([0.7881], grad_fn=<SumBackward1>),\n",
       " 18400: tensor([0.7881], grad_fn=<SumBackward1>),\n",
       " 20987: tensor([0.7880], grad_fn=<SumBackward1>),\n",
       " 18754: tensor([0.7880], grad_fn=<SumBackward1>),\n",
       " 22920: tensor([0.7879], grad_fn=<SumBackward1>),\n",
       " 23035: tensor([0.7878], grad_fn=<SumBackward1>),\n",
       " 490: tensor([0.7878], grad_fn=<SumBackward1>),\n",
       " 9516: tensor([0.7878], grad_fn=<SumBackward1>),\n",
       " 19201: tensor([0.7877], grad_fn=<SumBackward1>),\n",
       " 9867: tensor([0.7877], grad_fn=<SumBackward1>),\n",
       " 25870: tensor([0.7876], grad_fn=<SumBackward1>),\n",
       " 10138: tensor([0.7875], grad_fn=<SumBackward1>),\n",
       " 21159: tensor([0.7874], grad_fn=<SumBackward1>),\n",
       " 6317: tensor([0.7874], grad_fn=<SumBackward1>),\n",
       " 26215: tensor([0.7874], grad_fn=<SumBackward1>),\n",
       " 6436: tensor([0.7873], grad_fn=<SumBackward1>),\n",
       " 10490: tensor([0.7872], grad_fn=<SumBackward1>),\n",
       " 4833: tensor([0.7872], grad_fn=<SumBackward1>),\n",
       " 2307: tensor([0.7870], grad_fn=<SumBackward1>),\n",
       " 6170: tensor([0.7870], grad_fn=<SumBackward1>),\n",
       " 2905: tensor([0.7869], grad_fn=<SumBackward1>),\n",
       " 11185: tensor([0.7869], grad_fn=<SumBackward1>),\n",
       " 1691: tensor([0.7868], grad_fn=<SumBackward1>),\n",
       " 19610: tensor([0.7868], grad_fn=<SumBackward1>),\n",
       " 14543: tensor([0.7867], grad_fn=<SumBackward1>),\n",
       " 7188: tensor([0.7867], grad_fn=<SumBackward1>),\n",
       " 465: tensor([0.7867], grad_fn=<SumBackward1>),\n",
       " 6325: tensor([0.7867], grad_fn=<SumBackward1>),\n",
       " 19981: tensor([0.7866], grad_fn=<SumBackward1>),\n",
       " 20820: tensor([0.7865], grad_fn=<SumBackward1>),\n",
       " 15002: tensor([0.7865], grad_fn=<SumBackward1>),\n",
       " 22636: tensor([0.7863], grad_fn=<SumBackward1>),\n",
       " 11942: tensor([0.7863], grad_fn=<SumBackward1>),\n",
       " 14430: tensor([0.7863], grad_fn=<SumBackward1>),\n",
       " 2993: tensor([0.7861], grad_fn=<SumBackward1>),\n",
       " 10542: tensor([0.7860], grad_fn=<SumBackward1>),\n",
       " 21708: tensor([0.7860], grad_fn=<SumBackward1>),\n",
       " 20879: tensor([0.7860], grad_fn=<SumBackward1>),\n",
       " 8106: tensor([0.7859], grad_fn=<SumBackward1>),\n",
       " 2253: tensor([0.7858], grad_fn=<SumBackward1>),\n",
       " 11153: tensor([0.7856], grad_fn=<SumBackward1>),\n",
       " 21769: tensor([0.7856], grad_fn=<SumBackward1>),\n",
       " 2141: tensor([0.7856], grad_fn=<SumBackward1>),\n",
       " 25143: tensor([0.7856], grad_fn=<SumBackward1>),\n",
       " 6309: tensor([0.7856], grad_fn=<SumBackward1>),\n",
       " 400: tensor([0.7855], grad_fn=<SumBackward1>),\n",
       " 20974: tensor([0.7855], grad_fn=<SumBackward1>),\n",
       " 68: tensor([0.7854], grad_fn=<SumBackward1>),\n",
       " 6319: tensor([0.7854], grad_fn=<SumBackward1>),\n",
       " 11296: tensor([0.7853], grad_fn=<SumBackward1>),\n",
       " 10794: tensor([0.7853], grad_fn=<SumBackward1>),\n",
       " 9094: tensor([0.7853], grad_fn=<SumBackward1>),\n",
       " 18569: tensor([0.7851], grad_fn=<SumBackward1>),\n",
       " 10932: tensor([0.7851], grad_fn=<SumBackward1>),\n",
       " 19588: tensor([0.7848], grad_fn=<SumBackward1>),\n",
       " 2678: tensor([0.7848], grad_fn=<SumBackward1>),\n",
       " 25073: tensor([0.7846], grad_fn=<SumBackward1>),\n",
       " 13524: tensor([0.7846], grad_fn=<SumBackward1>),\n",
       " 20403: tensor([0.7846], grad_fn=<SumBackward1>),\n",
       " 7637: tensor([0.7845], grad_fn=<SumBackward1>),\n",
       " 10584: tensor([0.7845], grad_fn=<SumBackward1>),\n",
       " 2566: tensor([0.7845], grad_fn=<SumBackward1>),\n",
       " 3518: tensor([0.7845], grad_fn=<SumBackward1>),\n",
       " 18786: tensor([0.7844], grad_fn=<SumBackward1>),\n",
       " 21250: tensor([0.7844], grad_fn=<SumBackward1>),\n",
       " 6628: tensor([0.7841], grad_fn=<SumBackward1>),\n",
       " 4771: tensor([0.7841], grad_fn=<SumBackward1>),\n",
       " 18519: tensor([0.7841], grad_fn=<SumBackward1>),\n",
       " 16567: tensor([0.7841], grad_fn=<SumBackward1>),\n",
       " 5179: tensor([0.7841], grad_fn=<SumBackward1>),\n",
       " 16116: tensor([0.7840], grad_fn=<SumBackward1>),\n",
       " 7752: tensor([0.7840], grad_fn=<SumBackward1>),\n",
       " 1924: tensor([0.7840], grad_fn=<SumBackward1>),\n",
       " 5996: tensor([0.7839], grad_fn=<SumBackward1>),\n",
       " 25346: tensor([0.7839], grad_fn=<SumBackward1>),\n",
       " 7373: tensor([0.7838], grad_fn=<SumBackward1>),\n",
       " 11233: tensor([0.7837], grad_fn=<SumBackward1>),\n",
       " 7066: tensor([0.7836], grad_fn=<SumBackward1>),\n",
       " 13131: tensor([0.7836], grad_fn=<SumBackward1>),\n",
       " 12785: tensor([0.7836], grad_fn=<SumBackward1>),\n",
       " 20288: tensor([0.7835], grad_fn=<SumBackward1>),\n",
       " 7791: tensor([0.7834], grad_fn=<SumBackward1>),\n",
       " 878: tensor([0.7834], grad_fn=<SumBackward1>),\n",
       " 7262: tensor([0.7834], grad_fn=<SumBackward1>),\n",
       " 21039: tensor([0.7834], grad_fn=<SumBackward1>),\n",
       " 20321: tensor([0.7833], grad_fn=<SumBackward1>),\n",
       " 21789: tensor([0.7833], grad_fn=<SumBackward1>),\n",
       " 14180: tensor([0.7833], grad_fn=<SumBackward1>),\n",
       " 6320: tensor([0.7833], grad_fn=<SumBackward1>),\n",
       " 6735: tensor([0.7832], grad_fn=<SumBackward1>),\n",
       " 4129: tensor([0.7832], grad_fn=<SumBackward1>),\n",
       " 17512: tensor([0.7832], grad_fn=<SumBackward1>),\n",
       " 17451: tensor([0.7831], grad_fn=<SumBackward1>),\n",
       " 849: tensor([0.7831], grad_fn=<SumBackward1>),\n",
       " 16119: tensor([0.7828], grad_fn=<SumBackward1>),\n",
       " 24718: tensor([0.7827], grad_fn=<SumBackward1>),\n",
       " 25026: tensor([0.7827], grad_fn=<SumBackward1>),\n",
       " 9257: tensor([0.7827], grad_fn=<SumBackward1>),\n",
       " 23493: tensor([0.7827], grad_fn=<SumBackward1>),\n",
       " 10173: tensor([0.7827], grad_fn=<SumBackward1>),\n",
       " 9809: tensor([0.7826], grad_fn=<SumBackward1>),\n",
       " 13717: tensor([0.7826], grad_fn=<SumBackward1>),\n",
       " 11250: tensor([0.7826], grad_fn=<SumBackward1>),\n",
       " 8784: tensor([0.7826], grad_fn=<SumBackward1>),\n",
       " 22533: tensor([0.7825], grad_fn=<SumBackward1>),\n",
       " 18574: tensor([0.7824], grad_fn=<SumBackward1>),\n",
       " 7222: tensor([0.7823], grad_fn=<SumBackward1>),\n",
       " 1162: tensor([0.7821], grad_fn=<SumBackward1>),\n",
       " 16900: tensor([0.7820], grad_fn=<SumBackward1>),\n",
       " 4695: tensor([0.7820], grad_fn=<SumBackward1>),\n",
       " 6578: tensor([0.7820], grad_fn=<SumBackward1>),\n",
       " 18910: tensor([0.7819], grad_fn=<SumBackward1>),\n",
       " 20621: tensor([0.7819], grad_fn=<SumBackward1>),\n",
       " 3221: tensor([0.7819], grad_fn=<SumBackward1>),\n",
       " 22790: tensor([0.7819], grad_fn=<SumBackward1>),\n",
       " 18524: tensor([0.7819], grad_fn=<SumBackward1>),\n",
       " 2765: tensor([0.7818], grad_fn=<SumBackward1>),\n",
       " 15709: tensor([0.7818], grad_fn=<SumBackward1>),\n",
       " 11242: tensor([0.7818], grad_fn=<SumBackward1>),\n",
       " 6724: tensor([0.7817], grad_fn=<SumBackward1>),\n",
       " 2192: tensor([0.7817], grad_fn=<SumBackward1>),\n",
       " 20144: tensor([0.7816], grad_fn=<SumBackward1>),\n",
       " 8146: tensor([0.7816], grad_fn=<SumBackward1>),\n",
       " 16840: tensor([0.7816], grad_fn=<SumBackward1>),\n",
       " 9220: tensor([0.7816], grad_fn=<SumBackward1>),\n",
       " 10140: tensor([0.7815], grad_fn=<SumBackward1>),\n",
       " 5741: tensor([0.7815], grad_fn=<SumBackward1>),\n",
       " 9524: tensor([0.7815], grad_fn=<SumBackward1>),\n",
       " 5704: tensor([0.7814], grad_fn=<SumBackward1>),\n",
       " 21176: tensor([0.7814], grad_fn=<SumBackward1>),\n",
       " 22072: tensor([0.7814], grad_fn=<SumBackward1>),\n",
       " 9612: tensor([0.7814], grad_fn=<SumBackward1>),\n",
       " 9588: tensor([0.7813], grad_fn=<SumBackward1>),\n",
       " 15220: tensor([0.7813], grad_fn=<SumBackward1>),\n",
       " 14807: tensor([0.7812], grad_fn=<SumBackward1>),\n",
       " 25549: tensor([0.7812], grad_fn=<SumBackward1>),\n",
       " 20003: tensor([0.7812], grad_fn=<SumBackward1>),\n",
       " 682: tensor([0.7812], grad_fn=<SumBackward1>),\n",
       " 23416: tensor([0.7811], grad_fn=<SumBackward1>),\n",
       " 612: tensor([0.7811], grad_fn=<SumBackward1>),\n",
       " 22413: tensor([0.7810], grad_fn=<SumBackward1>),\n",
       " 11176: tensor([0.7810], grad_fn=<SumBackward1>),\n",
       " 9267: tensor([0.7810], grad_fn=<SumBackward1>),\n",
       " 16492: tensor([0.7810], grad_fn=<SumBackward1>),\n",
       " 10159: tensor([0.7809], grad_fn=<SumBackward1>),\n",
       " 2926: tensor([0.7809], grad_fn=<SumBackward1>),\n",
       " 19108: tensor([0.7809], grad_fn=<SumBackward1>),\n",
       " 1130: tensor([0.7809], grad_fn=<SumBackward1>),\n",
       " 22668: tensor([0.7809], grad_fn=<SumBackward1>),\n",
       " 14076: tensor([0.7808], grad_fn=<SumBackward1>),\n",
       " 4645: tensor([0.7808], grad_fn=<SumBackward1>),\n",
       " 14693: tensor([0.7808], grad_fn=<SumBackward1>),\n",
       " 3291: tensor([0.7808], grad_fn=<SumBackward1>),\n",
       " 25756: tensor([0.7807], grad_fn=<SumBackward1>),\n",
       " 18588: tensor([0.7806], grad_fn=<SumBackward1>),\n",
       " 18202: tensor([0.7806], grad_fn=<SumBackward1>),\n",
       " 4579: tensor([0.7806], grad_fn=<SumBackward1>),\n",
       " 24925: tensor([0.7805], grad_fn=<SumBackward1>),\n",
       " 9121: tensor([0.7805], grad_fn=<SumBackward1>),\n",
       " 7346: tensor([0.7805], grad_fn=<SumBackward1>),\n",
       " 12915: tensor([0.7804], grad_fn=<SumBackward1>),\n",
       " 10436: tensor([0.7804], grad_fn=<SumBackward1>),\n",
       " 5907: tensor([0.7804], grad_fn=<SumBackward1>),\n",
       " 1125: tensor([0.7803], grad_fn=<SumBackward1>),\n",
       " 20497: tensor([0.7803], grad_fn=<SumBackward1>),\n",
       " 1540: tensor([0.7802], grad_fn=<SumBackward1>),\n",
       " 12045: tensor([0.7802], grad_fn=<SumBackward1>),\n",
       " 10775: tensor([0.7802], grad_fn=<SumBackward1>),\n",
       " 10659: tensor([0.7802], grad_fn=<SumBackward1>),\n",
       " 26078: tensor([0.7801], grad_fn=<SumBackward1>),\n",
       " 26541: tensor([0.7801], grad_fn=<SumBackward1>),\n",
       " 18580: tensor([0.7801], grad_fn=<SumBackward1>),\n",
       " 10951: tensor([0.7800], grad_fn=<SumBackward1>),\n",
       " 14592: tensor([0.7799], grad_fn=<SumBackward1>),\n",
       " 19330: tensor([0.7799], grad_fn=<SumBackward1>),\n",
       " 20514: tensor([0.7799], grad_fn=<SumBackward1>),\n",
       " 14470: tensor([0.7799], grad_fn=<SumBackward1>),\n",
       " 15337: tensor([0.7799], grad_fn=<SumBackward1>),\n",
       " 1413: tensor([0.7798], grad_fn=<SumBackward1>),\n",
       " 11501: tensor([0.7796], grad_fn=<SumBackward1>),\n",
       " 7571: tensor([0.7796], grad_fn=<SumBackward1>),\n",
       " 25986: tensor([0.7796], grad_fn=<SumBackward1>),\n",
       " 24060: tensor([0.7795], grad_fn=<SumBackward1>),\n",
       " 22738: tensor([0.7795], grad_fn=<SumBackward1>),\n",
       " 5619: tensor([0.7794], grad_fn=<SumBackward1>),\n",
       " 25545: tensor([0.7794], grad_fn=<SumBackward1>),\n",
       " 14184: tensor([0.7793], grad_fn=<SumBackward1>),\n",
       " 26491: tensor([0.7793], grad_fn=<SumBackward1>),\n",
       " 1573: tensor([0.7792], grad_fn=<SumBackward1>),\n",
       " 15443: tensor([0.7792], grad_fn=<SumBackward1>),\n",
       " 2201: tensor([0.7792], grad_fn=<SumBackward1>),\n",
       " 25388: tensor([0.7791], grad_fn=<SumBackward1>),\n",
       " 22883: tensor([0.7791], grad_fn=<SumBackward1>),\n",
       " 1905: tensor([0.7791], grad_fn=<SumBackward1>),\n",
       " 11915: tensor([0.7790], grad_fn=<SumBackward1>),\n",
       " 18041: tensor([0.7789], grad_fn=<SumBackward1>),\n",
       " 24588: tensor([0.7789], grad_fn=<SumBackward1>),\n",
       " 8454: tensor([0.7789], grad_fn=<SumBackward1>),\n",
       " 13728: tensor([0.7787], grad_fn=<SumBackward1>),\n",
       " 2580: tensor([0.7786], grad_fn=<SumBackward1>),\n",
       " 21452: tensor([0.7786], grad_fn=<SumBackward1>),\n",
       " 23790: tensor([0.7786], grad_fn=<SumBackward1>),\n",
       " 19429: tensor([0.7785], grad_fn=<SumBackward1>),\n",
       " 21941: tensor([0.7785], grad_fn=<SumBackward1>),\n",
       " 25597: tensor([0.7785], grad_fn=<SumBackward1>),\n",
       " 2709: tensor([0.7784], grad_fn=<SumBackward1>),\n",
       " 7666: tensor([0.7784], grad_fn=<SumBackward1>),\n",
       " 22511: tensor([0.7783], grad_fn=<SumBackward1>),\n",
       " 11231: tensor([0.7783], grad_fn=<SumBackward1>),\n",
       " 6308: tensor([0.7782], grad_fn=<SumBackward1>),\n",
       " 25927: tensor([0.7782], grad_fn=<SumBackward1>),\n",
       " 35: tensor([0.7782], grad_fn=<SumBackward1>),\n",
       " 9011: tensor([0.7781], grad_fn=<SumBackward1>),\n",
       " 24495: tensor([0.7781], grad_fn=<SumBackward1>),\n",
       " 2320: tensor([0.7781], grad_fn=<SumBackward1>),\n",
       " 4688: tensor([0.7781], grad_fn=<SumBackward1>),\n",
       " 7386: tensor([0.7780], grad_fn=<SumBackward1>),\n",
       " 9343: tensor([0.7780], grad_fn=<SumBackward1>),\n",
       " 4569: tensor([0.7780], grad_fn=<SumBackward1>),\n",
       " 2297: tensor([0.7780], grad_fn=<SumBackward1>),\n",
       " 3220: tensor([0.7779], grad_fn=<SumBackward1>),\n",
       " 17558: tensor([0.7779], grad_fn=<SumBackward1>),\n",
       " 25676: tensor([0.7779], grad_fn=<SumBackward1>),\n",
       " 19505: tensor([0.7778], grad_fn=<SumBackward1>),\n",
       " 2284: tensor([0.7778], grad_fn=<SumBackward1>),\n",
       " 8871: tensor([0.7778], grad_fn=<SumBackward1>),\n",
       " 5341: tensor([0.7777], grad_fn=<SumBackward1>),\n",
       " 1381: tensor([0.7777], grad_fn=<SumBackward1>),\n",
       " 8227: tensor([0.7777], grad_fn=<SumBackward1>),\n",
       " 21492: tensor([0.7777], grad_fn=<SumBackward1>),\n",
       " 20716: tensor([0.7776], grad_fn=<SumBackward1>),\n",
       " 1438: tensor([0.7776], grad_fn=<SumBackward1>),\n",
       " 18445: tensor([0.7775], grad_fn=<SumBackward1>),\n",
       " 8207: tensor([0.7775], grad_fn=<SumBackward1>),\n",
       " 25741: tensor([0.7775], grad_fn=<SumBackward1>),\n",
       " 4777: tensor([0.7774], grad_fn=<SumBackward1>),\n",
       " 9162: tensor([0.7773], grad_fn=<SumBackward1>),\n",
       " 19450: tensor([0.7770], grad_fn=<SumBackward1>),\n",
       " 19824: tensor([0.7770], grad_fn=<SumBackward1>),\n",
       " 20192: tensor([0.7770], grad_fn=<SumBackward1>),\n",
       " 22978: tensor([0.7769], grad_fn=<SumBackward1>),\n",
       " 2311: tensor([0.7768], grad_fn=<SumBackward1>),\n",
       " 19022: tensor([0.7768], grad_fn=<SumBackward1>),\n",
       " 7691: tensor([0.7768], grad_fn=<SumBackward1>),\n",
       " 22155: tensor([0.7767], grad_fn=<SumBackward1>),\n",
       " 8164: tensor([0.7767], grad_fn=<SumBackward1>),\n",
       " 6411: tensor([0.7766], grad_fn=<SumBackward1>),\n",
       " 18184: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 1528: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 22519: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 4039: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 6835: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 15885: tensor([0.7765], grad_fn=<SumBackward1>),\n",
       " 10421: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 15989: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 11422: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 20118: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 6352: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 6881: tensor([0.7764], grad_fn=<SumBackward1>),\n",
       " 20266: tensor([0.7763], grad_fn=<SumBackward1>),\n",
       " 15161: tensor([0.7763], grad_fn=<SumBackward1>),\n",
       " 12356: tensor([0.7763], grad_fn=<SumBackward1>),\n",
       " 22787: tensor([0.7762], grad_fn=<SumBackward1>),\n",
       " 4988: tensor([0.7762], grad_fn=<SumBackward1>),\n",
       " 17014: tensor([0.7761], grad_fn=<SumBackward1>),\n",
       " 22980: tensor([0.7761], grad_fn=<SumBackward1>),\n",
       " 13080: tensor([0.7760], grad_fn=<SumBackward1>),\n",
       " 20864: tensor([0.7760], grad_fn=<SumBackward1>),\n",
       " 24025: tensor([0.7760], grad_fn=<SumBackward1>),\n",
       " 8780: tensor([0.7759], grad_fn=<SumBackward1>),\n",
       " 18974: tensor([0.7759], grad_fn=<SumBackward1>),\n",
       " 26139: tensor([0.7758], grad_fn=<SumBackward1>),\n",
       " 15232: tensor([0.7758], grad_fn=<SumBackward1>),\n",
       " 25444: tensor([0.7758], grad_fn=<SumBackward1>),\n",
       " 25556: tensor([0.7757], grad_fn=<SumBackward1>),\n",
       " 7731: tensor([0.7757], grad_fn=<SumBackward1>),\n",
       " 25454: tensor([0.7757], grad_fn=<SumBackward1>),\n",
       " 9629: tensor([0.7756], grad_fn=<SumBackward1>),\n",
       " 8229: tensor([0.7756], grad_fn=<SumBackward1>),\n",
       " 3571: tensor([0.7755], grad_fn=<SumBackward1>),\n",
       " 20103: tensor([0.7755], grad_fn=<SumBackward1>),\n",
       " 4112: tensor([0.7755], grad_fn=<SumBackward1>),\n",
       " 20990: tensor([0.7755], grad_fn=<SumBackward1>),\n",
       " 2721: tensor([0.7754], grad_fn=<SumBackward1>),\n",
       " 2513: tensor([0.7753], grad_fn=<SumBackward1>),\n",
       " 7210: tensor([0.7753], grad_fn=<SumBackward1>),\n",
       " 883: tensor([0.7753], grad_fn=<SumBackward1>),\n",
       " 23856: tensor([0.7752], grad_fn=<SumBackward1>),\n",
       " 6324: tensor([0.7752], grad_fn=<SumBackward1>),\n",
       " 7306: tensor([0.7752], grad_fn=<SumBackward1>),\n",
       " 20978: tensor([0.7750], grad_fn=<SumBackward1>),\n",
       " 20600: tensor([0.7750], grad_fn=<SumBackward1>),\n",
       " 18044: tensor([0.7749], grad_fn=<SumBackward1>),\n",
       " 24340: tensor([0.7749], grad_fn=<SumBackward1>),\n",
       " 16530: tensor([0.7747], grad_fn=<SumBackward1>),\n",
       " 26192: tensor([0.7747], grad_fn=<SumBackward1>),\n",
       " 3019: tensor([0.7747], grad_fn=<SumBackward1>),\n",
       " 20758: tensor([0.7747], grad_fn=<SumBackward1>),\n",
       " 15236: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 4795: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 21893: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 1156: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 1888: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 17536: tensor([0.7746], grad_fn=<SumBackward1>),\n",
       " 2945: tensor([0.7745], grad_fn=<SumBackward1>),\n",
       " 585: tensor([0.7745], grad_fn=<SumBackward1>),\n",
       " 15902: tensor([0.7745], grad_fn=<SumBackward1>),\n",
       " 16227: tensor([0.7745], grad_fn=<SumBackward1>),\n",
       " 12877: tensor([0.7744], grad_fn=<SumBackward1>),\n",
       " 22103: tensor([0.7744], grad_fn=<SumBackward1>),\n",
       " 9034: tensor([0.7744], grad_fn=<SumBackward1>),\n",
       " 19322: tensor([0.7743], grad_fn=<SumBackward1>),\n",
       " 6691: tensor([0.7743], grad_fn=<SumBackward1>),\n",
       " 17005: tensor([0.7743], grad_fn=<SumBackward1>),\n",
       " 526: tensor([0.7742], grad_fn=<SumBackward1>),\n",
       " 8749: tensor([0.7742], grad_fn=<SumBackward1>),\n",
       " 24790: tensor([0.7742], grad_fn=<SumBackward1>),\n",
       " 8578: tensor([0.7741], grad_fn=<SumBackward1>),\n",
       " 16231: tensor([0.7741], grad_fn=<SumBackward1>),\n",
       " 26540: tensor([0.7741], grad_fn=<SumBackward1>),\n",
       " 18480: tensor([0.7741], grad_fn=<SumBackward1>),\n",
       " 14635: tensor([0.7740], grad_fn=<SumBackward1>),\n",
       " 22382: tensor([0.7740], grad_fn=<SumBackward1>),\n",
       " 162: tensor([0.7740], grad_fn=<SumBackward1>),\n",
       " 15778: tensor([0.7739], grad_fn=<SumBackward1>),\n",
       " 8238: tensor([0.7739], grad_fn=<SumBackward1>),\n",
       " 13975: tensor([0.7739], grad_fn=<SumBackward1>),\n",
       " 5298: tensor([0.7739], grad_fn=<SumBackward1>),\n",
       " 18266: tensor([0.7739], grad_fn=<SumBackward1>),\n",
       " 9545: tensor([0.7738], grad_fn=<SumBackward1>),\n",
       " 7375: tensor([0.7737], grad_fn=<SumBackward1>),\n",
       " 13538: tensor([0.7736], grad_fn=<SumBackward1>),\n",
       " 13464: tensor([0.7735], grad_fn=<SumBackward1>),\n",
       " 18066: tensor([0.7734], grad_fn=<SumBackward1>),\n",
       " 17804: tensor([0.7733], grad_fn=<SumBackward1>),\n",
       " 9110: tensor([0.7733], grad_fn=<SumBackward1>),\n",
       " 82: tensor([0.7733], grad_fn=<SumBackward1>),\n",
       " 3845: tensor([0.7732], grad_fn=<SumBackward1>),\n",
       " 13420: tensor([0.7732], grad_fn=<SumBackward1>),\n",
       " 18213: tensor([0.7731], grad_fn=<SumBackward1>),\n",
       " 12389: tensor([0.7730], grad_fn=<SumBackward1>),\n",
       " 14556: tensor([0.7728], grad_fn=<SumBackward1>),\n",
       " 242: tensor([0.7728], grad_fn=<SumBackward1>),\n",
       " 25360: tensor([0.7727], grad_fn=<SumBackward1>),\n",
       " 11253: tensor([0.7727], grad_fn=<SumBackward1>),\n",
       " 9721: tensor([0.7727], grad_fn=<SumBackward1>),\n",
       " 18138: tensor([0.7726], grad_fn=<SumBackward1>),\n",
       " 13798: tensor([0.7726], grad_fn=<SumBackward1>),\n",
       " 16010: tensor([0.7726], grad_fn=<SumBackward1>),\n",
       " 14316: tensor([0.7726], grad_fn=<SumBackward1>),\n",
       " 22556: tensor([0.7724], grad_fn=<SumBackward1>),\n",
       " 24821: tensor([0.7724], grad_fn=<SumBackward1>),\n",
       " 23168: tensor([0.7724], grad_fn=<SumBackward1>),\n",
       " 19552: tensor([0.7723], grad_fn=<SumBackward1>),\n",
       " 6613: tensor([0.7722], grad_fn=<SumBackward1>),\n",
       " 9891: tensor([0.7720], grad_fn=<SumBackward1>),\n",
       " 20081: tensor([0.7719], grad_fn=<SumBackward1>),\n",
       " 21820: tensor([0.7719], grad_fn=<SumBackward1>),\n",
       " 26652: tensor([0.7719], grad_fn=<SumBackward1>),\n",
       " 22450: tensor([0.7719], grad_fn=<SumBackward1>),\n",
       " 2227: tensor([0.7718], grad_fn=<SumBackward1>),\n",
       " 7848: tensor([0.7718], grad_fn=<SumBackward1>),\n",
       " 19088: tensor([0.7717], grad_fn=<SumBackward1>),\n",
       " 11214: tensor([0.7717], grad_fn=<SumBackward1>),\n",
       " 57: tensor([0.7717], grad_fn=<SumBackward1>),\n",
       " 2391: tensor([0.7717], grad_fn=<SumBackward1>),\n",
       " 18537: tensor([0.7716], grad_fn=<SumBackward1>),\n",
       " 2219: tensor([0.7716], grad_fn=<SumBackward1>),\n",
       " 12813: tensor([0.7716], grad_fn=<SumBackward1>),\n",
       " 16384: tensor([0.7716], grad_fn=<SumBackward1>),\n",
       " 26118: tensor([0.7715], grad_fn=<SumBackward1>),\n",
       " 3680: tensor([0.7715], grad_fn=<SumBackward1>),\n",
       " 4694: tensor([0.7715], grad_fn=<SumBackward1>),\n",
       " 14666: tensor([0.7714], grad_fn=<SumBackward1>),\n",
       " 376: tensor([0.7714], grad_fn=<SumBackward1>),\n",
       " 16223: tensor([0.7713], grad_fn=<SumBackward1>),\n",
       " 21608: tensor([0.7713], grad_fn=<SumBackward1>),\n",
       " 3657: tensor([0.7712], grad_fn=<SumBackward1>),\n",
       " 457: tensor([0.7712], grad_fn=<SumBackward1>),\n",
       " 11900: tensor([0.7711], grad_fn=<SumBackward1>),\n",
       " 7139: tensor([0.7711], grad_fn=<SumBackward1>),\n",
       " 11786: tensor([0.7711], grad_fn=<SumBackward1>),\n",
       " 15699: tensor([0.7710], grad_fn=<SumBackward1>),\n",
       " 6828: tensor([0.7710], grad_fn=<SumBackward1>),\n",
       " 18556: tensor([0.7709], grad_fn=<SumBackward1>),\n",
       " 21810: tensor([0.7709], grad_fn=<SumBackward1>),\n",
       " 2618: tensor([0.7708], grad_fn=<SumBackward1>),\n",
       " 17848: tensor([0.7708], grad_fn=<SumBackward1>),\n",
       " 14962: tensor([0.7708], grad_fn=<SumBackward1>),\n",
       " 3274: tensor([0.7707], grad_fn=<SumBackward1>),\n",
       " 18365: tensor([0.7707], grad_fn=<SumBackward1>),\n",
       " 10259: tensor([0.7707], grad_fn=<SumBackward1>),\n",
       " 2725: tensor([0.7706], grad_fn=<SumBackward1>),\n",
       " 10612: tensor([0.7706], grad_fn=<SumBackward1>),\n",
       " 12466: tensor([0.7705], grad_fn=<SumBackward1>),\n",
       " 6945: tensor([0.7705], grad_fn=<SumBackward1>),\n",
       " 9258: tensor([0.7704], grad_fn=<SumBackward1>),\n",
       " 7736: tensor([0.7704], grad_fn=<SumBackward1>),\n",
       " 14188: tensor([0.7703], grad_fn=<SumBackward1>),\n",
       " 16446: tensor([0.7703], grad_fn=<SumBackward1>),\n",
       " 23061: tensor([0.7703], grad_fn=<SumBackward1>),\n",
       " 23635: tensor([0.7702], grad_fn=<SumBackward1>),\n",
       " 10258: tensor([0.7702], grad_fn=<SumBackward1>),\n",
       " 6793: tensor([0.7702], grad_fn=<SumBackward1>),\n",
       " 12074: tensor([0.7702], grad_fn=<SumBackward1>),\n",
       " 22732: tensor([0.7701], grad_fn=<SumBackward1>),\n",
       " 17269: tensor([0.7701], grad_fn=<SumBackward1>),\n",
       " 8268: tensor([0.7701], grad_fn=<SumBackward1>),\n",
       " 1584: tensor([0.7701], grad_fn=<SumBackward1>),\n",
       " 26614: tensor([0.7701], grad_fn=<SumBackward1>),\n",
       " 15827: tensor([0.7700], grad_fn=<SumBackward1>),\n",
       " 7345: tensor([0.7700], grad_fn=<SumBackward1>),\n",
       " 4640: tensor([0.7700], grad_fn=<SumBackward1>),\n",
       " 10164: tensor([0.7700], grad_fn=<SumBackward1>),\n",
       " 10119: tensor([0.7700], grad_fn=<SumBackward1>),\n",
       " 24417: tensor([0.7699], grad_fn=<SumBackward1>),\n",
       " 13542: tensor([0.7699], grad_fn=<SumBackward1>),\n",
       " 21573: tensor([0.7699], grad_fn=<SumBackward1>),\n",
       " 14844: tensor([0.7699], grad_fn=<SumBackward1>),\n",
       " 7404: tensor([0.7699], grad_fn=<SumBackward1>),\n",
       " 15639: tensor([0.7698], grad_fn=<SumBackward1>),\n",
       " 21164: tensor([0.7698], grad_fn=<SumBackward1>),\n",
       " 8006: tensor([0.7698], grad_fn=<SumBackward1>),\n",
       " 8833: tensor([0.7698], grad_fn=<SumBackward1>),\n",
       " 844: tensor([0.7698], grad_fn=<SumBackward1>),\n",
       " 13597: tensor([0.7697], grad_fn=<SumBackward1>),\n",
       " 16279: tensor([0.7697], grad_fn=<SumBackward1>),\n",
       " 4352: tensor([0.7697], grad_fn=<SumBackward1>),\n",
       " 11152: tensor([0.7697], grad_fn=<SumBackward1>),\n",
       " 803: tensor([0.7697], grad_fn=<SumBackward1>),\n",
       " 17825: tensor([0.7696], grad_fn=<SumBackward1>),\n",
       " 5915: tensor([0.7696], grad_fn=<SumBackward1>),\n",
       " 8890: tensor([0.7696], grad_fn=<SumBackward1>),\n",
       " 14394: tensor([0.7696], grad_fn=<SumBackward1>),\n",
       " 20753: tensor([0.7695], grad_fn=<SumBackward1>),\n",
       " 25379: tensor([0.7695], grad_fn=<SumBackward1>),\n",
       " 10186: tensor([0.7694], grad_fn=<SumBackward1>),\n",
       " 4881: tensor([0.7694], grad_fn=<SumBackward1>),\n",
       " 3719: tensor([0.7694], grad_fn=<SumBackward1>),\n",
       " 10809: tensor([0.7693], grad_fn=<SumBackward1>),\n",
       " 14297: tensor([0.7693], grad_fn=<SumBackward1>),\n",
       " 6689: tensor([0.7693], grad_fn=<SumBackward1>),\n",
       " 23834: tensor([0.7693], grad_fn=<SumBackward1>),\n",
       " 3765: tensor([0.7693], grad_fn=<SumBackward1>),\n",
       " 6086: tensor([0.7692], grad_fn=<SumBackward1>),\n",
       " 7734: tensor([0.7692], grad_fn=<SumBackward1>),\n",
       " 4686: tensor([0.7691], grad_fn=<SumBackward1>),\n",
       " 13868: tensor([0.7691], grad_fn=<SumBackward1>),\n",
       " 17887: tensor([0.7690], grad_fn=<SumBackward1>),\n",
       " 18161: tensor([0.7690], grad_fn=<SumBackward1>),\n",
       " 4896: tensor([0.7690], grad_fn=<SumBackward1>),\n",
       " 23713: tensor([0.7690], grad_fn=<SumBackward1>),\n",
       " 1152: tensor([0.7690], grad_fn=<SumBackward1>),\n",
       " 24803: tensor([0.7689], grad_fn=<SumBackward1>),\n",
       " 12059: tensor([0.7689], grad_fn=<SumBackward1>),\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_isbn = \"0440234743\"\n",
    "img = prepare_img(query_isbn)\n",
    "query = model_vgg(img)\n",
    "res = img_sim(query, feat_map_vgg)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, user, book, df, user2idx, book2idx) -> None:\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        # make idx \n",
    "        self.user2idx = user2idx\n",
    "        self.book2idx = book2idx\n",
    "        self.n_user = len(self.user2idx)\n",
    "        self.n_item = len(self.book2idx)\n",
    "        # mapping id2idx\n",
    "        self.df['rating'] = 1 # change explicit -> implicit\n",
    "        self.df['isbn'] = self.df['isbn'].map(self.book2idx)\n",
    "        self.df['user_id'] = self.df['user_id'].map(self.user2idx)\n",
    "        self.df['neg'] = np.zeros(len(self.df), dtype=int)\n",
    "\n",
    "        self._make_Ttriples_data()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.df.user_id[index]\n",
    "        pos = self.df.isbn[index]\n",
    "        neg = self.df.neg[index]\n",
    "        return user, pos, neg\n",
    "    \n",
    "    def _neg_sampling(self, pos_list):\n",
    "        neg = np.random.randint(0,self.n_item,1)\n",
    "        while neg in pos_list:\n",
    "            neg = np.random.randint(0,self.n_item,1)\n",
    "        return neg\n",
    "\n",
    "    def _make_Ttriples_data(self):\n",
    "        for id in tqdm(range(self.n_user)):\n",
    "            pos_list = (self.df[self.df.user_id==id].isbn).tolist()\n",
    "            for i in range(len(self.df[self.df.user_id==id])):\n",
    "                idx = self.df[self.df['user_id'] == id].index[i]\n",
    "                self.df.at[idx, 'neg'] = self._neg_sampling(pos_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14348/14348 [00:34<00:00, 418.10it/s] \n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataset = BookDataset(user_data, n_book_data, n_rating_data, user2idx, book2idx)\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8,0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class VBPR(nn.Module):\n",
    "    def __init__(self, n_user, n_item, K, D, F, feature_map) -> None:\n",
    "        super().__init__()\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.K = K\n",
    "        self.D = D\n",
    "        self.F = F\n",
    "\n",
    "        self.offset = nn.Parameter(torch.zeros(1))\n",
    "        self.user_bias = nn.Embedding(self.n_user,1)\n",
    "        self.item_bias = nn.Embedding(self.n_item,1)\n",
    "        self.vis_bias = nn.Embedding(self.F,1)\n",
    "        self.user_emb = nn.Embedding(self.n_user,self.K)\n",
    "        self.item_emb = nn.Embedding(self.n_item,self.K)\n",
    "        self.img_vis_emb = nn.Embedding(self.D, self.F)\n",
    "        self.user_vis_emb = nn.Embedding(self.n_user, self.D)\n",
    "        self.feature_map = feature_map\n",
    "    \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _get_feature_map(self, itemset):\n",
    "        res = torch.tensor([])\n",
    "        for item in itemset:\n",
    "            res = torch.concat((res, self.feature_map[item.item()]), dim=0)\n",
    "        return res\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_bias.weight)\n",
    "        nn.init.xavier_uniform_(self.item_bias.weight.data)\n",
    "        nn.init.xavier_uniform_(self.vis_bias.weight.data)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight.data)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight.data)\n",
    "        nn.init.xavier_uniform_(self.img_vis_emb.weight.data)\n",
    "        nn.init.xavier_uniform_(self.user_vis_emb.weight.data)\n",
    "    \n",
    "    def cal_each(self, user, item):\n",
    "        feat_map = self._get_feature_map(item).T\n",
    "        vis_term = ((self.user_vis_emb(user))@(self.img_vis_emb.weight@(feat_map))).sum(dim=1) + (self.vis_bias.weight.T)@(feat_map)\n",
    "        mf_term = self.offset + self.user_bias(user).T + self.item_bias(item).T + (self.user_emb(user)@self.item_emb(item).T).sum(dim=1).unsqueeze(dim=0)\n",
    "        params = (self.offset, self.user_bias(user), self.item_bias(item), self.vis_bias.weight, self.user_emb(user), self.item_emb(item), self.img_vis_emb.weight, self.user_vis_emb(user))\n",
    "        return (mf_term+vis_term).squeeze(), params\n",
    "    \n",
    "    def forward(self, user, pos, neg):\n",
    "        xui, pos_params = self.cal_each(user,pos)\n",
    "        xuj, neg_params = self.cal_each(user,neg)\n",
    "        return (xui-xuj), pos_params, neg_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, reg_theta, reg_beta, reg_e) -> None:\n",
    "        super().__init__()\n",
    "        self.reg_theta = reg_theta\n",
    "        self.reg_beta = reg_beta\n",
    "        self.reg_e = reg_e\n",
    "    \n",
    "    def _cal_l2(self, *tensors):\n",
    "        total = 0\n",
    "        for tensor in tensors:\n",
    "            total += tensor.pow(2).sum()\n",
    "        return 0.5 * total\n",
    "\n",
    "    def _reg_term(self, pos_params, neg_params):\n",
    "        alpha, beta_u, beta_pos, beta_prime_pos, gamma_u, gamma_pos, e_pos, theta_u = pos_params\n",
    "        _, _, beta_neg, beta_prime_neg, _, gamma_neg, e_neg, _ = neg_params\n",
    "\n",
    "        reg_out = self.reg_theta * self._cal_l2(alpha, beta_u, beta_pos, beta_neg, theta_u, gamma_u, gamma_pos, gamma_neg)\n",
    "        reg_out += self.reg_beta * self._cal_l2(beta_prime_pos, beta_prime_neg)\n",
    "        reg_out += self.reg_e * self._cal_l2(e_pos, e_neg)\n",
    "\n",
    "        return reg_out\n",
    "\n",
    "    def forward(self, diff, pos_params, neg_params):\n",
    "        loss = -nn.functional.logsigmoid(diff).sum()\n",
    "        loss += self._reg_term(pos_params, neg_params)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def train(model, optimizer, dataloader, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for user, pos, neg in tqdm(dataloader):\n",
    "        user = user.to(device)\n",
    "        pos = pos.to(device)\n",
    "        neg = neg.to(device)\n",
    "\n",
    "        diff, pos_params, neg_params = model(user, pos, neg)\n",
    "        loss = criterion(diff, pos_params, neg_params)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "n_user = dataset.n_user\n",
    "n_item = dataset.n_item\n",
    "\n",
    "K = 20\n",
    "D = 20\n",
    "F = 4096\n",
    "F_res = 512\n",
    "\n",
    "\n",
    "reg_theta = 0.1\n",
    "reg_beta = 0.1\n",
    "reg_e = 0\n",
    "\n",
    "lr = 0.001\n",
    "epoch = 20\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "criterion = BPRLoss(reg_theta, reg_beta, reg_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = feat_map_alex\n",
    "\n",
    "vbpr_alex = VBPR(n_user, n_item, K, D, F, feat_map)\n",
    "optimizer = Adam(params = vbpr_alex.parameters(), lr=lr)\n",
    "alex_train_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    alex_train_loss.append(train(vbpr_alex, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {alex_train_loss[-1]:.10}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 109.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | LOSS : 12.06705586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 109.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1 | LOSS : 0.907961418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 121.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2 | LOSS : 0.6536929019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3 | LOSS : 0.7142501128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:20<00:00, 102.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 4 | LOSS : 0.9812125337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 112.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5 | LOSS : 0.7100947362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 108.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 6 | LOSS : 0.7686918331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 109.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7 | LOSS : 0.6620515275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:14<00:00, 137.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 | LOSS : 0.8357741724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 167.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 | LOSS : 0.7628951862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 167.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10 | LOSS : 0.6573955787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 167.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11 | LOSS : 0.6698878438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 164.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 12 | LOSS : 0.6955393603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 164.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13 | LOSS : 0.4996107364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 168.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 14 | LOSS : 0.4321633493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 167.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15 | LOSS : 0.6310107784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 168.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16 | LOSS : 0.4835853257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 169.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 17 | LOSS : 0.3101582933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 167.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18 | LOSS : 0.4584670633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:12<00:00, 169.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 19 | LOSS : 0.3013432855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "F_res = 512\n",
    "feat_map = feat_map_res\n",
    "\n",
    "vbpr_res = VBPR(n_user, n_item, K, D, F_res, feat_map)\n",
    "optimizer = Adam(params = vbpr_res.parameters(), lr=lr)\n",
    "res_train_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    res_train_loss.append(train(vbpr_res, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {res_train_loss[-1]:.10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 105.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | LOSS : 47.93991741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1 | LOSS : 12.08850028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 103.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2 | LOSS : 6.726029596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:20<00:00, 100.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3 | LOSS : 8.294232354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 105.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 4 | LOSS : 11.44785878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5 | LOSS : 7.010211182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 103.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 6 | LOSS : 11.18077581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 104.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7 | LOSS : 8.97416033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 | LOSS : 9.264488202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 | LOSS : 10.23720499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 105.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10 | LOSS : 10.7106802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 106.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11 | LOSS : 9.721966219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 105.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 12 | LOSS : 11.16755602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 107.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13 | LOSS : 8.317118321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 108.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 14 | LOSS : 8.940015897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 108.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15 | LOSS : 11.26451899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 108.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16 | LOSS : 11.18482602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:18<00:00, 108.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 17 | LOSS : 8.90851371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 107.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18 | LOSS : 7.993380213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:19<00:00, 107.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 19 | LOSS : 8.285846245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feat_map = feat_map_vgg\n",
    "\n",
    "vbpr_vgg = VBPR(n_user, n_item, K, D, F, feat_map)\n",
    "optimizer = Adam(params = vbpr_vgg.parameters(), lr=lr)\n",
    "vgg_train_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    vgg_train_loss.append(train(vbpr_vgg, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {vgg_train_loss[-1]:.10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x32fc05a80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGgCAYAAAAKKQXsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABpsUlEQVR4nO3dd3hT1R8G8Ddp0nTvRWnLpiCjQGUUqEwZIoIgIIKC4mYoQxEHyBBEnCACai34UxRQEQUFAWWXVfYqq0ALnZSmM/v+/kgbutu0GW3zfp4nT8a9ufekaZq355z7vSJBEAQQERERWYjY2g0gIiIi28LwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFsXwQURERBbF8EFEREQWxfBBREREFmVU+Hj//fchEomKXVq1amVYrlAoMHnyZHh7e8PFxQUjR45ESkqKyRtNREREdZfE2Ce0adMGu3btur8Byf1NTJ8+Hdu2bcOmTZvg7u6OKVOmYMSIETh48GCVt6/T6XDnzh24urpCJBIZ2zwiIiKyAkEQkJ2djcDAQIjFlfRtCEaYN2+eEBYWVuayzMxMQSqVCps2bTI8dvHiRQGAEBMTU+V9JCQkCAB44YUXXnjhhZc6eElISKj0u97ono8rV64gMDAQDg4OiIiIwJIlSxASEoLY2Fio1Wr079/fsG6rVq0QEhKCmJgYdOvWrcztKZVKKJVKw32h4CS7CQkJcHNzM7Z5REREZAVZWVkIDg6Gq6trpesaFT66du2KtWvXIjQ0FElJSZg/fz4iIyNx7tw5JCcnw97eHh4eHsWe4+/vj+Tk5HK3uWTJEsyfP7/U425ubgwfREREdUxVpkwYFT4GDx5suN2+fXt07doVjRo1wsaNG+Ho6Gh8CwHMmTMHM2bMMNwvTE5ERERUP9XoUFsPDw+0bNkSV69eRUBAAFQqFTIzM4utk5KSgoCAgHK3IZPJDL0c7O0gIiKq/2oUPnJycnDt2jU0aNAA4eHhkEql2L17t2F5XFwcbt26hYiIiBo3lIiIiOoHo4ZdZs2ahaFDh6JRo0a4c+cO5s2bBzs7O4wdOxbu7u6YNGkSZsyYAS8vL7i5uWHq1KmIiIgod7IpERFRRQRBgEajgVartXZTCIBUKoWdnV2Nt2NU+EhMTMTYsWNx9+5d+Pr6omfPnjh8+DB8fX0BAJ999hnEYjFGjhwJpVKJgQMH4quvvqpxI4mIyPaoVCokJSUhLy/P2k2hAiKRCEFBQXBxcanZdoTCY1triaysLLi7u0Mul3P+BxGRjdLpdLhy5Qrs7Ozg6+sLe3t7Fp60MkEQkJaWhry8PLRo0aJUD4gx399G1/kgIiIyN5VKBZ1Oh+DgYDg5OVm7OVTA19cXN27cgFqtrtHwC08sR0REtValZbrJokzV+8R3lYiIiCyK4YOIiIgsiuGDiIjIQvbs2QORSFSqIKetYfggIiIysZiYGNjZ2WHIkCHWbkqVTJw4EcOHD7fY/mwmfKTkpuCz2M/waeyn1m4KERHVc1FRUZg6dSr27duHO3fuWLs5tY7NhI88TR6+O/cdfon7xdpNISIiIwmCgDyVxioXY8th5eTkYMOGDXjllVcwZMgQrF27tsL1Dxw4gMjISDg6OiI4OBjTpk1Dbm4uAOD777+Hi4sLrly5Ylj/1VdfRatWrQzF1xo3bozFixfjueeeg6urK0JCQvD1118X20dCQgJGjx4NDw8PeHl5YdiwYbhx4wYA4P3338e6deuwZcsWiEQiiEQi7Nmzx6jXbCybqfPh4+gDAMhWZ0OhUcBB4mDlFhERUVXlq7V4YO4Oq+z7woKBcLKv+tflxo0b0apVK4SGhmL8+PF4/fXXMWfOnDIPU7127RoGDRqERYsW4bvvvkNaWhqmTJmCKVOmIDo6Gs888wy2bt2KcePG4dChQ9ixYwe+/fZbxMTEFKt/8sknn2DhwoV4++238csvv+CVV15Br169EBoaCrVajYEDByIiIgL79++HRCLBokWLMGjQIJw5cwazZs3CxYsXkZWVhejoaACAl5dXzX9wFbCZng8XqQtkdjIAwF3FXSu3hoiI6quoqCiMHz8eADBo0CDI5XLs3bu3zHWXLFmCcePG4fXXX0eLFi3QvXt3LF++HN9//z0UCgUAYM2aNUhKSsK0adMwadIkvP/++wgPDy+2nUceeQSvvvoqmjdvjtmzZ8PHxwf//fcfAGDDhg3Q6XT49ttv0a5dO7Ru3RrR0dG4desW9uzZAxcXFzg6OkImkyEgIAABAQGwt7c340/Ihno+RCIRfBx9cDvnNtLz09HQpaG1m0RERFXkKLXDhQUDrbbvqoqLi8PRo0exefNmAIBEIsGYMWMQFRWF3r17l1r/9OnTOHPmDH788UfDY4IgQKfTIT4+Hq1bt4anpyeioqIwcOBAdO/eHW+99Vap7bRv395wWyQSISAgAKmpqYZ9XL16Fa6ursWeo1AocO3atSq/NlOymfABAN6O3obwQUREdYdIJDJq6MNaoqKioNFoEBgYaHhMEATIZDJ8+eWXpdbPycnBSy+9hGnTppVaFhISYri9b98+2NnZISkpCbm5uaWChFQqLXZfJBJBp9MZ9hEeHl4s4BQqPDGspdX+d9KEfBz08z7u5nPYhYiITEuj0eD777/HJ598ggEDBhRbNnz4cPz0009o1apVscc7deqECxcuoHnz5uVu99ChQ1i6dCn+/PNPzJ49G1OmTMG6deuq3K5OnTphw4YN8PPzK/eEb/b29tBqtVXeZk3ZzJwP4P6kU/Z8EBGRqW3duhX37t3DpEmT0LZt22KXkSNHIioqqtRzZs+ejUOHDmHKlCk4deoUrly5gi1btmDKlCkAgOzsbDz99NOYNm0aBg8ejB9//BEbNmzAL79U/cjNcePGwcfHB8OGDcP+/fsRHx+PPXv2YNq0aUhMTASgP2LmzJkziIuLQ3p6OtRqtWl+KOWwyfCRlp9m5ZYQEVF9ExUVhf79+8Pd3b3UspEjR+L48eM4c+ZMscfbt2+PvXv34vLly4iMjETHjh0xd+5cw7DNa6+9BmdnZyxevBgA0K5dOyxevBgvvfQSbt++XaV2OTk5Yd++fQgJCcGIESPQunVrTJo0CQqFwtAT8sILLyA0NBQPPvggfH19cfDgwZr8KColEow9gNnMsrKy4O7uDrlcXm73UHVtjNuIhYcXondwb6zou8Kk2yYiItNRKBSIj49HkyZN4ODA0gi1RUXvizHf3zbZ88E5H0RERNZjk+GDcz6IiIisx2bDRy0bbSIiIrIZNhU+vB29AQBqnRpZqiwrt4aIiMg22VT4kNnJ4GqvL8zCeR9ERETWYVPhA+C8DyIiImtj+CAiIiKLsr3w4cDwQUREZE02Fz4KJ52mKxg+iIiIrMHmwgcLjREREVmXzYYPDrsQEZE5TJw4ESKRCCKRCFKpFE2aNMGbb74JhUJh7aYZNG7cGJ9//rnV9i+x2p6thOGDiIjMbdCgQYiOjoZarUZsbCwmTJgAkUiEpUuXWrtptQJ7PoiIqPYTBECVa51LNSpiy2QyBAQEIDg4GMOHD0f//v2xc+dOAIBOp8OSJUvQpEkTODo6IiwsDL/88ovhuffu3cO4cePg6+sLR0dHtGjRAtHR0QCAGzduQCQS4bfffkOfPn3g5OSEsLAwxMTEFNv/gQMHEBkZCUdHRwQHB2PatGnIzc0FAPTu3Rs3b97E9OnTDT00lmZzPR+FE07vKe5Bo9NAIra5HwERUd2jzgMWB1pn32/fAeydq/30c+fO4dChQ2jUqBEAYMmSJfjhhx+wevVqtGjRAvv27cP48ePh6+uLXr164b333sOFCxfw999/w8fHB1evXkV+fn6xbb7zzjv4+OOP0aJFC7zzzjsYO3Ysrl69ColEgmvXrmHQoEFYtGgRvvvuO6SlpWHKlCmYMmUKoqOj8dtvvyEsLAwvvvgiXnjhhRr9aKrL5r55PWWeEIvE0Ak63FPcg6+Tr7WbRERE9czWrVvh4uICjUYDpVIJsViML7/8EkqlEosXL8auXbsQEREBAGjatCkOHDiANWvWoFevXrh16xY6duyIBx98EIB+fkZJs2bNwpAhQwAA8+fPR5s2bXD16lW0atUKS5Yswbhx4/D6668DAFq0aIHly5ejV69eWLVqFby8vGBnZwdXV1cEBARY5OdRks2FDzuxHbwcvJCen470/HSGDyKiukDqpO+BsNa+jdSnTx+sWrUKubm5+OyzzyCRSDBy5EicP38eeXl5ePjhh4utr1Kp0LFjRwDAK6+8gpEjR+LEiRMYMGAAhg8fju7duxdbv3379obbDRo0AACkpqaiVatWOH36NM6cOYMff/zRsI4gCNDpdIiPj0fr1q2Nfj2mZnPhA9DP+ygMH0REVAeIRDUa+rA0Z2dnNG/eHADw3XffISwsDFFRUWjbti0AYNu2bWjYsGGx58hkMgDA4MGDcfPmTfz111/YuXMn+vXrh8mTJ+Pjjz82rCuVSg23C+ds6HQ6AEBOTg5eeuklTJs2rVS7QkJCTPgqq88mw4eh0BjDBxERmZlYLMbbb7+NGTNm4PLly5DJZLh16xZ69epV7nN8fX0xYcIETJgwAZGRkXjjjTeKhY+KdOrUCRcuXDCEn7LY29tDq9Ua/VpMxeaOdgHul1i/q2ChMSIiMr9Ro0bBzs4Oa9aswaxZszB9+nSsW7cO165dw4kTJ7BixQqsW7cOADB37lxs2bIFV69exfnz57F161ajhkpmz56NQ4cOYcqUKTh16hSuXLmCLVu2YMqUKYZ1GjdujH379uH27dtIT7f8P+I22fPBw22JiMiSJBIJpkyZgo8++gjx8fHw9fXFkiVLcP36dXh4eKBTp054++23Aeh7JebMmYMbN27A0dERkZGR+Pnnn6u8r/bt22Pv3r145513EBkZCUEQ0KxZM4wZM8awzoIFC/DSSy+hWbNmUCqVEKpxOHFNiARL77ESWVlZcHd3h1wuh5ubm1n28cOFH7D02FIMbDwQH/eqWjcWERFZjkKhQHx8PJo0aQIHBwdrN4cKVPS+GPP9bZvDLuz5ICIishqbDB+FE055cjkiIiLLs8nwwZ4PIiIi67Hp8JGjzkG+Jr+StYmIiMiUbDJ8uEhdILPTF3Ph0AsREZFl2WT4EIlEHHohIiKyEpsMHwAnnRIREVmLzYYPX0f9CeXY80FERGRZNhs+DMMuCoYPIiIiS7LZ8MGTyxEREVmHzYYPTjglIiJTGjp0KAYNGlTmsv3790MkEuHMmTMAgF9//RV9+/aFp6cnHB0dERoaiueeew4nT54s9jyVSoVly5ahU6dOcHZ2hru7O8LCwvDuu+/izp07Zn9N5mK74aPwzLaccEpERCYwadIk7Ny5E4mJiaWWRUdH48EHH0T79u0xe/ZsjBkzBh06dMAff/yBuLg4rF+/Hk2bNsWcOXMMz1EqlXj44YexePFiTJw4Efv27cPZs2exfPlypKenY8WKFZZ8eSZlk2e1Be73fKTlp1m5JUREVBlBEKxWFNJR4giRSFTpeo8++ih8fX2xdu1avPvuu4bHc3JysGnTJixbtgyHDx/GRx99hC+++ALTpk0zrBMSEoLw8PBiZ5f97LPPcODAARw/fhwdO3Ystm6vXr0sfiZaU7L58JGenw5BEKr0i0VERNaRr8lH1/VdrbLvI08dgZPUqdL1JBIJnnnmGaxduxbvvPOO4Xtl06ZN0Gq1GDt2LObOnQsXFxe8+uqrZW6j6HfRTz/9hIcffrhY8Chv3brGZoddCiecanQaZKmyrNwaIiKqD5577jlcu3YNe/fuNTwWHR2NkSNHwt3dHZcvX0bTpk0hkdz/3//TTz+Fi4uL4SKXywEAly9fRmhoaLHtP/7444b1unfvbpkXZQY22/Nhb2cPN3s3ZKmykJ6fDneZu7WbRERE5XCUOOLIU0estu+qatWqFbp3747vvvsOvXv3xtWrV7F//34sWLCg3Oc899xzeOyxx3DkyBGMHz++wuGUr776Crm5uVi+fDn27dtn1OuoTWw2fAD6oZfC8NHMo5m1m0NEROUQiURVGvqoDSZNmoSpU6di5cqViI6ORrNmzdCrVy8AQIsWLXDgwAGo1WpIpVIAgIeHBzw8PEpNVG3RogXi4uKKPdagQQMAgJeXlwVeifnY7LALwMNtiYjI9EaPHg2xWIz169fj+++/x3PPPWeYnzF27Fjk5OTgq6++qnQ7Y8eOxc6dO0sdflsf2HTPBwuNERGRqbm4uGDMmDGYM2cOsrKyMHHiRMOyiIgIzJw5EzNnzsTNmzcxYsQIBAcHIykpCVFRURCJRBCL9f0C06dPx7Zt29CvXz/MmzcPkZGR8PT0xOXLl/H333/Dzs7OSq+w5tjzAdb6ICIi05o0aRLu3buHgQMHIjAwsNiyjz/+GOvXr8fJkyfx6KOPokWLFhg1ahR0Oh1iYmLg5uYGAHBwcMDu3bsxe/ZsREdHo2fPnmjdujVef/119OjRA7///rsVXplp2HTPB4ddiIjIHCIiIiqcODp69GiMHj260u3IZDLMnj0bs2fPNmXzrI49H2D4ICIisiTbDh8OPLMtERGRpdUofHz44YcQiUR4/fXXDY8pFApMnjwZ3t7ecHFxwciRI5GSklLTdppF4YRTzvkgIiKynGqHj2PHjmHNmjVo3759scenT5+OP//8E5s2bcLevXtx584djBgxosYNNYfCYZd7intQ69RWbg0REZFtqFb4yMnJwbhx4/DNN9/A09PT8LhcLkdUVBQ+/fRT9O3bF+Hh4YiOjsahQ4dw+PDhMrelVCqRlZVV7GIpHjIP2InsIEDAPcU9i+2XiIiqpi6fPK0+MtX7Ua3wMXnyZAwZMgT9+/cv9nhsbCzUanWxx1u1aoWQkBDExMSUua0lS5bA3d3dcAkODq5Ok6rFTmwHLwd9lThOOiUiqj0Kq3/m5eVZuSVUlEqlAoAa1xgx+lDbn3/+GSdOnMCxY8dKLUtOToa9vT08PDyKPe7v74/k5OQytzdnzhzMmDHDcD8rK8uiAcTH0Qdp+WkMH0REtYidnR08PDyQmpoKAHBycqrTZ3GtD3Q6HdLS0uDk5FTsxHjVYdSzExIS8Nprr2Hnzp1wcHCo0Y4LyWQyyGQyk2yrOjjplIiodgoICAAAQwAh6xOLxQgJCalxEDQqfMTGxiI1NRWdOnUyPKbVarFv3z58+eWX2LFjB1QqFTIzM4v1fqSkpBh+iWob1vogIqqdRCIRGjRoAD8/P6jVPCigNrC3tzeUf68Jo8JHv379cPbs2WKPPfvss2jVqhVmz56N4OBgSKVS7N69GyNHjgQAxMXF4datW4iIiKhxY82B4YOIqHazs7Or0+cxodKMCh+urq5o27ZtscecnZ3h7e1teHzSpEmYMWMGvLy84ObmhqlTpyIiIgLdunUzXatNiOGDiIjIskx+bpfPPvsMYrEYI0eOhFKpxMCBA6t06mBr4ZltiYiILKvG4WPPnj3F7js4OGDlypVYuXJlTTdtEYUl1u8qOOGUiIjIEmz63C4Ah12IiIgsjeGjIHzkqnORp2YxGyIiInOz+fDhLHWGg52+ZgmHXoiIiMzP5sOHSCRioTEiIiILsvnwAXDeBxERkSUxfIDhg4iIyJIYPsDwQUREZEkMH2ChMSIiIkti+MD9ng9OOCUiIjI/hg/cr3LKng8iIiLzY/hAkTkfCoYPIiIic2P4QPEJp4IgWLk1RERE9RvDB+5PONXoNMhSZVm5NURERPUbwwcAezt7uMvcAQBpeWlWbg0REVH9xvBRwDDplPM+iIiIzIrhowALjREREVkGw0cBnlyOiIjIMhg+CrDng4iIyDIYPgowfBAREVkGw0cBhg8iIiLLYPgowJPLERERWQbDRwGeXI6IiMgyGD4KFIaPe8p7UOvUVm4NERFR/cXwUcBD5gE7kR0AICM/w8qtISIiqr9sJnyoNDpcSclG7M2yg4VYJIa3Q8G8D1Y5JSIiMhubCR9xydl4+LN9eOWHE+Wuw0JjRERE5mcz4SPI0xEAkJqthEKtLXMdHm5LRERkfjYTPjycpHC218/puJOZX+Y6DB9ERETmZzPhQyQSIcjTCQCQeI/hg4iIyFpsJnwA94deygsfLDRGRERkfjYaPvLKXM5CY0REROZnY+GDwy5ERETWZmPho2o9HwwfRERE5mNj4aNqPR95mjzkqcsOKERERFQzNhY+Kq714SRxgqNEvw7nfRAREZmHTYWPymp9iEQillgnIiIyM5sKH6z1QUREZH02FT6Aymt9MHwQERGZlw2Hj7InlLLQGBERkXnZYPio2rALJ5wSERGZhw2GD9b6ICIisiYbDB+ccEpERGRNNhg+Kq71wfBBRERkXjYXPiqr9WGY86G4C52gs2jbiIiIbIHNhY/Kan14OXgBADQ6DbKUWRZtGxERkS2wufABVFzrw97OHu4ydwAceiEiIjIHGw8f5Rzx4lAw74Ml1omIiEzORsNH1Y54SctLs1ibiIiIbIWNho+qVTlloTEiIiLTs9HwwVofRERE1mKj4aOKtT4454OIiMjkbDJ8VLXWB3s+iIiITM8mw0dltT54cjkiIiLzscnwAVRc64M9H0RERObD8FHGES+F4SNTmQm1Vm3RdhEREdV3Nhw+yh92cZe5QyKSANCf44WIiIhMx4bDR/k9H2KRGF6O+nO8cN4HERGRadlw+GCtDyIiImuw4fBRxVofDB9EREQmZVT4WLVqFdq3bw83Nze4ubkhIiICf//9t2G5QqHA5MmT4e3tDRcXF4wcORIpKSkmb7QpsNYHERGRdRgVPoKCgvDhhx8iNjYWx48fR9++fTFs2DCcP38eADB9+nT8+eef2LRpE/bu3Ys7d+5gxIgRZml4TVVW68PbQX9+F4YPIiIi05IYs/LQoUOL3f/ggw+watUqHD58GEFBQYiKisL69evRt29fAEB0dDRat26Nw4cPo1u3bqZrtYkEeToiLiW74kJjPNqFiIjIpKo950Or1eLnn39Gbm4uIiIiEBsbC7Vajf79+xvWadWqFUJCQhATE1PudpRKJbKysopdLKUqtT7Y80FERGRaRoePs2fPwsXFBTKZDC+//DI2b96MBx54AMnJybC3t4eHh0ex9f39/ZGcnFzu9pYsWQJ3d3fDJTg42OgXUV1VKbHO8EFERGRaRoeP0NBQnDp1CkeOHMErr7yCCRMm4MKFC9VuwJw5cyCXyw2XhISEam/LWOz5ICIisjyj5nwAgL29PZo3bw4ACA8Px7Fjx/DFF19gzJgxUKlUyMzMLNb7kZKSgoCAgHK3J5PJIJPJjG+5CVSl5yNfk488dR6cpE4WbRsREVF9VeM6HzqdDkqlEuHh4ZBKpdi9e7dhWVxcHG7duoWIiIia7sYsKqr14SR1gqNEv5y9H0RERKZjVM/HnDlzMHjwYISEhCA7Oxvr16/Hnj17sGPHDri7u2PSpEmYMWMGvLy84ObmhqlTpyIiIqJWHukC3K/1kavS4k5mPpr6uhRb7uPog4TsBKTnpyPELcRKrSQiIqpfjAofqampeOaZZ5CUlAR3d3e0b98eO3bswMMPPwwA+OyzzyAWizFy5EgolUoMHDgQX331lVkabgqFtT4KD7etKHwQERGRaRgVPqKioipc7uDggJUrV2LlypU1apQlVaXWB8MHERGR6djsuV0KVXTEC6ucEhERmR7DRxWOeGGVUyIiItNh+GCtDyIiIoti+GCVUyIiIoti+Kig1gfDBxERkenZfPgorPUBAHcyi/d+eDvqJ5xm5GdAJ+gs3jYiIqL6yObDR2GtD6D00Evh0S4aQQO5Um7xthEREdVHNh8+gKKTTouHD6mdFB4yDwAceiEiIjIVhg/wiBciIiJLYvhAxUe8FM77YPggIiIyDYYPVK3n424+C40RERGZAsMHKqn14cBhFyIiIlNi+EDVan2k5adZvF1ERET1EcMHqlbrg8MuREREpsHwgYprffBoFyIiItNi+ChQXq0PQ/hQMHwQERGZAsNHgfKOeCkMH3KlHCqtyuLtIiIiqm8YPgqUN+ziLnOHRCQBAGQoMizeLiIiovqG4aNAeT0fYpEYXo5eADjvg4iIyBQYPgpUWOuDk06JiIhMhuGjQFVqfTB8EBER1RzDR4GKan34OvoCYPggIiIyBYaPAhXV+uDJ5YiIiEyH4aOIymp9sMopERFRzTF8FFFZrQ/2fBAREdUcw0cRLLFORERkfgwfRZTb8+FQMOyiuAtBECzeLiIiovqE4aOIyiac5mvykafJK/U8IiIiqjqGjyLKq/XhJHWCk0QfTDj0QkREVDMMH0VUVOuD8z6IiIhMg+GjiIpqfTB8EBERmQbDRwnl1fpgoTEiIiLTYPgoobJaHyw0RkREVDMMHyVw2IWIiMi8GD5KYJVTIiIi82L4KIE9H0RERObF8FFCebU+Cieccs4HERFRzTB8lFBerY+iJdZ1gs4qbSMiIqoPGD5KKK/Wh5ejFwBAK2iRqcy0RtOIiIjqBYaPMpRV60MqlsJT5gmA8z6IiIhqguGjDOUd8cJCY0RERDXH8FGGwmGXhHKOeOGkUyIioupj+CgDa30QERGZD8NHGVjrg4iIyHwYPspQ2PORVqLWB8MHERFRzTF8lKForY/bRWp9sNAYERFRzTF8lKG8Wh+FPR9p+WlWaRcREVF9wPBRjrImnRZWOeWwCxERUfUxfJSjrEJjhT0fWaosqLQqq7SLiIiormP4KEdZwy5uMjdIxBIAnPdBRERUXQwf5Shr2EUsEsPbgVVOiYiIaoLhoxys9UFERGQeDB/lqLTWh4Lhg4iIqDoYPspRXq0P9nwQERHVDMNHOcqr9cFCY0RERDXD8FGBMmt9sOeDiIioRhg+KlBRrQ+GDyIiouph+KhARSXWGT6IiIiqh+GjAhWVWL+bfxeCIFilXURERHUZw0cFKppwqtAqkKvOtUq7iIiI6jKjwseSJUvQuXNnuLq6ws/PD8OHD0dcXFyxdRQKBSZPngxvb2+4uLhg5MiRSElJMWmjLaWsWh9OUic4SfShhEMvRERExjMqfOzduxeTJ0/G4cOHsXPnTqjVagwYMAC5ufd7AKZPn44///wTmzZtwt69e3Hnzh2MGDHC5A23hPJqffg6+QJg+CAiIqoOiTErb9++vdj9tWvXws/PD7GxsXjooYcgl8sRFRWF9evXo2/fvgCA6OhotG7dGocPH0a3bt1M13ILKKz1EZeSjcR7+Wjm6wIA8Hbwxs2sm6xySkREVA01mvMhl8sBAF5eXgCA2NhYqNVq9O/f37BOq1atEBISgpiYmDK3oVQqkZWVVexSm1RU64OFxoiIiIxX7fCh0+nw+uuvo0ePHmjbti0AIDk5Gfb29vDw8Ci2rr+/P5KTk8vczpIlS+Du7m64BAcHV7dJZsFaH0RERKZV7fAxefJknDt3Dj///HONGjBnzhzI5XLDJSEhoUbbMzXW+iAiIjIto+Z8FJoyZQq2bt2Kffv2ISgoyPB4QEAAVCoVMjMzi/V+pKSkICAgoMxtyWQyyGSy6jTDIlhinYiIyLSM6vkQBAFTpkzB5s2b8e+//6JJkybFloeHh0MqlWL37t2Gx+Li4nDr1i1ERESYpsUWxpPLERERmZZRPR+TJ0/G+vXrsWXLFri6uhrmcbi7u8PR0RHu7u6YNGkSZsyYAS8vL7i5uWHq1KmIiIioc0e6FCpZ68NBaseeDyIiohowKnysWrUKANC7d+9ij0dHR2PixIkAgM8++wxisRgjR46EUqnEwIED8dVXX5mksdZQWOsjV6XF7Uz94baF4SNDkQGtTgs7sZ2VW0lERFR3GBU+qnIuEwcHB6xcuRIrV66sdqNqk7JqfXg6eEIEEbSCFpnKTMMwDBEREVWO53apgpKTTqViKTwdPAFw6IWIiMhYDB9VUFatD046JSIiqh6Gjyoos9aHQ8GkU5ZYJyIiMgrDRxWw1gcREZHpMHxUAaucEhERmQ7DRxWUrPUB3J/zwfBBRERkHIaPKiis9QEAtzP1vR88sy0REVH1MHxUQWGtD+D+0AuHXYiIiKqH4aOKSk46ZfggIiKqHoaPKipZ66MwfGSpsqDSqqzWLiIiorqG4aOKSg67uNm7QSLWV6dn7wcREVHVMXxUUclhF5FIxKEXIiKiamD4qKIKq5wyfBAREVUZw0cVlVXrgz0fRERExmP4qKKyan3w5HJERETGY/ioItb6ICIiMg2GDyOw1gcREVHNMXwYobxaH+kKhg8iIqKqYvgwQnnDLpzzQUREVHUMH0YoOexS9My2giBYrV1ERER1CcOHEUr2fHg76MOHUqtEjjrHau0iIiKqSxg+jFCy1oeT1AnOUmcAnHRKRERUVQwfRiir1gePeCEiIjIOw4cRyqr1UTj0wkmnREREVcPwYSTW+iAiIqoZhg8jlVvrg+GDiIioShg+jMQS60RERDXD8GGkcoddWOWUiIioShg+jFRqwinPbEtERGQUhg8jlaz14evoC4DDLkRERFXF8GGkkrU+CoddMhQZ0Oq01mwaERFRncDwYaSStT48HTwhggg6QYd7yntWbh0REVHtx/BRDUUnnUrEEng6eALgvA8iIqKqYPioBtb6ICIiqj6Gj2pgrQ8iIqLqY/ioBpZYJyIiqj6Gj2oor9YHwwcREVHlGD6qoWStDx8Hfc8HJ5wSERFVjuGjGsqr9cES60RERJVj+KiGkrU+OOeDiIio6hg+qqnopFOGDyIioqpj+KimorU+CiecZquyodQqrdksIiKiWo/ho5qKDru42btBKpYC4KRTIiKiyjB8VFPRYReRSMShFyIioipi+Kim8qqcpuWnWa1NREREdQHDRzWVrPVROO+Dwy5EREQVY/iopnJrfXDYhYiIqEK2Ez6y7gD7lgG75ptkc+XV+uCwCxERUcVsJ3zkpAD/LgKOrAbUCpNssuik0yCXIADA3oS9yFZlm2T7RERE9ZHthI8GHQDXBoA6D7ix3ySbLFrrY1CTQWjk1ghp+Wn44sQXJtk+ERFRfWQ74UMkAloO0t+O+9skmyw67CKzk+G9bu8BADbGbcSp1FMm2QcREVF9YzvhAwBCB+uvL+8ABKHGmwv2uj/sAgBdG3TFY80egwAB82PmQ61T13gf9UWWKgsancbazSAiolrAtsJHk4cAiSOQlQgkn63x5krW+gCAWQ/OgofMA1czr+L789/XeB/1wfb47eizoQ/G/zUe+Zr8yp9ARET1msTaDbAoqSPQrA8Q95d+6KVB+xptrmStDwepHTwdPDHrwVl49+C7WH16NQY0HoBg12BTtL5O2nR5ExbGLIQAAefvnseSI0uwoMcCazfLKHnqPNzIuoHWXq0hEoms3RyqIwRBQGJOIho4N4BEbFt/aitz8e5FLD22FEk5SZDaSSEV379IxBLY29nff6zE8vLuS8QSSMVSw3MdJY7o2qArnKXO1n65VAbb+0SEDtaHj8t/A71n12hT7o5SuMgkyFFqcDszH818XQAAjzV7DH9c+wNHk4/ig8MfYFX/VTb5pRV9Lhqfxn4KAOgd1Bv7bu/D5qub0cm/E4Y3H27dxlVRnjoPT//9NC7fu4zIhpGYGzEXAc4B1m4W1WIqrQrbb2zHjxd/xIW7F9DGuw2W910OPyc/azfN6jQ6DaLPReOr019ZZBg2wDkAC7ovQERghNn3RcYRCYIJJj+YUFZWFtzd3SGXy+Hm5mb6HWSnAJ+01N+ecQlwa1CjzQ36fB8uJWdj3XNd0Kulr+HxG/IbGPnHSKh0KiyNXIpHmj5So/3UJYIgYMXJFfjm7DcAgOfbPY9pHafh6zNf48tTX8LBzgHrh6xHC88WVm5pxQRBwKy9s/DPzX8Mj7lIXTDzwZkY2WKkTQZKKl9aXho2Xt6IjXEbkaHIKLbM38kfX/b7Eq28WlmpddZ3K+sW3j7wNk6nnQYA9Avph4ltJkKAAJVWBbVODbVWrb8uein5mFYNjU5juG94bol14+XxSMlLAQCMCR2DGeEz4CR1suaPoN4z5vvb9sIHAHzTF7gdCwz9AgifWKNNPb/uGHZdTMUHj7fFuK6Nii1bfXo1Vp5aCS8HL/wx/A+4y9xrtK+6QCfosPjIYmyI2wAAeL3T65jUbpJh2au7XsXBOwfR2K0xNjy6oVb/MfjmzDdYfnI5JGIJ3o94Hxsvb8SZtDMA9JOL3494H0GuQVZuJVnbmbQz+PHij/jnxj/QCPr/5v2c/DC21Vh0a9ANbx94G/HyeDhKHPHRQx+hd3Bv6zbYwgRBwKbLm/Dx8Y+Rr8mHi9QFc7rOwdCmQ80a4PPUefg09lPD36IglyAs7LEQDwY8aLZ92jqGj8rsXQb8twhoORh46ucaber9P85j7aEbeKV3M8weVPy/GpVWhSf+fALx8niMbDES73d/v0b7qu3UOjXeO/getl3fBhFEeLfbuxgdOrrYOhmKDIz6cxRS81LxSJNH8GHkh7WyB2Ff4j5M2T0FAgTMjZiLUS1HQavT4seLP2LFyRVQaBVwlDjitU6vYWyrsRCLbGvutqnlqHKQkJ2AW9m39NdZt/S3sxKg1qnRrUE3RAZFomfDnvB08LR2c6HWqrHj5g6sv7geZ9PvT17v5NcJT7V+Cn1D+kIqlgLQH+k1c89MHE46DBFEmPngTDzzwDO18vfe1NLy0jD30FwcuH0AANAloAsW9liIQJdAi7XhcNJhzD04F0m5SRBBhPEPjMe0jtPgIHGwWBtsBcNHZZLPAqt76o98efM6YF/9/76/3X8di7ZdxNCwQKwY27HU8tiUWEzcPhEAsHbQWoT7h1d7X7WZUqvErL2zsCdhDyQiCT7o+UG5Q00nU0/i2e3PQito8V6390oFFGuLl8fjqW1PIUedg1EtR2FuxNxiy29l3cK8Q/NwPOU4AKCjX0cs6L4Ajd0bW6G1dYdcKS8eLIrcLjlMUR6xSIz2Pu3xUNBDeCjoIbT0bGnRL/H0/HRsituEjZc3Gs7jJBVL8UiTR/BU66fwgPcDZT5PrVNjyZEl2HR5EwDgiZZP4O2ubxsCSn2048YOLDy8EHKlHPZie7zW6TWMf2C8VYJ6jioHy44vw29XfgMANHZrjA96foD2vjU76ICKM2v42LdvH5YtW4bY2FgkJSVh8+bNGD58uGG5IAiYN28evvnmG2RmZqJHjx5YtWoVWrSo2vi+RcKHIACftwPkCcDYn+/X/6iG7eeS8PIPJ9AxxAObX+1R5jrvH3ofv175FU3dm+KXob9Aale//uDkqnMx7d9pOJp8FDI7GT7p9Ql6Bfeq8Dlrz63FJ7GfQCqW4odHfij3j7alZauy8dS2p3Aj6wY6+nVE1ICoMt8vnaDDprhN+DT2U+Rp8mAvtsfkjpPxzAPP2OyRDYIg4J7yHm5l3TL0YhS9LVfKK3y+l4MXgl2DEeIagmA3/XUjt0ZQaVXYf3s/9iXuw+V7l4s9x9/J3xBEujboCkeJo1le27n0c/jx4o/YfmO7YaKkn6MfxrQag5EtRhrOal0RQRDwvwv/w8fHP4YAAd0adMMnvT+Bm72Z/s5ZSZYqC4uPLMa269sAAK29WmNxz8Vo7tncyi3T92i+f+h9pOWnQSwS49k2z+LVDq/C3s7e2k2rF8waPv7++28cPHgQ4eHhGDFiRKnwsXTpUixZsgTr1q1DkyZN8N577+Hs2bO4cOECHBwq7+aySPgAgG2zgGPfAJ0mAI8tr/Zmzt2W49EVB+DrKsOxd/qXuY5cKcdjvz+GDEUGpnSYgpfCXqr2/mobuVKOV3a9grPpZ+EsdcaKvivQOaBzpc8TBAHT/p2GPYl7EOQShA1DN1j9j7BO0OG1f1/DnsQ98HPyw4ZHNxhOGFieOzl3MD9mPg7dOQQAaOPdBgt6LEBLz5aWaLJVJeUkYf/t/TiefBw3sm4gITsBOeqcCp/j6+irDxhuIcVCRrBrMFztXSvdZ3JuMvYl7sO+xH04knQECu398zTZi+3RpUEXQxhp6NKwRq9PrVVj582d+PHSj4a5PgDQwbcDxrUeh36N+lWr52JPwh68ue9N5Gvy0cS9CVb2XYlgt/pxOH7MnRi8d/A9pOSlQCwS4/l2z+Pl9i/Xqn+45Eo5lhxdYghHzT2a44OeH9Saf4DqMosNu4hEomLhQxAEBAYGYubMmZg1axYAQC6Xw9/fH2vXrsWTTz5p0sbXyNVdwA8jAZcAYMZFQFy9rsDMPBU6LNgJALi0cBAcpHZlrrft+ja8tf8t2Ivt8etjv9aLLvq0vDS8uPNFXM28Cg+ZB1b3X402Pm2q/Hy5Uo4xW8fgds5t9Avph896f2bVcfAvT36JNWfWwF5sj3WD16GtT9sqPU8QBPx+9XcsO74M2apsSMQSvNj+RTzf9vla9Ue3ptQ6NU6lnsL+2/uxP3E/rmZeLXO9AOcAQ6AwhAzXYAS7Bpt0grFCo8Cx5GPYl7gP+2/vx+2c28WWN/dojsigSDzU8CF08OtQ5R6p9Px0/HL5F2yM22g4S7VULMXgJoPxVKunjPodL8+ljEuYsnsKUvJS4CHzwOd9Pq/TQ7L5mnx8Hvs51l9aDwAIcQ3B4sjFCPMNs3LLyrf75m4sOLwAGYoMSEQFn9n2z9froTBzs1r4uH79Opo1a4aTJ0+iQ4cOhvV69eqFDh064IsvSp9wTalUQqlUFmt8cHCw+cOHRgl81BRQ5QAv/Ac07FStzQiCgHbv/4McpQa7Z/Yy1Pooa72Xd72MQ3cOoWtAV3wz4Js6PeEsMTsRL/zzAhJzEuHn6IevB3yNZh7NjN7O+fTzePrvp6HWqfFm5zfx9ANPm6G1ldt1cxem75kOAPig5wd4rNljRm8jNS8VCw8vxJ6EPQCAlp4tsaDHArTxrvmXlbWk5aXhwO0D2H97P2LuxBTr2RCLxAjzDUP3wO5o6dkSIa4hCHINsspEPkEQcF1+HXsT92Jf4j6cSj0FraA1LHe1d0WPwB54KOihcietnr97Husvrsff8X8bTo3g6+iL0aGj8UTLJyrtBTNWWl4apv47FefvnodULMX87vMxtNlQk+7DEs6lnzMc0QPUrcNaMxQZWHR4EXbe1P8D2dqrNT7o+UGtLwNQW1ktfBw6dAg9evTAnTt30KDB/foZo0ePhkgkwoYNG0pt4/3338f8+fNLPW728AEAG8YDF/8Ees0G+rxd7c2UV+ujpISsBDz+x+NQapXV/oKrDa5lXsOL/7yI1PxUBLkE4ZsB39TokNOfLv2ExUcWQyKSYO3gtRb/b+nKvSsY99c45GvyMb71eMzuUv3ic4IgYPuN7Vh8ZDEylZmwE9nh2bbP4uWwlyGzk5mw1eah1WlxNv2soXfjYsbFYss9ZZ7o2bAnIoMi0T2we609fFyulCPmTgz2Ju7FgdsHkKnMNCwTQYT2vvpJq5ENI3Ez6yZ+vPgjTqWdMqwT5huGca3HoX9If7P2XuVr8vH2/rex69YuAMAL7V7AlI5T6sTRU2qdGt+e+RZrzqyBVtDC19EXC3osQM+GPa3dNKMUfmY/OPIB5Eo5pGIpJneYjIltJsJOXHZPNpWtToUPq/V8AMCp9cDvrwAB7YCXD1R7MxXV+ijp27Pf4osTX8BD5oE/hv9RKw4bNMb59PN4edfLyFRmorlHc3z98NfwdSo/cFWFIAh4Y98b2HFjBwKcA7Dp0U3wcPAwTYMrIVfK8eTWJ5GYk4iuAV2x+uHVJpkwejf/Lj48+iG239gOAGji3gQLui9AB78ONd62qd1T3MPBOwexP3E/Dt45WGpiaFvvtogMikRkw0g84P1AnfuDXBioCueKxN2LK3M9iViCwY0H46nWT1V5yM0UdIIOy08sR9S5KADAwMYDsajHolp9KGi8PB5v738b5+6eA6Bv87td37XY59Yc0vLSMD9mPvYm7gUAtPdtj0U9FqGJexMrt6zuqFPDLjVpfI3lpgPLmgMQgOnnAffq/fdeUa2PktQ6NUb/ORpXM69iWLNhWNRzUbX2aQ3Hko9h6r9TkavORTufdviq31cm+2OTo8rBk9uexM2sm4hsGIkv+31p9v/+NDoNXt31KmKSYtDQpSF+GvKTycPg7pu7sejIIqTnp0MEEca1HoepHadatUtaJ+hwMeMi9ifux/7b+3E27SwE3P8zUDhEUdi7YerhBmtLzk02HD1zJOkInKXOGN1yNEaFjrLqa918ZTMWHF4AjU6Ddj7tsLzv8lr3s9cJOvx86Wd8FvsZFFoFXO1d8W7Xd+tNBWdBELDl2hYsPboUOeocyOxkeK3TaxjXelyd6I2yNqtPOJ01axZmzpxpaIyfn1/tm3BaKGoAkHAEGPIJ0Pn5am2islofJZ1KPYWn/366YPdR6NKgS7X2a0n7Evdhxp4ZUGqV6BLQBcv7Ljf5CZviMuIw7q9xUGqVeK3Ta3i+XfXej6r65PgnWHt+LRwljvjf4P8h1CvULPuRK+X46NhH+OPaHwD0lRbnd59v0fc9S5WFmDsx2J+4HwduH8Bdxd1iy0M9Qw29G+1929vM4cJanRZikbjWzL86lnwM0/dMh1wpRwPnBljRd4XZfi+NlZybjLkH5yImKQYAENEgAgt6LKiX5zoq+VrD/cOxsMdCmz5JaFWYNXzk5OTg6lX9LPeOHTvi008/RZ8+feDl5YWQkBAsXboUH374YbFDbc+cOVP7DrUttP9TYPd8oPnDwPhfqrWJqtT6KGlhzEJsvLwRjd0a45fHfqnV8wH+uv4X3jnwDjSCBr2De+PjXh+brb2/XfkN8w7Ng1gkxrcDvq3SYbvVUXj0EQAs67UMgxoPMst+itqfuB/zY+YbzjcxuuVoTA+fDhf7sicpV4VO0EGulCNDkYEMRQbuKu4iIz/DcD9DkYHUvFRcuHuh2ARMJ4kTIgIjENkwEj0a9qiXXyB11c2sm5iyewpuZN2Ak8QJy3otw0NBD1m1TX9d/wuLjixCtiobDnYOmB4+HU+2erJe9waULAvvKHHErAdnYVTLUbUmrNY2Zg0fe/bsQZ8+fUo9PmHCBKxdu9ZQZOzrr79GZmYmevbsia+++gotW1at7oHFw0fqReCrboCdDJgdD9gb/998VWp9lJSlysKw34chPT8dL4e9jMkdJhu9X0vYGLcRiw4vggABQ5oOwcIeC816KJogCHj34Lv449of8HX0xcahG03e9Xzh7gU88/czUGqVeL7d83it02sm3X5FclQ5+DT2U0OlywDnAMyLmFdskl6eOq9YeDAEi/y7pR67p7hXLFRUpKl7U0Q2jERkUCQ6+XWqV4cB1zdypRwz9szA0eSjEIvEeLPzm3iq1VMW/9KTK+VYdHiRYe5SW++2WBy52KbmQSRkJ2DuwbmGisb1ucenplhe3RiCACzvANy7AYz5EWj9qNGbqGqtj5J23NiBWXtnQSKW4NfH9BVQa5Oos1H4/MTnAPSHz73d9W2L/KeTp87DU9uewjX5NXRt0BVr+q8x2STHu/l38eS2J5Gcm4yeDXviy75fWmUC5dGko5h3aB4ScxIB6Ic9ctQ5yFBkIF+Tb/T23Ozd4O3oDS8HL8PF26HgvqMXWnu15knw6hi1Vo1FRxYZSoKPCR2Dt7q8ZfYhMYVGgauZV3E+/TzWnFmDtPw02Ins8FL7l2y2DoZO0GH9xfX44sQXUGgVcJG64I3Ob2BI0yG1utfa0hg+jPX3W8CRVUCH8cDwlUY/vaq1Psp63uTdk7H/9n6E+4fju4Hf1YpuTEEQ8MWJLwyz719o9wKmdpxq0f+6rmdex5PbnkS+Jt9kPUNqnRov/PMCYlNi0citEdYPWW/Vqqp56jysOLkCP178sdiETwCQ2cmKhYeiocIQLAoe95R5shejnhIEAWvPr8VnsZ9BgIDugd3xca+Pq1QNtirbTs9Px6WMS4i7F4fLGZdx6d4l3My6CZ2gM6zXxL0JlvRcYpLianXdDfkNvHPwHUPFW5mdDOH+4ege2B0RgRFo4dHCpodkGD6MdX0P8P0wwNkXmHm5WtVOq1rro6TbObfx+JbHka/Jx/zu8zGixQij921KOkGHDw5/gI2XNwIApodPx3Ntn7NKW/689ifePvA2RBBhdf/V6N6we422t/jIYvx06Sc4S52x/pH1aOpRO3qarmVew82sm8VChZPEyab/iFFxu2/txpz9c5CvyUcz92b4st+XRvVkqXVq3JDfwKWMS7h87zLiMuIQdy+u3BP6eTl4IdQzFOH+4ZjQZkKtPuzX0rQ6Lb6/8D1+uPADUvNTiy3zcfRBRIMIRATqL7XtaCVzY/gwlkYFLGsGKLOASbuAYOMnORpT66OkdefX4ePjH8PN3g1/DP+jSiepMge1To13D7yLv+L/gggivBfxHka1HGWVthSaHzMfv1z+BZ4yT2waugn+zv7V2s7mK5sx95D+7LTL+yxHn5DS85aIarMLdy9g6u6pSM1PhZeDF77o80WZdWOyVFn6cFEQMOIy4nA186qhamtRYpEYjd0aI9QzFC29WqKVVyuEeobCx9GH4bcSgiDgWuY1xCTF4NCdQziefLzYuYYAfZXjiAYR6B7YHZ38O9X7EMfwUR2bJgLnNwORM4F+cytdvSRjan2UpNFpMHbbWFzKuIQhTYfgw8gPjd5/TSk0Cryx9w3sSdwDiUiCxZGLMbhJ9c/2aypKrRLj/xqPSxmX0MmvE74d+K3RY86n007j2e3PQq1TY3KHyXg57GUztZbIvFJyUzD136m4mHER9mJ7zOk6Bx4yD8PQSVxGHJJyk8p8rrPUWR8yPAtChlcomnk0M9uZgG2NSqvCqdRTOHTnEA7dOVSqOrC92B6d/DsZhmhaerasFcPspsTwUR1nNgK/vQD4tQFePWT006MOxGPh1gto6OGI/03qgqZVnPdR6Fz6OTy17SkIELDm4TXoHlizIYaq0gk67EnYg9WnV+NixkXI7GT4tPenVj+0r6hbWbcwZusY5Khz8GzbZzEjfEaVn5ual4ontz6JtPw09Avph097f1rvPvBkW/LUeXhr/1v4L+G/ctdp6NIQLT1bItQrFK08W6GlV0s0dGnI330LylBk4EjSEcTc0feMFB5iX8jLwUs/PFMwTOPn5FfjfZZ16H2xo+TyCw7HV2SggXMDRA2MqvE+i2L4qI68DH21U0ELvHYG8DRu6ORujhIjVx3Cjbt58HK2R/TEzggL9jBqG0uOLMH6S+sR7BqM3x77zaxddGqtGtvityH6XDSuy68DAFykLljed7nZamvUxM6bOzFjjz50rOi7Ar2De1f6HJVWhWd3PIszaWfQ3KM5fnjkB5MXRiOyBq1Oi5WnVmLz1c3wc/JDqGcoQr1CDcMn1pxITaUJgoD4rHhDEDmWfKzUUW3NPZojIlA/RBPuH27okVJoFKUOuS8MECUPwTfm0PtA50DseGKHSV8nw0d1RT8C3DwIDP4I6PqS0U9Pz1Hi2ehjOHtbDid7O6waH27U5NMcVQ6GbRmG1LxUs9WfyFXn4pfLv+B/F/5nSOKuUleMaTUG41qPq9UTpJYeXYofLv4AN3s3bBy6EQ1dGpa7riAImHdoHjZf3QxXe1f8PORnhLiFWLC1RERlU2vVOJV2CjF3YhBzJwbn754vdsSbVCyFv5M/7invIVeda/T23WXuZR4dV3gEnbejN7wdvE3+N5Hho7oOLgd2vgc07QM883u1NpGj1OCVH2Kx/0o6JGIRlo1qj8c7Vn1W+u5bu/H6f69DIpJg49CNJju18938u1h/aT1+uvQTslXZAPSnC3/6gacxquWoGlXZtBS1Vo0J2yfgbPpZtPVui+8Hf1/uIaaFZ8oVi8T4qt9X6NGwapVniYgsLVORiSPJ94doSs7bkYqlxer4lAoTteTQe4aP6kq/Anz5ICCWAm9eBxyqt3+VRoc3fjmNLafuAADeeaQ1Xnio6od1Tvt3Gv5L+A8dfDtg3eB1NRqnTcxOxNrza/H71d+h1OrPHtzYrTEmtpmIoc2Gwt7OvtrbtoY7OXcw6s9RyFJlYVzrcXiry1ul1jmWfAwv/vMiNIIGM8Jn4Nm2z1qhpURExhMEATezbuKe8p4hbLhIXerE0UcMHzWxIhy4exUYtQ5oM7zam9HpBCz+6yK+PRAPAHghsgnmDG4NsbjyX6Dk3GQM+30Y8jR5eK/bexgdOtro/cdlxCHqXBT+ufGPYQywrXdbTGo3CX2C+9S506IXtTdhL6b8OwUA8EmvTzCg8QDDsqScJDy57UlkKDIwuMlgLI1cWic+tEREdZ0x39+c+lxSy4ITjF3eXqPNiMUivPvoA3j7Ef1ht9/sj8fMTaeh1uoqeab+fB9TO04FAHwe+znS8tKqtE9BEHAs+Rhe3vUynvjzCfwd/ze0ghY9AnsgakAU1g9Zj/6N+tfp4AEAvYJ7GQqfzT00F7eybgEA8jX5eO2/15ChyEBrr9aY330+gwcRUS3E8FFSaEFti8s7AF3VZg1X5MWHmuHT0WGQiEXYfPI2Jq07jlylptLnjW01Fm282yBbnY2lx5ZWuK5O0GH3zd0Y99c4PLfjORy8fRBikRiDGw/Gxkc3YvXDq9GlQZd69UU8teNUdPLrhFx1LmbsmQGFRoH3D72PixkX4SnzxOd9Pmf9AiKiWorDLiVpNfpqp4pM4NntQKMIk2x2T1wqXvnhBPLVWoQFueO7iZ3h7VLxCYku3r2IJ7c9CZ2gw8p+K0vV3lBpVdh6fSuiz0XjRtYNAPpzDQxvPhwT2kxAsGuwSdpeW6XkpmD01tHIUGSgmXszXJNfg53IDt8M+KZWHi5MRFSfcdilJuwkQIuH9bcv/22yzfYO9cP6F7rC00mK04lyPLE6BgkZeRU+p7V3a4xvPR4A8MHhD5Cn1q+fo8rB2nNrMfjXwZh3aB5uZN2Aq70rXmj3AnaM3IF3u71b74MHAPg7+2NJ5BKIIMI1+TUAwJud32TwICKq5djzUZZzvwK/PAf4hAJTjpp009fScvBM1FHczsyHr6sM657tggcCy3+deeo8DN8yHEm5SRjdcjTcZe74+dLPyFbrD5f1c/TDM22ewRMtn7DZAlrfnPkGy08ux+iWo/Fut3fr1fASEVFdwaNdakohBz5qCug0wNQTgHczk24+JUuBCd8dxaXkbLjKJPj6mQcR0az8k8kVPbqjUGO3xniu7XMY0nRInTtc1hwyFBnwcvCydjOIiGwWh11qysEdaFRwbpUaHvVSFn83B2x4KQJdm3ghW6nBhO+O4q+zZZ8MCtAf3TGk6RAAQHuf9vi8z+fYMnwLHm/xOINHAQYPIqK6gz0f5Yn5CtgxB2gcCUzcapZdKNRaTN9wCn+fS4ZIBCx4rA2ejmhc5rpanRbJeckIdA7ksAIREdU67PkwhdCCeh+3YoD8TLPswkFqhy+f6oTx3UIgCMB7W87jk3/iUFYetBPboaFLQwYPIiKq8xg+yuPVFPBtpZ/3cXWX2XZjJxZh4bC2mPFwSwDAin+vYs5vZ6GpQjGyuiA1S4Gl2y+h44J/8NL/jkOrq1UdbUREZAUMHxUxUbXTyohEIkzr1wJLRrSDWAT8fCwBL/9wAgp1zYucWcv1tBzM+e0Mei79D6v2XMO9PDV2nE/Bx//EWbtpRERkZQwfFSmsdnrlH0CrNvvuxnYJwarx4ZBJxNh1MQXjvz2CzDyV2fdrSidv3cPL/4tFv0/34qejCVBpdQhv5ImpfZsDAFbtuYa/K5hcS0RE9Z/E2g2o1YI6A07eQN5d4NZhoEmk2Xc5sE0Afni+KyatPYbjN+9h1OoYfD+pCxq4195S4YIgYE9cGlbtvYaj8RmGx/u39sPLvZrhwcb6I1GUGh2+3ncdszadRgt/FzT3c7VWk4mIyIrY81ERsR3QouCMqWYeeimqc2MvbHq5OwLcHHAlNQcjvzqEKynZFtt/Vam1Ovx2IhGDPt+PZ9cew9H4DEjtRBgVHoSd0x/CtxM6G4IHALw5MBQRTb2Rq9Lixf/FIlth/t4kImuJuXYX0346WeFh9ES2iofaVubCFmDjM4BXM2DaCYvu+nZmPp6JOoJrablwd5Tiu4kPIryR9etZ5Co1+PlYAqL2X8cduQIA4CKT4KmuIXi2R+MKe2nu5igxdMUB3JErMOABf6weHw6xmEfwUP1x4tY9fPJPHA5evWt47I2BoXi1dzMerUb1GiucmpIyW1/tVKsCphwHfFpYdPf3clV4bt0xnLyVCXs7McIbeaJ9sDvCgjzQrqE7gjwdLfYHLT1HiXWHbuD7mJuQ5+t7LXxcZHiuZ2OM69oI7o7SKm3ndEImRq2OgUqrwxsDQzG5T3NzNpvIIs7fkePTfy5j96VUAIDUToTOjb1w6Jo+hIztEoyFw9pCYscOZ6qfGD5M7X+PA9f+BR5eCPSYZvHd56u0mPrTSey6mFJqmbezPdoFuaN9kAfCCq59XSs+W66xbt7Nxdf7ruOX2EQoNfpDgJv4OOPFh5ri8Y4N4SC1M3qbG47dwuxfz0IkAtY92wUPtfQ1aZuJLOVqag4+23kZ2wqGV8Qi4InwIEzt2wLBXk5Yd+gG5v95HjoB6B3qiy+f6gQXGafbUf3D8GFqR74G/n4DCOkOPGe6M90aQxAExKVk43RCJk4nynEmMROXkrKhKaNuRqC7A9oHeRh6SNo2dK9yr0RRZxPlWL33Gv4+l4TC3YQFe+CVXk3x8AMBsKvhcMmc387ip6O34O4oxdapPRHs5VSj7RFZ0q27efh892X8fvI2dAIgEgFD2wfi9f4t0NTXpdi6Oy+kYOpPJ6BQ69Am0A3fTewMfzcHK7WcyDwYPkwt8xbweTtAJAbeuAY4WX/eBaAvz34pORtnEjNxOkEfSK6m5aCsd7SJjzPaF+khaRPoDkf70j0WgiBg/5V0rN57zdBdDAB9Qn3xUq9m6NrEy2TDPEqNFqPXHMbphEw80MANv77Svcw2EdUmSfJ8rPj3KjYeSzCE/4cf8MfMAS3RKqD8v1mnEjIxae0x3M1VoaGHI6Kf7YyW/jzii+oPhg9zWNUDSDkHPP41EDbG2q0pV45Sg3O39UGksIckISO/1Hp2YhFa+LkgrKCHpH1DD1xPz8GavddxISkLACARi/BYWCBe7NW0wj+qNZEkz8ejyw/gbq4KIzo2xCejw2rVpDydTsDqfdewNy4Nk/s05/CQDUvPUWLVnmv43+GbUBUMPz7U0hczH26JsGCPKm3j1t08TIw+iuvpuXB1kGDN0+Ho3szHjK0mshyGD3PYvRDY/zHQ5nFg1Fprt8YoGbkqnEnMxJlEecElE6nZynLXd7K3w5OdQzApsgkaepi/vkjMtbsYH3UEWp2A+Y+1wYTujc2+z6rIV2kx65fT2Hbm/qGSj4UF4t1HW8PPlV3mtkKep8bX+68h+uAN5Kn0VYe7NPbCzAEt0bWpt9Hbu5erwov/O45jN+5BaifCR0+0x+Mdg0zdbCKLY/gwh8TjwLf9AJmbfuhFUrdPZZ8sV+B0YmaxUGIvEeOZbo3wdEQjeDhZ9vV9u/86Fm27CIlYhJ9e7IbOja07tJWSpcAL3x/HmUQ5pHYiPPyAP7afS4ZOANwcJJg9uBXGdg7hYcL1WI5Sg+gD8fh6/3VkKzQAgLAgd8wcEIrIFj416qFTqLWYuel+sJ01oCUm92leq3r9iIzF8GEOOh3wSSiQmwo8/TvQrI+1W2RSgiBY9Q+fIAiY9vMp/Hn6DnxdZdg6tafVJuSduy3H8+uOIzlLAU8nKVaPD0fXpt44myjHnM1ncO62fliqU4gHFo9oZ7YhKbIOhVqL/8XcxKq915CRqz+9QasAV8x4uCUefsDfZJ8TnU7Ah9sv4et91wHwUFyq+xg+zGXLZODkD0DXl4HBS63dmnonT6XB4ysPIS4lG+GNPPHTC91gL7HsH+Lt55Lw+oZTUKh1aO7ngqgJD6KRt7NhuUarw/cxN/HJP3HIVWkhEYvwfGRTvNavhc1NllVrdVj531VsOJaAbk298UR4ECKaetfZ3iCVRocNx25hxb9XDcOSTXycMf3hlni0XQOzva7vY27g/T/0h+L2aumLleN4KC7VTQwf5nJpG/DzU4BHI+C10/pj68ik4tNz8diXB5Ct0OCZiEZYMKytRfYrCAK+2nMNy3boz7r7UEtffPlUR7g5lH2IcpI8H+//cR47zutrrwR5OmLh8LboE+pnkfZa26XkLMzceBrn72QVe7yhhyNGdGqIkZ2C0NjHuZxn1y4arQ6/nbyNL3Zdwe1M/eTshh6OeK1/C4zo2NAiPRFFD8V9oIEbop/lobhU9zB8mIsqF1jaBNAqgVcPA36trd2iemn3xRRMWnccAPDxqDA8EW7eyXgKtRZzfjuLzSdvAwAmdm+Md4e0rtKXzs4LKZi35ZyhzPyQdg0wd+gD9faLQ6PVYc2+6/h812WotQI8nKSY3r8lLqdk44/TdwxzIwCgc2NPPBEehEfaNYBrOSHOmlKzFNgTl4bVe6/henouAMDXVYapfZtjTOdgyCSW7ck6lZCJ59cdQ3qOCoHuDlj7XBceikt1CsOHOf04CrjyD9BvHhA5w9qtqbc+23kZX+y+AplEjF9f6Y62Dd3Nsp/0HCVe+l8sYm/eg51YhPmPtcH4bo2M2kauUoPPdl5G9KEb0OoEuMokeHNQKJ7q2qjGhdhqk6upOZi16TROJWQC0J+1ePGIdoYjfxRqLXZeSMEvsYnYfyXNUJjOQSrG4LYNrD4sk6fS4Eh8Bg5cSceBK+mIK3KyRk8nKV7p3QxPd2ts1eGzW3fzMHHtUVxPKzgUd3w4ujfnobhUNzB8mNOxKGDbDCC4KzDpH2u3pt7S6QRMWncM/8WloaGHI7ZO7QlPZ9MegXMpOQuT1h7H7cx8uDlI8NW4cPRsUf0/9OfvyPH25nM4XfDlHBbsgcWPt0WbQPMEJ0vR6QR8dzAey3bEQanRwdVBgnlD22Bkp4blTr5Mliuw+eRt/BKbgGtpuYbHA90dMDI8yCLDMlqdgHO35ThwNR37r6ThxM1MqLQ6w3KRCGgT6IbBbRtgQvfGtWaeBQ/FpbqK4cOc5LeBzx4AIAJmXQFcWHTKXOR5ajy28gBu3s1DZAsfrH22i8l6EnZfTMG0n04iV6VFEx9nfDvhQTQrURK7OrQ6AT8euYll2+OQrdTATizCcz0a4/X+LeFcS77cjHHzbi7e2HQGR29kAAAiW/jgoyfaV3jm4qIEQcCphEz8EptokWGZW3fzcOBqOg5cTcPBq3cNJ0As1NDDET2b+6BnCx/0aO4DLxMHWlPhobhUFzF8mNuah4Ck08Cwr4CO46zdmnrtYlIWRnx1CPlqLV7t3QxvDmpVo+0JgoCoA/H44K+LEAQgoqk3Vo3vZPK6JilZCiz484LhZGMNPRwx/7E26P+Av0n3Yy66ghC1+K9LyFdr4Wxvh3eGPICxXYKr/QVY0bDMoDYBeCI8GN2bGTcsI89T49C1dOy/qh9KuZWRV2y5q0yCiGbe6NnCBz2b+6CJj3Od+QLX6QQs3X4JawoOxX2yczAWDm8LKQ/FpVqK4cPc/lsC7P0QaD0UGPODtVtT7205dRuv/XwKALB6fCcMatugWttRaXR47/dz2HA8AQAwtksIFgxrY9Y/5v9dSsW7v58zHEUxqE0A3n+sDQLca++E1NuZ+Xjzl9M4eFV/bp9uTb2w7Ikwk574r6JhmRGdgjAyPAhNyhiWUWl0OHHrHg5c0QeOs4mZKHpuRYlYhI4hHujZ3Bc9W/ggLMi9ztfNKHoo7kMtffEVD8WlWorhw9zunAS+7g3YuwBvXgckpj2FPZW2cOsFRB2Ih7O9HbZM6YnmfsYNkdzLVeHlH2JxJD4DYhHw7pAH8GyPxhb5LzhPpcEXu6/g2/3x0OoEuMgkmDmgJZ6JaFyrJqQKgoCNxxOwcOtF5Cg1cJCKMXtQK0yIaGy2SaIVDcs82Eg/LNO2oXvBRNE0HInPMJQ4L9TM1xmRLXzRs7kPujXzrpdfzDwUt/bIUqgRe/MebqbnwttFBn83B/i76a8dpLZV66ckhg9zEwTg09ZAdhIw/legeX9rt6jeU2t1GP/tERyJz0AzX2f8PrlHlecJXE3NwaR1x3Dzbh5cZBKseKqjVepxXEzKwtubz+LkrUwAQPsgdyx+vJ3ZjuQxRkqWAm/9egb/xaUB0Fdv/XhUWKlTw5uTQq3Frov6YZl9l9OK9WgU5eNijx7NfQxzN6o6/6SuO52QiUlFDsWNfrYLQgN4KK65pWYpcPRGBo7fuIej8Rm4lJxV7u+mu6PUEET8XB0Q4H7/duHjvq6yejt0xvBhCX++BsSuBTo/Dwz5xNqtsQlp2UoMXXEAyVkKDGzjj9Xjwyvtudh3OQ2T159AtkKDYC9HRE2w7mnMdToBPx27hQ//voRshQZiETCxexPMGNDSKv+xC4KALafuYN4f5yHPV8PeToyZA1ri+cimVu2VSckqHJZJxO17+XiwsSciW/igZ3NftApwrbNVVGsqISMPE6ILDsWVFZwVl4fimowgCIhPz9UHjRsZOHYjAzfv5pVar5G3E0L9XZGZr0ZKlgIpWQoo1LoytliaSAR4O8sMYcTfTVYQVO7f9ndzgLezfZ37PWf4sITLO4D1owG3IGD6OVY7tZCTt+5hzJrDUGl1eHNQKF7t3bzcddcduoEFWy9AqxPQubEnVo8Ph7dL7RgiS81WYOHWi/jz9B0AgKPUDu2C3NEx2AMdQzzQMcTT7N3q6TlKvLP5rKFKa/sgd3wyKgwtWNiqVsvMU+GF7/WH4opEgJuDFE72dnCU2sGxjGsnezs4SPX3C2872UvgaC8uWEdSbJmjvR2cCq5lEnGdmaBbHRqtDheTsnGsIGgcu3EP6TnFz/gtEgGtA9zQpYkXOjf2QufGnvAr8dkUBAFZCg1SsxRIyVIiuSCQFN5PyVYgRa5AarYSmvK6TUoQifQ9KR6OUrg72cPDUQoPJ2nBtb3+tpMUHo72cC/yuLuj1Gr/ODB8WII6X1/tVJMPvHwACGhn7RbZjPVHbuHtzWchFgFrn+2Ch1oWP9xZo9Vh/p8X8L/DNwEAIzsFYfGIthavWFkVey+nYd6Wc7hRxn9XDdwd9EEk2BMdQjzQrqG7ycaU/zqbhHd/P4eMXBUkYhFe69cCL/duVm+7g+sbhVqL2b+ewZZTd8y+L3s7MewlYkjtRAXX+vv3Hy9+W1bWuoXr24khldy/dpHZwd1Rari4FVyb67OqUGtx8lYmjt/IwNEbGTh5KxM5Sk2xdewlYnQI8kDnJp54sLEXwht5lnuaBWPpdAIy8lSG3pKULKXhOjVLURBalLibq0RNvpndHCSGgOJeGFYcpfB0uh9kfF1lpf521hTDh6X8NBaI+wvo8y7Q6w1rt8ZmCIKAt349iw3HE+DhJMWfU3oajsSQ56sx+ccTOHA1HSIRMHtQK7z0UNNa/d+bTifgWloOTiZk4uStTJy8dQ+XU7JLjStLxCK0auCKjsGe6BjigQ7BHkYfOnovV4W5f5w39Li0CnDFJ6PD6nwhNFuVmqVAlkKDfJUW+Wot8lQaKNRa5BXcz1dpiyzTQqEufjuvYHnJ5xQtxmYNDlJxsVBSNJiUvBR+wZYVXDLzVIi9WTCEEp+Bs7flUGuLf7BcHSR4sJE+aHRp4mXSkF9daq0O9/JUkOepkZmvRmaeGpl5Kv11fuG1umC5/r48T43sEkGqIo28nbD3DdOenZ3hw1Ji1wF/TgMahgMv/Gvt1tgUhVqL0WticCZRjjaBbvj1le5Ilivw3LpjuJ6WCyd7O3w2pgMGtgmwdlOrJVepwZlEOU4m3MOpW5k4mZCJtGxlqfU8nKQIC7o/VNMhyAPuTmX/l7brQgrmbD6LtGwl7MQivNKrGab1a2HxMwdT7afR6qDQ6JCv0kKt1UGt1UGl0UFVeK3RQa0VoNJqodIIUGl1UBcsL7muushzVFqh2GM5Sg3k+WrDJUuhrtF//MD94CKT2JWq+wIAfq4ydG7ihS6N9cMooQGuteqos5pQa3WQF4QVeWFIMQQVFTLz1bhXEGT8XB3wyegwk+6f4cNSspOBT0L1t2deBlzrRgGp+uJ2Zj6GrjiAjFwVHmrpi9MJmZDnqxHo7oBvJjxYr/6bFwQBtzPzcaqgd+RUQibO3pZDpSn9H2pTX2fDUE3HYA809HDEB39dxC+xiQCA5n4u+GRUGMKCPSz8KogqptMJyFZqkFUkkJS8ZOapy1xeXnBp6uuMzo28DIEj2MuxVveE1mUMH5b0TV/gdiwwdDkQPsHarbE5h66mY3zUEcMQRYdgD3z9TLjhZGf1mUqjw8WkrIJAcg8nEzLLnJlfSCQCXohsihkPt7R6tzKRqZUMLjlKDZr7ucCnlkwytwUMH5a0dxnw3yIg9BFg7E/Wbo1Nij4Yj0XbLmJo+wb4cGR7m/5ivZujxOnETMNQzalbmchWatDY2wkfjwrDg429rN1EIqqnGD4sKfkssLonIHEEZscDUtsoeFTb5Kk0cLKvf5Uta0qnE5CUpYC/q6zOlxknotrNmO9v/jWqKf+2+lofmnwgfp+1W2OzGDzKJhaL0NDDkcGDiGoV/kWqKZEICB2kvx33t3XbQkREVAcwfJhC6GD99eXtqPFxYkRERPUc+6pNoXGk/gy32UlA0ikgsKO1W2R9GhWQd7fgkg7kZQB29oCzD+DkAzh5AQ4egJj5l4jI1jB8mIJEBjTrA1z8E/jlOcC7OeDoBTh5A06eRW57Fb8tqSOHgOl0gCJTHyDy0u+HitzC2xlFQkbBfWVW5dsV2RX8LLwLQomXPpg4+9x/3LCs4DGJvdlfbp2l1QCqbECZA6hy9NfKLECVq19uZw/YSQqu7QGxFLArvNgD4sJlBY+JCx+347mLiMikGD5Mpe0T+vCRcV1/qQqpc+UBxdHz/m2ZGyDoAK0a0GkAnRrQaQvuFzym1dxfpi1YblhW+Lxybqtyi/dUGHouMgBBa/zPRGR3P1A4eQEa5f1tK7P028xN1V/SqrhNmVvZIcXRU7+86Ost+fModr/kz09T/FLyZyfoAImDPjBKHIpcZJVfSx0rX0fQAcqiwSH7/nW5j5UIGpp849+jqqosrEhk+iO+qvLzKPVzLO9nVnBfLAUgFAxpVvcaFS8XdAW3dUUuJe+XdREqX9/eWf976+B2/9reVR8EiWwUD7U1FUHQH3YrT7j/hZ1f+AV+r8jtDCD/XvW+zK2t6Be/oVeiSA9Fycdl7uUPq2iU93tScsvqTSkIKbnp92/XxZ+ZNdjJAJmLfihQ5qq/BgoCqUofrAovhsc0Bdcq/pwtRepcPJCUunYvuHYtf5mdaU54Vm2CoP+nRZkFKLKKXMuL3JeXWFZkHZFY/3OwdwKkTvqgZu98/7bUSb/M3uX+bWnBOobbRR6TyNhLZ0XGfH8zepuKSAQ0aK+/VEan03/wCoNIqbBSeDuj+ONa1f1tiKUF/3kWXBtu293/D7XY45IS9wvWNdyW6P/bLDnkUTjs4ehl2iEPiQxwa6C/VIVh6KdoSCkIKrl39T9HkaiS12xX4udW5L5Yov9PVCwpsk6R+yKRPjBpFAUXZYlrBaAub1nR55WzHKKCL5kioaEwOJT7mGvp59i71Px90unu95xpVQU9QariIUVXJMBolfo5PpW+9vKWVXSdX9ArUZSo4AumvOvK1im5XFzGpWB5mcuKrlPR8oLgXfjlrMzWf+kW9lCpc/WX7KTqv1d2sjKGyiTF/wYYHpcWv11sWeFz7Is/X6etJFhk1a6wWjTMFAaZ8j4nsqK3Sz5WsL7EofphRhD0v8eqPH3vpDqvxO3c+9eG20WWC0JB+12KvJbybhe5SJ3rxFw6s4WPlStXYtmyZUhOTkZYWBhWrFiBLl26mGt3dYtYrB8mKBwqqApB0P/RF9nZ5hi8WFzQ6+IFoIW1W1O/icWAWFZ75iTpdPfDQH2gURUMnZXXI1DQW2C4n116HXXBPB6tUn+xNpFdOb02Bfcd3MvuvYFQ/pewuuC+4XbhF3bhYwVf1Kq8+z8DQacfjlRlm+51lRn0C4KJOr+c9hdclwrOFlK0F6lUSCm47xYIRM60TvtgpvCxYcMGzJgxA6tXr0bXrl3x+eefY+DAgYiLi4Ofn585dln/iUS158uAyJLqwH9xRpHYA5KCocnq0moKJhPnlBhCKzK/y9BrVcayoj1XOnXBXKgS97UqfU+CITC4lx0sZG76LzNrhkOtpuzehMJep8J5UYY5U9mlHys6n6ow3AnagmEjec3aJ3EoMZRUdHjJ6X6PRdEhJKBIAMu93ytiuJ9T/HWqcgAUzKJQF4Sz3Aom0/m0tGr4MMucj65du6Jz58748ssvAQA6nQ7BwcGYOnUq3nrrrQqfW2fnfBARUf2g097/Qi9zgne2fkil3EBR5LbUyTKTiwXhfk9M0WCizi07sDi4AxGTTdoEq875UKlUiI2NxZw5cwyPicVi9O/fHzExMaXWVyqVUCrvdxtmZVXhEE0iIiJzERcMIznUoX+ARaKCXhQnAL7Wbk2lTN6fmZ6eDq1WC39//2KP+/v7Izk5udT6S5Ysgbu7u+ESHBxs6iYRERFRLWL1wdQ5c+ZALpcbLgkJCdZuEhEREZmRyYddfHx8YGdnh5SUlGKPp6SkICAgoNT6MpkMMhknUhIREdkKk/d82NvbIzw8HLt37zY8ptPpsHv3bkRERJh6d0RERFTHmGUK7owZMzBhwgQ8+OCD6NKlCz7//HPk5ubi2WefNcfuiIiIqA4xS/gYM2YM0tLSMHfuXCQnJ6NDhw7Yvn17qUmoREREZHt4bhciIiKqMWO+v61+tAsRERHZFoYPIiIisiiGDyIiIrIohg8iIiKyKIYPIiIisiiGDyIiIrIoC5zn1ziFR/7y7LZERER1R+H3dlUqeNS68JGdnQ0APLstERFRHZSdnQ13d/cK16l1RcZ0Oh3u3LkDV1dXiEQik247KysLwcHBSEhIqPcFzGzptQK29Xr5WusvW3q9fK31jyAIyM7ORmBgIMTiimd11LqeD7FYjKCgILPuw83NrV7/AhRlS68VsK3Xy9daf9nS6+VrrV8q6/EoxAmnREREZFEMH0RERGRRNhU+ZDIZ5s2bB5lMZu2mmJ0tvVbAtl4vX2v9ZUuvl6/VttW6CadERERUv9lUzwcRERFZH8MHERERWRTDBxEREVkUwwcRERFZFMMHERERWVS9Cx8rV65E48aN4eDggK5du+Lo0aMVrr9p0ya0atUKDg4OaNeuHf766y8LtbT6lixZgs6dO8PV1RV+fn4YPnw44uLiKnzO2rVrIRKJil0cHBws1OKaef/990u1vVWrVhU+py6+rwDQuHHjUq9VJBJh8uTJZa5fl97Xffv2YejQoQgMDIRIJMLvv/9ebLkgCJg7dy4aNGgAR0dH9O/fH1euXKl0u8Z+5i2loterVqsxe/ZstGvXDs7OzggMDMQzzzyDO3fuVLjN6nwWLKGy93bixIml2j1o0KBKt1sb39vKXmtZn1+RSIRly5aVu83a+r6aU70KHxs2bMCMGTMwb948nDhxAmFhYRg4cCBSU1PLXP/QoUMYO3YsJk2ahJMnT2L48OEYPnw4zp07Z+GWG2fv3r2YPHkyDh8+jJ07d0KtVmPAgAHIzc2t8Hlubm5ISkoyXG7evGmhFtdcmzZtirX9wIED5a5bV99XADh27Fix17lz504AwKhRo8p9Tl15X3NzcxEWFoaVK1eWufyjjz7C8uXLsXr1ahw5cgTOzs4YOHAgFApFuds09jNvSRW93ry8PJw4cQLvvfceTpw4gd9++w1xcXF47LHHKt2uMZ8FS6nsvQWAQYMGFWv3Tz/9VOE2a+t7W9lrLfoak5KS8N1330EkEmHkyJEVbrc2vq9mJdQjXbp0ESZPnmy4r9VqhcDAQGHJkiVlrj969GhhyJAhxR7r2rWr8NJLL5m1naaWmpoqABD27t1b7jrR0dGCu7u75RplQvPmzRPCwsKqvH59eV8FQRBee+01oVmzZoJOpytzeV19XwEImzdvNtzX6XRCQECAsGzZMsNjmZmZgkwmE3766adyt2PsZ95aSr7eshw9elQAINy8ebPcdYz9LFhDWa91woQJwrBhw4zaTl14b6vyvg4bNkzo27dvhevUhffV1OpNz4dKpUJsbCz69+9veEwsFqN///6IiYkp8zkxMTHF1geAgQMHlrt+bSWXywEAXl5eFa6Xk5ODRo0aITg4GMOGDcP58+ct0TyTuHLlCgIDA9G0aVOMGzcOt27dKnfd+vK+qlQq/PDDD3juuecqPMNzXX5fC8XHxyM5ObnY++bu7o6uXbuW+75V5zNfm8nlcohEInh4eFS4njGfhdpkz5498PPzQ2hoKF555RXcvXu33HXry3ubkpKCbdu2YdKkSZWuW1ff1+qqN+EjPT0dWq0W/v7+xR739/dHcnJymc9JTk42av3aSKfT4fXXX0ePHj3Qtm3bctcLDQ3Fd999hy1btuCHH36ATqdD9+7dkZiYaMHWVk/Xrl2xdu1abN++HatWrUJ8fDwiIyORnZ1d5vr14X0FgN9//x2ZmZmYOHFiuevU5fe1qML3xpj3rTqf+dpKoVBg9uzZGDt2bIVnPTX2s1BbDBo0CN9//z12796NpUuXYu/evRg8eDC0Wm2Z69eX93bdunVwdXXFiBEjKlyvrr6vNSGxdgOoZiZPnoxz585VOj4YERGBiIgIw/3u3bujdevWWLNmDRYuXGjuZtbI4MGDDbfbt2+Prl27olGjRti4cWOV/qOoq6KiojB48GAEBgaWu05dfl9JT61WY/To0RAEAatWrapw3br6WXjyyScNt9u1a4f27dujWbNm2LNnD/r162fFlpnXd999h3HjxlU6Cbyuvq81UW96Pnx8fGBnZ4eUlJRij6ekpCAgIKDM5wQEBBi1fm0zZcoUbN26Ff/99x+CgoKMeq5UKkXHjh1x9epVM7XOfDw8PNCyZcty217X31cAuHnzJnbt2oXnn3/eqOfV1fe18L0x5n2rzme+tikMHjdv3sTOnTsr7PUoS2WfhdqqadOm8PHxKbfd9eG93b9/P+Li4oz+DAN19301Rr0JH/b29ggPD8fu3bsNj+l0OuzevbvYf4ZFRUREFFsfAHbu3Fnu+rWFIAiYMmUKNm/ejH///RdNmjQxehtarRZnz55FgwYNzNBC88rJycG1a9fKbXtdfV+Lio6Ohp+fH4YMGWLU8+rq+9qkSRMEBAQUe9+ysrJw5MiRct+36nzma5PC4HHlyhXs2rUL3t7eRm+jss9CbZWYmIi7d++W2+66/t4C+p7L8PBwhIWFGf3cuvq+GsXaM15N6eeffxZkMpmwdu1a4cKFC8KLL74oeHh4CMnJyYIgCMLTTz8tvPXWW4b1Dx48KEgkEuHjjz8WLl68KMybN0+QSqXC2bNnrfUSquSVV14R3N3dhT179ghJSUmGS15enmGdkq91/vz5wo4dO4Rr164JsbGxwpNPPik4ODgI58+ft8ZLMMrMmTOFPXv2CPHx8cLBgweF/v37Cz4+PkJqaqogCPXnfS2k1WqFkJAQYfbs2aWW1eX3NTs7Wzh58qRw8uRJAYDw6aefCidPnjQc3fHhhx8KHh4ewpYtW4QzZ84Iw4YNE5o0aSLk5+cbttG3b19hxYoVhvuVfeatqaLXq1KphMcee0wICgoSTp06VexzrFQqDdso+Xor+yxYS0WvNTs7W5g1a5YQExMjxMfHC7t27RI6deoktGjRQlAoFIZt1JX3trLfY0EQBLlcLjg5OQmrVq0qcxt15X01p3oVPgRBEFasWCGEhIQI9vb2QpcuXYTDhw8blvXq1UuYMGFCsfU3btwotGzZUrC3txfatGkjbNu2zcItNh6AMi/R0dGGdUq+1tdff93wc/H39xceeeQR4cSJE5ZvfDWMGTNGaNCggWBvby80bNhQGDNmjHD16lXD8vryvhbasWOHAECIi4srtawuv6///fdfmb+3ha9Hp9MJ7733nuDv7y/IZDKhX79+pX4GjRo1EubNm1fssYo+89ZU0euNj48v93P833//GbZR8vVW9lmwlopea15enjBgwADB19dXkEqlQqNGjYQXXnihVIioK+9tZb/HgiAIa9asERwdHYXMzMwyt1FX3ldzEgmCIJi1a4WIiIioiHoz54OIiIjqBoYPIiIisiiGDyIiIrIohg8iIiKyKIYPIiIisiiGDyIiIrIohg8iIiKyKIYPIiIisiiGDyIiIrIohg8iIiKyKIYPIiIisqj/AwdVW3uwY9N5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epoch), alex_train_loss, label=\"Alexnet\")\n",
    "plt.plot(range(epoch), res_train_loss, label=\"Resnet\")\n",
    "plt.plot(range(epoch), vgg_train_loss, label=\"VGG\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change n_factor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 40\n",
    "# D = 20\n",
    "\n",
    "# reg_theta = 0.1\n",
    "# reg_beta = 0.1\n",
    "# reg_e = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | LOSS : 28.18210384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 82.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1 | LOSS : 7.046804023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2 | LOSS : 4.428007555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3 | LOSS : 7.956360625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 82.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 4 | LOSS : 2.868613842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5 | LOSS : 2.814103955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 6 | LOSS : 8.579558687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7 | LOSS : 2.964048634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 | LOSS : 3.686908787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 | LOSS : 2.994235508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10 | LOSS : 2.789032084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11 | LOSS : 3.615923688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:25<00:00, 79.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 12 | LOSS : 6.103832317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 83.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13 | LOSS : 2.558734805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 83.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 14 | LOSS : 2.088150819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 85.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15 | LOSS : 1.993634929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16 | LOSS : 3.095410129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 17 | LOSS : 2.360050931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:26<00:00, 78.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18 | LOSS : 2.04970236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 19 | LOSS : 2.348759699\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 125.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | LOSS : 10.98272017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 126.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1 | LOSS : 0.9296352961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 124.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2 | LOSS : 0.7893494078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 122.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3 | LOSS : 1.000911919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 125.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 4 | LOSS : 1.167948515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 124.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5 | LOSS : 0.8235874394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 120.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 6 | LOSS : 0.9123857598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 122.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7 | LOSS : 0.7872915809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 125.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 | LOSS : 0.735302651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 125.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 | LOSS : 0.9112764455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 126.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10 | LOSS : 0.7521344983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 126.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11 | LOSS : 0.6108194673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 123.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 12 | LOSS : 0.5387842943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 120.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13 | LOSS : 0.9015949113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 120.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 14 | LOSS : 0.4204573612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:16<00:00, 121.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15 | LOSS : 0.5046210329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 116.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16 | LOSS : 0.6513782719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 118.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 17 | LOSS : 0.4889759619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 120.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18 | LOSS : 0.4544509858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:17<00:00, 118.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 19 | LOSS : 0.3908704371\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 87.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 | LOSS : 37.55897907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1 | LOSS : 9.016051165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 87.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2 | LOSS : 7.779947816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 3 | LOSS : 7.482064555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 4 | LOSS : 12.10761968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 86.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 5 | LOSS : 11.40450947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:24<00:00, 84.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 6 | LOSS : 10.24837937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:25<00:00, 80.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 7 | LOSS : 9.116939221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 85.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 8 | LOSS : 13.39221242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 9 | LOSS : 8.56362654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 10 | LOSS : 12.17954752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 11 | LOSS : 9.938569797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 12 | LOSS : 13.55961507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 13 | LOSS : 10.46487571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 14 | LOSS : 9.530770193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 15 | LOSS : 9.012995173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 16 | LOSS : 10.63092894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 17 | LOSS : 8.406587514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 18 | LOSS : 10.70024191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2055/2055 [00:23<00:00, 88.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 19 | LOSS : 10.51508709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vbpr_alex = VBPR(n_user, n_item, K, D, F, feat_map_alex)\n",
    "optimizer = Adam(params = vbpr_alex.parameters(), lr=lr)\n",
    "alex_train_loss_40 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    alex_train_loss_40.append(train(vbpr_alex, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {alex_train_loss_40[-1]:.10}')\n",
    "\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "vbpr_res = VBPR(n_user, n_item, K, D, F_res, feat_map_res)\n",
    "optimizer = Adam(params = vbpr_res.parameters(), lr=lr)\n",
    "res_train_loss_40 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    res_train_loss_40.append(train(vbpr_res, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {res_train_loss_40[-1]:.10}')\n",
    "\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "vbpr_vgg = VBPR(n_user, n_item, K, D, F, feat_map_vgg)\n",
    "optimizer = Adam(params = vbpr_vgg.parameters(), lr=lr)\n",
    "vgg_train_loss_40 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    vgg_train_loss_40.append(train(vbpr_vgg, optimizer, train_dataloader, criterion, device))\n",
    "    print(f'EPOCH : {i} | LOSS : {vgg_train_loss_40[-1]:.10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top K rec test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, model, query_img, train_dataset, n_item, feature_map, device) -> None:\n",
    "        self.model = model\n",
    "        self.train_df = train_dataset.dataset.df\n",
    "        self.all_item = set(range(0,n_item))\n",
    "        self.query_img = query_img\n",
    "        self.feature_map = feature_map\n",
    "        self.device = device\n",
    "\n",
    "    def _get_img_sim(self, itemset:list):\n",
    "        print(\"GET IMG SIM\")\n",
    "        res = []\n",
    "        for item in itemset:\n",
    "            res.append(nn.functional.cosine_similarity(self.query_img, self.feature_map[item.item()]))\n",
    "        return res\n",
    "\n",
    "    def _get_unobs_items(self, user_idx):\n",
    "        obs_item_set = set(self.train_df[self.train_df.user_id==user_idx].isbn)\n",
    "        return list(self.all_item - obs_item_set)\n",
    "\n",
    "    def user_rank(self, user_idx:int, top_k:int=None):\n",
    "        self.model.eval()\n",
    "        unobs_itemset = self._get_unobs_items(user_idx)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            itemset = torch.tensor(unobs_itemset).to(self.device)\n",
    "            user = torch.tensor(np.full(len(itemset), user_idx)).to(self.device)\n",
    "            img_sim = torch.tensor(self._get_img_sim(itemset))\n",
    "\n",
    "            out, _ = self.model.cal_each(user, itemset)\n",
    "            out = out + img_sim\n",
    "            scores = np.array(torch.concat((user.unsqueeze(dim=1),itemset.unsqueeze(dim=1),out.unsqueeze(dim=1)), dim=1))\n",
    "       \n",
    "        sorted_scores = scores[(-scores[:, 2]).argsort()]\n",
    "        return sorted_scores[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(recommender, test_dataset):\n",
    "    df = test_dataset.dataset.df\n",
    "    user_list = df['user_id'].unique()\n",
    "    res_true = {}\n",
    "    res_topk = {}\n",
    "    res_hit = {}\n",
    "    \n",
    "    for user in tqdm(user_list[:50]):\n",
    "        true_item = df[df.user_id==user].isbn\n",
    "        if len(true_item)>4:\n",
    "            res = recommender.user_rank(user, 20)\n",
    "            topk = res[:,1]\n",
    "            hit = len(set(true_item).intersection(set(topk)))\n",
    "            res_true[user] = list(true_item)\n",
    "            res_topk[user] = list(topk)\n",
    "            res_hit[user] = hit\n",
    "    \n",
    "    return res_true, res_topk, res_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:21<32:34, 40.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [02:42<45:02, 57.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [04:03<27:51, 37.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [05:24<34:25, 48.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [06:45<39:20, 56.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [08:06<33:04, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [09:26<23:59, 38.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [10:47<22:59, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [12:08<26:35, 46.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [13:29<19:44, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [14:50<22:48, 45.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [16:11<25:25, 52.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [17:32<27:27, 58.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [18:27<16:18, 39.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [19:14<09:05, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [20:01<09:42, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [20:49<10:12, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [21:36<10:33, 35.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [22:23<08:15, 30.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [23:12<08:40, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [24:04<04:13, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [24:55<03:33, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [25:47<02:50, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [26:38<02:03, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [27:29<01:14, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [28:20<00:58, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [29:13<00:34, 34.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET IMG SIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [30:06<00:00, 36.12s/it]\n"
     ]
    }
   ],
   "source": [
    "query_isbn = \"0440234743\"\n",
    "img = prepare_img(query_isbn)\n",
    "query = model_res(img)\n",
    "# res = img_sim(query, feat_map_vgg)\n",
    "# res\n",
    "recommender = Recommender(vbpr_res, query, train_dataset, n_item, feat_map_res, device)\n",
    "\n",
    "res_true, res_topk, res_hit = eval(recommender, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
